{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducción e Importación de librerías y datos\n",
    "### En este cuaderno vamos a practicar con diferentes algoritmos de clasificación:\n",
    "* SVM(Support Vector Machine). En español: Máquina de vectores de soporte \n",
    "* Regresión Logística \n",
    "* Árboles de Decisión \n",
    "* Bosques aleatorios \n",
    "* kNN, o el algoritmo de k vecino más cercano\n",
    "### Para los siguientes datasets:\n",
    "* Phishing Urls\n",
    "* Calidad del Vino(Si es 5 o menor es de mala calidad y si es mayor de 5 es buena calidad)\n",
    "* Diagnostico de Cancer de Mama\n",
    "* Temperatura en España (dias de lluvia de un mes y lugar concreto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para cada algoritmo vamos a:\n",
    "* Explicar en qué consiste el algoritmo\n",
    "* Explicar los resultados en cada dataset en base a las métricas iniciales sin incluir hiperparámetros\n",
    "* Ajuste de hiperparamétros en cada uno de los ejemplos (3 casos por cada hiperparámetros y comparar y explicar cuál es el mejor resultado) y explicar en que consisten cada uno de ellos y cuando usarlos.\n",
    "* Analizar los resultados de cada dataset indicando cual es mejor algoritmo en cada caso\n",
    "* Incluir dos nuevas métricas en cada algoritmo, explicar la métrica y analizar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por cada dataset vamos a:\n",
    "* Tratar los datos(limpieza, encoding y escalado) cuando sea necesario\n",
    "* Crear uno de ejemplo con sólo 10 registros, con 5 para un caso y otros 5 para otro. Usar los algoritmos con estos dataset, con la configuración de hiperparametros que hayais obtenido mejor resultado e indicar en cada caso que resultado habéis obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-24T18:05:22.885288Z",
     "iopub.status.busy": "2025-02-24T18:05:22.884978Z",
     "iopub.status.idle": "2025-02-24T18:05:23.266306Z",
     "shell.execute_reply": "2025-02-24T18:05:23.265564Z",
     "shell.execute_reply.started": "2025-02-24T18:05:22.885264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import  OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, average_precision_score, explained_variance_score\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T18:05:25.342838Z",
     "iopub.status.busy": "2025-02-24T18:05:25.342225Z",
     "iopub.status.idle": "2025-02-24T18:05:25.477367Z",
     "shell.execute_reply": "2025-02-24T18:05:25.476313Z",
     "shell.execute_reply.started": "2025-02-24T18:05:25.342798Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\domid\\Desktop\\210MIA\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\domid\\AppData\\Local\\Temp\\ipykernel_9120\\2918722099.py:7: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
      "  dfphishing = kagglehub.load_dataset(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DATASET PHISHING'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>UsingIP</th>\n",
       "      <th>LongURL</th>\n",
       "      <th>ShortURL</th>\n",
       "      <th>Symbol@</th>\n",
       "      <th>Redirecting//</th>\n",
       "      <th>PrefixSuffix-</th>\n",
       "      <th>SubDomains</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DomainRegLen</th>\n",
       "      <th>...</th>\n",
       "      <th>UsingPopupWindow</th>\n",
       "      <th>IframeRedirection</th>\n",
       "      <th>AgeofDomain</th>\n",
       "      <th>DNSRecording</th>\n",
       "      <th>WebsiteTraffic</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>GoogleIndex</th>\n",
       "      <th>LinksPointingToPage</th>\n",
       "      <th>StatsReport</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  UsingIP  LongURL  ShortURL  Symbol@  Redirecting//  PrefixSuffix-  \\\n",
       "0      0        1        1         1        1              1             -1   \n",
       "1      1        1        0         1        1              1             -1   \n",
       "2      2        1        0         1        1              1             -1   \n",
       "3      3        1        0        -1        1              1             -1   \n",
       "4      4       -1        0        -1        1             -1             -1   \n",
       "\n",
       "   SubDomains  HTTPS  DomainRegLen  ...  UsingPopupWindow  IframeRedirection  \\\n",
       "0           0      1            -1  ...                 1                  1   \n",
       "1          -1     -1            -1  ...                 1                  1   \n",
       "2          -1     -1             1  ...                 1                  1   \n",
       "3           1      1            -1  ...                -1                  1   \n",
       "4           1      1            -1  ...                 1                  1   \n",
       "\n",
       "   AgeofDomain  DNSRecording  WebsiteTraffic  PageRank  GoogleIndex  \\\n",
       "0           -1            -1               0        -1            1   \n",
       "1            1            -1               1        -1            1   \n",
       "2           -1            -1               1        -1            1   \n",
       "3           -1            -1               0        -1            1   \n",
       "4            1             1               1        -1            1   \n",
       "\n",
       "   LinksPointingToPage  StatsReport  class  \n",
       "0                    1            1     -1  \n",
       "1                    0           -1     -1  \n",
       "2                   -1            1     -1  \n",
       "3                    1            1      1  \n",
       "4                   -1           -1      1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domid\\AppData\\Local\\Temp\\ipykernel_9120\\2918722099.py:18: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
      "  dfvino = kagglehub.load_dataset(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DATASET VINO'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  Id  \n",
       "0      9.4        5   0  \n",
       "1      9.8        5   1  \n",
       "2      9.8        5   2  \n",
       "3      9.8        6   3  \n",
       "4      9.4        5   4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domid\\AppData\\Local\\Temp\\ipykernel_9120\\2918722099.py:29: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
      "  dfcancer = kagglehub.load_dataset(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DATASET CANCER'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x.radius_mean</th>\n",
       "      <th>x.texture_mean</th>\n",
       "      <th>x.perimeter_mean</th>\n",
       "      <th>x.area_mean</th>\n",
       "      <th>x.smoothness_mean</th>\n",
       "      <th>x.compactness_mean</th>\n",
       "      <th>x.concavity_mean</th>\n",
       "      <th>x.concave_pts_mean</th>\n",
       "      <th>x.symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>x.texture_worst</th>\n",
       "      <th>x.perimeter_worst</th>\n",
       "      <th>x.area_worst</th>\n",
       "      <th>x.smoothness_worst</th>\n",
       "      <th>x.compactness_worst</th>\n",
       "      <th>x.concavity_worst</th>\n",
       "      <th>x.concave_pts_worst</th>\n",
       "      <th>x.symmetry_worst</th>\n",
       "      <th>x.fractal_dim_worst</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>...</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>...</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>...</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.12970</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  x.radius_mean  x.texture_mean  x.perimeter_mean  x.area_mean  \\\n",
       "0           1         13.540           14.36             87.46        566.3   \n",
       "1           2         13.080           15.71             85.63        520.0   \n",
       "2           3          9.504           12.44             60.34        273.9   \n",
       "3           4         13.030           18.42             82.61        523.8   \n",
       "4           5          8.196           16.84             51.71        201.9   \n",
       "\n",
       "   x.smoothness_mean  x.compactness_mean  x.concavity_mean  \\\n",
       "0            0.09779             0.08129           0.06664   \n",
       "1            0.10750             0.12700           0.04568   \n",
       "2            0.10240             0.06492           0.02956   \n",
       "3            0.08983             0.03766           0.02562   \n",
       "4            0.08600             0.05943           0.01588   \n",
       "\n",
       "   x.concave_pts_mean  x.symmetry_mean  ...  x.texture_worst  \\\n",
       "0            0.047810           0.1885  ...            19.26   \n",
       "1            0.031100           0.1967  ...            20.49   \n",
       "2            0.020760           0.1815  ...            15.66   \n",
       "3            0.029230           0.1467  ...            22.81   \n",
       "4            0.005917           0.1769  ...            21.96   \n",
       "\n",
       "   x.perimeter_worst  x.area_worst  x.smoothness_worst  x.compactness_worst  \\\n",
       "0              99.70         711.2             0.14400              0.17730   \n",
       "1              96.09         630.5             0.13120              0.27760   \n",
       "2              65.13         314.9             0.13240              0.11480   \n",
       "3              84.46         545.9             0.09701              0.04619   \n",
       "4              57.26         242.2             0.12970              0.13570   \n",
       "\n",
       "   x.concavity_worst  x.concave_pts_worst  x.symmetry_worst  \\\n",
       "0            0.23900              0.12880            0.2977   \n",
       "1            0.18900              0.07283            0.3184   \n",
       "2            0.08867              0.06227            0.2450   \n",
       "3            0.04833              0.05013            0.1987   \n",
       "4            0.06880              0.02564            0.3105   \n",
       "\n",
       "   x.fractal_dim_worst  y  \n",
       "0              0.07259  B  \n",
       "1              0.08183  B  \n",
       "2              0.07773  B  \n",
       "3              0.06169  B  \n",
       "4              0.07409  B  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domid\\AppData\\Local\\Temp\\ipykernel_9120\\2918722099.py:41: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
      "  dftemp = kagglehub.load_dataset(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TEMPERATURA ESPAÑA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>rain_days</th>\n",
       "      <th>rain_accum</th>\n",
       "      <th>avg_wind</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diciembre</td>\n",
       "      <td>10ºC</td>\n",
       "      <td>15ºC</td>\n",
       "      <td>6ºC</td>\n",
       "      <td>4 Días</td>\n",
       "      <td>23 mm</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noviembre</td>\n",
       "      <td>13ºC</td>\n",
       "      <td>19ºC</td>\n",
       "      <td>9ºC</td>\n",
       "      <td>5 Días</td>\n",
       "      <td>27 mm</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Octubre</td>\n",
       "      <td>18ºC</td>\n",
       "      <td>24ºC</td>\n",
       "      <td>14ºC</td>\n",
       "      <td>5 Días</td>\n",
       "      <td>27 mm</td>\n",
       "      <td>8</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Septiembre</td>\n",
       "      <td>22ºC</td>\n",
       "      <td>29ºC</td>\n",
       "      <td>17ºC</td>\n",
       "      <td>3 Días</td>\n",
       "      <td>15 mm</td>\n",
       "      <td>8</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agosto</td>\n",
       "      <td>25ºC</td>\n",
       "      <td>32ºC</td>\n",
       "      <td>19ºC</td>\n",
       "      <td>1 Días</td>\n",
       "      <td>3 mm</td>\n",
       "      <td>9</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month avg_temp max_temp min_temp rain_days rain_accum  avg_wind  \\\n",
       "0   Diciembre     10ºC     15ºC      6ºC    4 Días      23 mm        10   \n",
       "1   Noviembre     13ºC     19ºC      9ºC    5 Días      27 mm        10   \n",
       "2     Octubre     18ºC     24ºC     14ºC    5 Días      27 mm         8   \n",
       "3  Septiembre     22ºC     29ºC     17ºC    3 Días      15 mm         8   \n",
       "4      Agosto     25ºC     32ºC     19ºC    1 Días       3 mm         9   \n",
       "\n",
       "    place  \n",
       "0  Murcia  \n",
       "1  Murcia  \n",
       "2  Murcia  \n",
       "3  Murcia  \n",
       "4  Murcia  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# PHISHING URLS\n",
    "phishing_path = \"phishing.csv\"  # Ruta donde deseas guardar el dataset\n",
    "# Cargar la última versión del dataset\n",
    "dfphishing = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,  # Formato que queremos (Pandas)\n",
    "  \"eswarchandt/phishing-website-detector\",  # Nombre del dataset\n",
    "  phishing_path\n",
    ")\n",
    "# Mostrar las primeras 5 filas del dataset phishing\n",
    "display(\"DATASET PHISHING\",dfphishing.head(5))\n",
    "\n",
    "# CALIDAD DEL VINO\n",
    "vino_path = \"WineQT.csv\"  # Ruta donde deseas guardar el dataset\n",
    "# Cargar la última versión del dataset\n",
    "dfvino = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,  # Formato que queremos (Pandas)\n",
    "  \"yasserh/wine-quality-dataset\",  # Nombre del dataset\n",
    "  vino_path\n",
    ")\n",
    "# Mostrar las primeras 5 filas del dataset vino\n",
    "display(\"DATASET VINO\",dfvino.head(5))\n",
    "\n",
    "# CANCER DE MAMA\n",
    "cancer_path = \"brca.csv\"  # Ruta donde deseas guardar el dataset\n",
    "# Cargar la última versión del dataset\n",
    "dfcancer = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,  # Formato que queremos (Pandas)\n",
    "  \"utkarshx27/breast-cancer-wisconsin-diagnostic-dataset\",  # Nombre del dataset\n",
    "  cancer_path\n",
    ")\n",
    "# Mostrar las primeras 5 filas del dataset cancer\n",
    "display(\"DATASET CANCER\",dfcancer.head(5))\n",
    "\n",
    "\n",
    "# TEMPERATURA ESPAÑA\n",
    "temp_path = \"monthly_temperature_spain (1996-2023).csv\"  # Ruta donde deseas guardar el dataset\n",
    "# Cargar la última versión del dataset\n",
    "dftemp = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,  # Formato que queremos (Pandas)\n",
    "  \"alexgczs/monthly-temperature-in-spain-1996-2023\",  # Nombre del dataset\n",
    "  temp_path\n",
    ")\n",
    "# Mostrar las primeras 5 filas del dataset temp españa\n",
    "display(\"TEMPERATURA ESPAÑA\",dftemp.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limpieza de Datasets y resultados sin incluir hiperparámetros\n",
    "###  Preparación previa a la aplicación de los diferentes Algoritmos de Clasificación.\n",
    "### Prueba del modelo sin incluir los hiperparámetros para comparar en futuros apartados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 TEMPERATURA ESPAÑA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info de las columnas:\n",
    "| **Variable**         | **Descripción**                                     |\n",
    "|----------------------|-----------------------------------------------------|\n",
    "| **rain_days**        | Días de lluvia en un mes                           |\n",
    "| **month**            | Mes del año                                        |\n",
    "| **max_temp**         | Temperatura máxima durante el mes                  |\n",
    "| **min_temp**         | Temperatura mínima durante el mes                  |\n",
    "| **rain_accum**       | Acumulación de lluvia en el mes (en mm)            |\n",
    "| **avg_wind**         | Velocidad media del viento durante el mes          |\n",
    "| **avg_temp**         | Temperatura media durante el mes                   |\n",
    "| **place**            | Lugar de la medición de los datos                  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>rain_days</th>\n",
       "      <th>rain_accum</th>\n",
       "      <th>avg_wind</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diciembre</td>\n",
       "      <td>10ºC</td>\n",
       "      <td>15ºC</td>\n",
       "      <td>6ºC</td>\n",
       "      <td>4 Días</td>\n",
       "      <td>23 mm</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noviembre</td>\n",
       "      <td>13ºC</td>\n",
       "      <td>19ºC</td>\n",
       "      <td>9ºC</td>\n",
       "      <td>5 Días</td>\n",
       "      <td>27 mm</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Octubre</td>\n",
       "      <td>18ºC</td>\n",
       "      <td>24ºC</td>\n",
       "      <td>14ºC</td>\n",
       "      <td>5 Días</td>\n",
       "      <td>27 mm</td>\n",
       "      <td>8</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Septiembre</td>\n",
       "      <td>22ºC</td>\n",
       "      <td>29ºC</td>\n",
       "      <td>17ºC</td>\n",
       "      <td>3 Días</td>\n",
       "      <td>15 mm</td>\n",
       "      <td>8</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agosto</td>\n",
       "      <td>25ºC</td>\n",
       "      <td>32ºC</td>\n",
       "      <td>19ºC</td>\n",
       "      <td>1 Días</td>\n",
       "      <td>3 mm</td>\n",
       "      <td>9</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month avg_temp max_temp min_temp rain_days rain_accum  avg_wind  \\\n",
       "0   Diciembre     10ºC     15ºC      6ºC    4 Días      23 mm        10   \n",
       "1   Noviembre     13ºC     19ºC      9ºC    5 Días      27 mm        10   \n",
       "2     Octubre     18ºC     24ºC     14ºC    5 Días      27 mm         8   \n",
       "3  Septiembre     22ºC     29ºC     17ºC    3 Días      15 mm         8   \n",
       "4      Agosto     25ºC     32ºC     19ºC    1 Días       3 mm         9   \n",
       "\n",
       "    place  \n",
       "0  Murcia  \n",
       "1  Murcia  \n",
       "2  Murcia  \n",
       "3  Murcia  \n",
       "4  Murcia  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dftemp.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobamos los nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores nulos por columna:\n",
      "month         0\n",
      "avg_temp      0\n",
      "max_temp      0\n",
      "min_temp      0\n",
      "rain_days     0\n",
      "rain_accum    0\n",
      "avg_wind      0\n",
      "place         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Comprobar los valores nulos por columna\n",
    "nulos_por_columna = dftemp.isnull().sum()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Número de valores nulos por columna:\")\n",
    "print(nulos_por_columna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No tenemos nulos, pero podemos descartar es avg_temp porque se podrá calcular con las demás, las otras serán importante para que nuestro modelo pueda predecir cuántos dias de lluvia habrá en el mes deseado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemp = dftemp.drop(\"avg_temp\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes del encoding, aunque no sea técnicamente obligatorio vamos a convertir a valores numéricos las columnas que en realidad son valores numericos (todas menos mes), aunque también se podria pasar a numérico pero la dejaremos así para que lo haga el Label Encoding mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>rain_days</th>\n",
       "      <th>rain_accum</th>\n",
       "      <th>avg_wind</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diciembre</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noviembre</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Octubre</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Septiembre</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agosto</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  max_temp  min_temp  rain_days  rain_accum  avg_wind   place\n",
       "0   Diciembre      15.0       6.0          4        23.0        10  Murcia\n",
       "1   Noviembre      19.0       9.0          5        27.0        10  Murcia\n",
       "2     Octubre      24.0      14.0          5        27.0         8  Murcia\n",
       "3  Septiembre      29.0      17.0          3        15.0         8  Murcia\n",
       "4      Agosto      32.0      19.0          1         3.0         9  Murcia"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 480 entries, 0 to 479\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   month       480 non-null    object \n",
      " 1   max_temp    480 non-null    float64\n",
      " 2   min_temp    480 non-null    float64\n",
      " 3   rain_days   480 non-null    int64  \n",
      " 4   rain_accum  480 non-null    float64\n",
      " 5   avg_wind    480 non-null    int64  \n",
      " 6   place       480 non-null    object \n",
      "dtypes: float64(3), int64(2), object(2)\n",
      "memory usage: 26.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Convertir las columnas a formato numérico solo si no están ya en el formato adecuado\n",
    "\n",
    "columns_to_convert = [\"max_temp\", \"min_temp\", \"rain_days\", \"rain_accum\"]\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    try:\n",
    "        # Si la columna ya es numérica, el código no hará nada\n",
    "        if \"temp\" in col:  # Eliminar 'ºC' de las columnas de temperatura\n",
    "            if dftemp[col].dtype != float:  # Verificamos si la columna no es de tipo float\n",
    "                dftemp[col] = dftemp[col].str.replace(\"ºC\", \"\").astype(float)\n",
    "        elif \"rain_days\" in col:  # Eliminar ' Días' de la columna de días de lluvia\n",
    "            if dftemp[col].dtype != int:  # Verificamos si la columna no es de tipo int\n",
    "                dftemp[col] = dftemp[col].str.replace(\" Días\", \"\").astype(int)\n",
    "        elif \"rain_accum\" in col:  # Eliminar ' mm' de la columna de acumulación de lluvia\n",
    "            if dftemp[col].dtype != float:  # Verificamos si la columna no es de tipo float\n",
    "                dftemp[col] = dftemp[col].str.replace(\" mm\", \"\").astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al convertir la columna {col}: {e}\")\n",
    "\n",
    "# Verificar el resultado\n",
    "display(dftemp.head())\n",
    "dftemp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para pasar las columnas no numéricas, antes de empezar con las técnicas de escalado de características, vamos a usar One - hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_Agosto</th>\n",
       "      <th>month_Diciembre</th>\n",
       "      <th>month_Enero</th>\n",
       "      <th>month_Febrero</th>\n",
       "      <th>month_Julio</th>\n",
       "      <th>month_Junio</th>\n",
       "      <th>month_Marzo</th>\n",
       "      <th>month_Mayo</th>\n",
       "      <th>month_Noviembre</th>\n",
       "      <th>month_Octubre</th>\n",
       "      <th>...</th>\n",
       "      <th>place_Valladolid</th>\n",
       "      <th>place_Zamora</th>\n",
       "      <th>place_Zaragoza</th>\n",
       "      <th>place_Álava</th>\n",
       "      <th>place_Ávila</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>rain_days</th>\n",
       "      <th>rain_accum</th>\n",
       "      <th>avg_wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_Agosto  month_Diciembre  month_Enero  month_Febrero  month_Julio  \\\n",
       "0           0.0              1.0          0.0            0.0          0.0   \n",
       "1           0.0              0.0          0.0            0.0          0.0   \n",
       "2           0.0              0.0          0.0            0.0          0.0   \n",
       "3           0.0              0.0          0.0            0.0          0.0   \n",
       "4           1.0              0.0          0.0            0.0          0.0   \n",
       "\n",
       "   month_Junio  month_Marzo  month_Mayo  month_Noviembre  month_Octubre  ...  \\\n",
       "0          0.0          0.0         0.0              0.0            0.0  ...   \n",
       "1          0.0          0.0         0.0              1.0            0.0  ...   \n",
       "2          0.0          0.0         0.0              0.0            1.0  ...   \n",
       "3          0.0          0.0         0.0              0.0            0.0  ...   \n",
       "4          0.0          0.0         0.0              0.0            0.0  ...   \n",
       "\n",
       "   place_Valladolid  place_Zamora  place_Zaragoza  place_Álava  place_Ávila  \\\n",
       "0               0.0           0.0             0.0          0.0          0.0   \n",
       "1               0.0           0.0             0.0          0.0          0.0   \n",
       "2               0.0           0.0             0.0          0.0          0.0   \n",
       "3               0.0           0.0             0.0          0.0          0.0   \n",
       "4               0.0           0.0             0.0          0.0          0.0   \n",
       "\n",
       "   max_temp  min_temp  rain_days  rain_accum  avg_wind  \n",
       "0      15.0       6.0          4        23.0        10  \n",
       "1      19.0       9.0          5        27.0        10  \n",
       "2      24.0      14.0          5        27.0         8  \n",
       "3      29.0      17.0          3        15.0         8  \n",
       "4      32.0      19.0          1         3.0         9  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas antes del One-Hot Encoding: 7\n",
      "Número de columnas después del One-Hot Encoding: 55\n"
     ]
    }
   ],
   "source": [
    "# Crear una copia del DataFrame original para no modificar el original\n",
    "dfesp_onehot = dftemp.copy()\n",
    "\n",
    "# Filtrar las columnas categóricas\n",
    "columnas_categoricas_temp = [\"month\", \"place\"]\n",
    "\n",
    "# Instancia de OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Aplicar One-Hot Encoding a las columnas seleccionadas\n",
    "columnas_encoded_temp = one_hot_encoder.fit_transform(dfesp_onehot[columnas_categoricas_temp])\n",
    "\n",
    "# Convertir el resultado a un DataFrame\n",
    "columnas_encoded_df_temp = pd.DataFrame(columnas_encoded_temp, columns=one_hot_encoder.get_feature_names_out(columnas_categoricas_temp))\n",
    "\n",
    "# Ahora concatenamos las columnas numéricas (las que no son categóricas) al DataFrame resultante\n",
    "columnas_numéricas = dfesp_onehot.drop(columns=columnas_categoricas_temp)\n",
    "columnas_encoded_df_temp = pd.concat([columnas_encoded_df_temp, columnas_numéricas], axis=1)\n",
    "\n",
    "# Mostrar el resultado\n",
    "display(columnas_encoded_df_temp.head())\n",
    "\n",
    "# Número de columnas antes y después del One-Hot Encoding\n",
    "print(\"Número de columnas antes del One-Hot Encoding:\", dfesp_onehot.shape[1])\n",
    "print(\"Número de columnas después del One-Hot Encoding:\", columnas_encoded_df_temp.shape[1])\n",
    "#columnas_encoded_df_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora vamos a normalizar los datos para dejarlo todo listo para cuando apliquemos los diferentes algoritmos de clasificación, en este caso vamos a usar Normalización (Min-Max) porque es la opción más adecuada, ya que ajusta las escalas sin alterar la forma de los datos y mantiene la comparabilidad entre las variables. Además, no afecta a los valores de rain_days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_Agosto</th>\n",
       "      <th>month_Diciembre</th>\n",
       "      <th>month_Enero</th>\n",
       "      <th>month_Febrero</th>\n",
       "      <th>month_Julio</th>\n",
       "      <th>month_Junio</th>\n",
       "      <th>month_Marzo</th>\n",
       "      <th>month_Mayo</th>\n",
       "      <th>month_Noviembre</th>\n",
       "      <th>month_Octubre</th>\n",
       "      <th>...</th>\n",
       "      <th>place_Valladolid</th>\n",
       "      <th>place_Zamora</th>\n",
       "      <th>place_Zaragoza</th>\n",
       "      <th>place_Álava</th>\n",
       "      <th>place_Ávila</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>rain_accum</th>\n",
       "      <th>avg_wind</th>\n",
       "      <th>rain_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71875</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_Agosto  month_Diciembre  month_Enero  month_Febrero  month_Julio  \\\n",
       "0           0.0              1.0          0.0            0.0          0.0   \n",
       "1           0.0              0.0          0.0            0.0          0.0   \n",
       "2           0.0              0.0          0.0            0.0          0.0   \n",
       "3           0.0              0.0          0.0            0.0          0.0   \n",
       "4           1.0              0.0          0.0            0.0          0.0   \n",
       "\n",
       "   month_Junio  month_Marzo  month_Mayo  month_Noviembre  month_Octubre  ...  \\\n",
       "0          0.0          0.0         0.0              0.0            0.0  ...   \n",
       "1          0.0          0.0         0.0              1.0            0.0  ...   \n",
       "2          0.0          0.0         0.0              0.0            1.0  ...   \n",
       "3          0.0          0.0         0.0              0.0            0.0  ...   \n",
       "4          0.0          0.0         0.0              0.0            0.0  ...   \n",
       "\n",
       "   place_Valladolid  place_Zamora  place_Zaragoza  place_Álava  place_Ávila  \\\n",
       "0               0.0           0.0             0.0          0.0          0.0   \n",
       "1               0.0           0.0             0.0          0.0          0.0   \n",
       "2               0.0           0.0             0.0          0.0          0.0   \n",
       "3               0.0           0.0             0.0          0.0          0.0   \n",
       "4               0.0           0.0             0.0          0.0          0.0   \n",
       "\n",
       "   max_temp  min_temp  rain_accum  avg_wind  rain_days  \n",
       "0   0.28125  0.333333    0.106481  0.285714          4  \n",
       "1   0.40625  0.458333    0.125000  0.285714          5  \n",
       "2   0.56250  0.666667    0.125000  0.142857          5  \n",
       "3   0.71875  0.791667    0.069444  0.142857          3  \n",
       "4   0.81250  0.875000    0.013889  0.214286          1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copia del dataframe para aplicar la normalización\n",
    "df_esplimpio = columnas_encoded_df_temp.copy()\n",
    "\n",
    "# Lista de las columnas numéricas para las que haremos la normalización\n",
    "columnas_numericas = df_esplimpio.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Excluimos la columna objetivo (quality)\n",
    "columnas_numericas = columnas_numericas.drop('rain_days')\n",
    "\n",
    "# Aplicamos MinMaxScaler de sklearn para normalizar las columnas numéricas\n",
    "min_max = MinMaxScaler()\n",
    "\n",
    "# Aplicamos el ajuste y la transformación a las columnas numéricas\n",
    "dfesp_limpio = pd.DataFrame(min_max.fit_transform(df_esplimpio[columnas_numericas]), columns=columnas_numericas)\n",
    "\n",
    "# Copiamos la columna \"quality\" (sin normalizar) a la tabla final\n",
    "dfesp_limpio['rain_days'] = df_esplimpio['rain_days']\n",
    "\n",
    "display(dfesp_limpio.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 PHISHING URLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info de las columnas:\n",
    "| **Variable**             | **Descripción**                                 | **Posibles Valores**                |\n",
    "|--------------------------|-------------------------------------------------|-------------------------------------|\n",
    "| **Index**                | Número de índice                                | Número de índice (0, 1, 2, ...)     |\n",
    "| **UsingIP**              | Uso de IP (1: Usado, -1: No usado)              | { -1, 1 }                          |\n",
    "| **LongURL**              | Longitud de URL (1: Larga, -1: Corta)           | { 1, 0, -1 }                       |\n",
    "| **ShortURL**             | URL corta (1: Usada, -1: No usada)              | { 1, -1 }                          |\n",
    "| **Symbol@**              | Uso del símbolo '@' en la URL                  | { 1, -1 }                          |\n",
    "| **Redirecting//**        | URL redireccionada (1: Redirige, -1: No redirige)| { -1, 1 }                          |\n",
    "| **PrefixSuffix-**        | Prefijo y sufijo en la URL (1: Tiene, -1: No tiene) | { -1, 1 }                          |\n",
    "| **HTTPS**                | Uso de HTTPS (1: Usado, 0: No usado)            | { -1, 1, 0 }                       |\n",
    "| **DomainRegLen**         | Longitud del registro de dominio                | { -1, 1 }                          |\n",
    "| **Favicon**              | Presencia de favicon                            | { 1, -1 }                          |\n",
    "| **NonStdPort**           | Puerto no estándar (1: Usado, -1: No usado)      | { 1, -1 }                          |\n",
    "| **HTTPSDomainURL**       | HTTPS en dominio (1: Usado, -1: No usado)        | { -1, 1 }                          |\n",
    "| **RequestURL**           | URL de solicitud                                | { 1, -1 }                          |\n",
    "| **AnchorURL**            | URL de anclaje (1: Existe, -1: No existe, 0: No hay) | { -1, 0, 1 }                       |\n",
    "| **LinksInScriptTags**    | Enlaces dentro de etiquetas `<script>`          | { 1, -1, 0 }                       |\n",
    "| **ServerFormHandler**    | Manejo de formularios en servidor               | { -1, 1, 0 }                       |\n",
    "| **InfoEmail**            | Información en el correo electrónico (1: Tiene, -1: No tiene) | { -1, 1 }                          |\n",
    "| **AbnormalURL**          | URL anómala                                     | { -1, 1 }                          |\n",
    "| **WebsiteForwarding**    | Redirección de sitio web (1: Redirige, 0: No redirige) | { 0, 1 }                           |\n",
    "| **StatusBarCust**        | Personalización de la barra de estado           | { 1, -1 }                          |\n",
    "| **DisableRightClick**    | Desactivar clic derecho (1: Desactivado, -1: No desactivado) | { 1, -1 }                          |\n",
    "| **UsingPopupWindow**     | Uso de ventanas emergentes (1: Usado, -1: No usado) | { 1, -1 }                          |\n",
    "| **IframeRedirection**    | Redirección mediante iframe (1: Usado, -1: No usado) | { 1, -1 }                          |\n",
    "| **AgeofDomain**          | Edad del dominio (1: Viejo, -1: Nuevo)          | { -1, 1 }                          |\n",
    "| **DNSRecording**         | Registro DNS (1: Tiene, -1: No tiene)           | { -1, 1 }                          |\n",
    "| **WebsiteTraffic**       | Tráfico del sitio web (1: Alto, -1: Bajo, 0: No hay) | { -1, 0, 1 }                       |\n",
    "| **PageRank**             | Rango de página de Google (1: Alto, -1: Bajo)   | { -1, 1 }                          |\n",
    "| **GoogleIndex**          | Indexado en Google (1: Indexado, -1: No indexado) | { 1, -1 }                          |\n",
    "| **LinksPointingToPage**  | Enlaces apuntando a la página (1: Varios, 0: Ninguno, -1: Pocos) | { 1, 0, -1 }                       |\n",
    "| **StatsReport**          | Informe de estadísticas (1: Tiene, -1: No tiene) | { -1, 1 }                          |\n",
    "| **class**                | Clase (1: Website normal, -1: Phishing)        | { -1, 1 }                          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>UsingIP</th>\n",
       "      <th>LongURL</th>\n",
       "      <th>ShortURL</th>\n",
       "      <th>Symbol@</th>\n",
       "      <th>Redirecting//</th>\n",
       "      <th>PrefixSuffix-</th>\n",
       "      <th>SubDomains</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DomainRegLen</th>\n",
       "      <th>...</th>\n",
       "      <th>UsingPopupWindow</th>\n",
       "      <th>IframeRedirection</th>\n",
       "      <th>AgeofDomain</th>\n",
       "      <th>DNSRecording</th>\n",
       "      <th>WebsiteTraffic</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>GoogleIndex</th>\n",
       "      <th>LinksPointingToPage</th>\n",
       "      <th>StatsReport</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  UsingIP  LongURL  ShortURL  Symbol@  Redirecting//  PrefixSuffix-  \\\n",
       "0      0        1        1         1        1              1             -1   \n",
       "1      1        1        0         1        1              1             -1   \n",
       "2      2        1        0         1        1              1             -1   \n",
       "3      3        1        0        -1        1              1             -1   \n",
       "4      4       -1        0        -1        1             -1             -1   \n",
       "\n",
       "   SubDomains  HTTPS  DomainRegLen  ...  UsingPopupWindow  IframeRedirection  \\\n",
       "0           0      1            -1  ...                 1                  1   \n",
       "1          -1     -1            -1  ...                 1                  1   \n",
       "2          -1     -1             1  ...                 1                  1   \n",
       "3           1      1            -1  ...                -1                  1   \n",
       "4           1      1            -1  ...                 1                  1   \n",
       "\n",
       "   AgeofDomain  DNSRecording  WebsiteTraffic  PageRank  GoogleIndex  \\\n",
       "0           -1            -1               0        -1            1   \n",
       "1            1            -1               1        -1            1   \n",
       "2           -1            -1               1        -1            1   \n",
       "3           -1            -1               0        -1            1   \n",
       "4            1             1               1        -1            1   \n",
       "\n",
       "   LinksPointingToPage  StatsReport  class  \n",
       "0                    1            1     -1  \n",
       "1                    0           -1     -1  \n",
       "2                   -1            1     -1  \n",
       "3                    1            1      1  \n",
       "4                   -1           -1      1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11054 entries, 0 to 11053\n",
      "Data columns (total 32 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   Index                11054 non-null  int64\n",
      " 1   UsingIP              11054 non-null  int64\n",
      " 2   LongURL              11054 non-null  int64\n",
      " 3   ShortURL             11054 non-null  int64\n",
      " 4   Symbol@              11054 non-null  int64\n",
      " 5   Redirecting//        11054 non-null  int64\n",
      " 6   PrefixSuffix-        11054 non-null  int64\n",
      " 7   SubDomains           11054 non-null  int64\n",
      " 8   HTTPS                11054 non-null  int64\n",
      " 9   DomainRegLen         11054 non-null  int64\n",
      " 10  Favicon              11054 non-null  int64\n",
      " 11  NonStdPort           11054 non-null  int64\n",
      " 12  HTTPSDomainURL       11054 non-null  int64\n",
      " 13  RequestURL           11054 non-null  int64\n",
      " 14  AnchorURL            11054 non-null  int64\n",
      " 15  LinksInScriptTags    11054 non-null  int64\n",
      " 16  ServerFormHandler    11054 non-null  int64\n",
      " 17  InfoEmail            11054 non-null  int64\n",
      " 18  AbnormalURL          11054 non-null  int64\n",
      " 19  WebsiteForwarding    11054 non-null  int64\n",
      " 20  StatusBarCust        11054 non-null  int64\n",
      " 21  DisableRightClick    11054 non-null  int64\n",
      " 22  UsingPopupWindow     11054 non-null  int64\n",
      " 23  IframeRedirection    11054 non-null  int64\n",
      " 24  AgeofDomain          11054 non-null  int64\n",
      " 25  DNSRecording         11054 non-null  int64\n",
      " 26  WebsiteTraffic       11054 non-null  int64\n",
      " 27  PageRank             11054 non-null  int64\n",
      " 28  GoogleIndex          11054 non-null  int64\n",
      " 29  LinksPointingToPage  11054 non-null  int64\n",
      " 30  StatsReport          11054 non-null  int64\n",
      " 31  class                11054 non-null  int64\n",
      "dtypes: int64(32)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "display(dfphishing.head(5))\n",
    "dfphishing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como podemos ver, están todos los datos ya normalizados y no hay que hacer ninguna transformación, son todas de tipo int, lo unico que se me puede ocurrir es borrar los index, no lo vamos a necesitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfphishing_limpio = dfphishing.copy()\n",
    "dfphishing_limpio = dfphishing_limpio.drop(['Index'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 CALIDAD DEL VINO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info de las columnas:\n",
    "| **Variable**             | **Descripción**                                        | **Rango de Valores**            |\n",
    "|--------------------------|--------------------------------------------------------|---------------------------------|\n",
    "| **fixed acidity**         | Acidez fija en el vino                                  | 4.6 a 15.9                     |\n",
    "| **volatile acidity**      | Acidez volátil en el vino                              | 0.12 a 1.58                    |\n",
    "| **citric acid**           | Ácido cítrico en el vino                               | 0 a 1                          |\n",
    "| **residual sugar**        | Azúcar residual en el vino                             | 0.9 a 15.5                     |\n",
    "| **chlorides**             | Cloruros en el vino                                   | 0.01 a 0.61                    |\n",
    "| **free sulfur dioxide**   | Dióxido de azufre libre en el vino                     | 1 a 68                         |\n",
    "| **total sulfur dioxide**  | Dióxido de azufre total en el vino                     | 6 a 289                        |\n",
    "| **density**               | Densidad del vino                                      | 0.99 a 1                       |\n",
    "| **pH**                    | Nivel de pH del vino                                   | 2.74 a 4.01                    |\n",
    "| **sulphates**             | Sulfatos en el vino                                    | 0.33 a 2                       |\n",
    "| **alcohol**               | Contenido de alcohol en el vino                        | 8.4 a 14.9                     |\n",
    "| **quality**               | Calidad del vino (1-10, 5 o menor es mala calidad)     | 3 a 8 (buena calidad si > 5)    |\n",
    "| **Id**                    | Identificación del vino                                | 0 a 1597                       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  Id  \n",
       "0      9.4        5   0  \n",
       "1      9.8        5   1  \n",
       "2      9.8        5   2  \n",
       "3      9.8        6   3  \n",
       "4      9.4        5   4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1143 entries, 0 to 1142\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1143 non-null   float64\n",
      " 1   volatile acidity      1143 non-null   float64\n",
      " 2   citric acid           1143 non-null   float64\n",
      " 3   residual sugar        1143 non-null   float64\n",
      " 4   chlorides             1143 non-null   float64\n",
      " 5   free sulfur dioxide   1143 non-null   float64\n",
      " 6   total sulfur dioxide  1143 non-null   float64\n",
      " 7   density               1143 non-null   float64\n",
      " 8   pH                    1143 non-null   float64\n",
      " 9   sulphates             1143 non-null   float64\n",
      " 10  alcohol               1143 non-null   float64\n",
      " 11  quality               1143 non-null   int64  \n",
      " 12  Id                    1143 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 116.2 KB\n"
     ]
    }
   ],
   "source": [
    "display(dfvino.head(5))\n",
    "dfvino.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teniendo en cuenta que los datos parecen que necesitan poca transformación, primero vamos a eliminar la columna id y transformar la columna quality que es nuestra variable objetiva a (si es 5 o menor es de mala calidad y si es mayor de 5 es buena calidad).\n",
    "###  0 para mala calidad e 1 para buena calidad quedaría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        0  \n",
       "1      9.8        0  \n",
       "2      9.8        0  \n",
       "3      9.8        1  \n",
       "4      9.4        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfvino = dfvino.drop(['Id'],axis = 1)\n",
    "dfvino['quality'] = dfvino['quality'].apply(lambda x: 1 if x > 5 else 0)\n",
    "display(dfvino.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a escalar las variables categoricas usando StandardScaler porque las características, como la acidez o alcohol, tienen rangos diferentes. Estandarizarlas asegura que los algoritmos como SVM o kNN no se vean afectados por estas diferencias y aprendan de manera más efectiva. Además, es más robusto frente a valores atípicos que la normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.521580</td>\n",
       "      <td>0.939332</td>\n",
       "      <td>-1.365027</td>\n",
       "      <td>-0.466421</td>\n",
       "      <td>-0.231395</td>\n",
       "      <td>-0.450467</td>\n",
       "      <td>-0.363610</td>\n",
       "      <td>0.555854</td>\n",
       "      <td>1.270695</td>\n",
       "      <td>-0.573658</td>\n",
       "      <td>-0.963382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.292593</td>\n",
       "      <td>1.941813</td>\n",
       "      <td>-1.365027</td>\n",
       "      <td>0.050060</td>\n",
       "      <td>0.234247</td>\n",
       "      <td>0.915920</td>\n",
       "      <td>0.643477</td>\n",
       "      <td>0.036165</td>\n",
       "      <td>-0.708928</td>\n",
       "      <td>0.130881</td>\n",
       "      <td>-0.593601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.292593</td>\n",
       "      <td>1.273492</td>\n",
       "      <td>-1.161568</td>\n",
       "      <td>-0.171289</td>\n",
       "      <td>0.107253</td>\n",
       "      <td>-0.060071</td>\n",
       "      <td>0.246745</td>\n",
       "      <td>0.140103</td>\n",
       "      <td>-0.325775</td>\n",
       "      <td>-0.045254</td>\n",
       "      <td>-0.593601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.653789</td>\n",
       "      <td>-1.399789</td>\n",
       "      <td>1.483400</td>\n",
       "      <td>-0.466421</td>\n",
       "      <td>-0.252560</td>\n",
       "      <td>0.135127</td>\n",
       "      <td>0.429852</td>\n",
       "      <td>0.659792</td>\n",
       "      <td>-0.964363</td>\n",
       "      <td>-0.456235</td>\n",
       "      <td>-0.593601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.521580</td>\n",
       "      <td>0.939332</td>\n",
       "      <td>-1.365027</td>\n",
       "      <td>-0.466421</td>\n",
       "      <td>-0.231395</td>\n",
       "      <td>-0.450467</td>\n",
       "      <td>-0.363610</td>\n",
       "      <td>0.555854</td>\n",
       "      <td>1.270695</td>\n",
       "      <td>-0.573658</td>\n",
       "      <td>-0.963382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0      -0.521580          0.939332    -1.365027       -0.466421  -0.231395   \n",
       "1      -0.292593          1.941813    -1.365027        0.050060   0.234247   \n",
       "2      -0.292593          1.273492    -1.161568       -0.171289   0.107253   \n",
       "3       1.653789         -1.399789     1.483400       -0.466421  -0.252560   \n",
       "4      -0.521580          0.939332    -1.365027       -0.466421  -0.231395   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0            -0.450467             -0.363610  0.555854  1.270695  -0.573658   \n",
       "1             0.915920              0.643477  0.036165 -0.708928   0.130881   \n",
       "2            -0.060071              0.246745  0.140103 -0.325775  -0.045254   \n",
       "3             0.135127              0.429852  0.659792 -0.964363  -0.456235   \n",
       "4            -0.450467             -0.363610  0.555854  1.270695  -0.573658   \n",
       "\n",
       "    alcohol  quality  \n",
       "0 -0.963382        0  \n",
       "1 -0.593601        0  \n",
       "2 -0.593601        0  \n",
       "3 -0.593601        1  \n",
       "4 -0.963382        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el objeto escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copiamos el dataframe para no modificar el original\n",
    "dfvino_limpio = dfvino.copy()\n",
    "\n",
    "# Estandarizar las columnas numéricas (exceptuando 'quality')\n",
    "dfvino_limpio = dfvino.drop(columns=['quality'])\n",
    "dfvino_limpio = scaler.fit_transform(dfvino_limpio)\n",
    "\n",
    "# Convertir de nuevo a un DataFrame\n",
    "dfvino_limpio = pd.DataFrame(dfvino_limpio, columns=dfvino.drop(columns=['quality']).columns)\n",
    "\n",
    "# Incluir 'quality' nuevamente al dataframe\n",
    "dfvino_limpio['quality'] = dfvino['quality']\n",
    "display(dfvino_limpio.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 DIAGNOSTICO DE CANCER DE MAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info de las columnas:\n",
    "| Columnas                      | Min  | Max  | Descripción |\n",
    "|------------------------------|------|------|-------------|\n",
    "| x.radius_mean                 | 6.98 | 28.1 | Radio medio de las células |\n",
    "| x.texture_mean                | 9.71 | 39.3 | Textura media de las células |\n",
    "| x.perimeter_mean              | 43.8 | 189  | Perímetro medio de las células |\n",
    "| x.area_mean                   | 144  | 2.5k | Área media de las células |\n",
    "| x.smoothness_mean             | 0.05 | 0.16 | Suavidad media de las células |\n",
    "| x.compactness_mean            | 0.02 | 0.35 | Compactación media de las células |\n",
    "| x.concavity_mean              | 0    | 0.43 | Concavidad media de las células |\n",
    "| x.concave_pts_mean            | 0    | 0.2  | Puntos cóncavos medios en las células |\n",
    "| x.symmetry_mean               | 0.11 | 0.3  | Simetría media de las células |\n",
    "| x.fractal_dim_mean            | 0.05 | 0.1  | Dimensión fractal media de las células |\n",
    "| x.radius_se                   | 0.11 | 2.87 | Error estándar del radio |\n",
    "| x.texture_se                  | 0.36 | 4.88 | Error estándar de la textura |\n",
    "| x.perimeter_se                | 0.76 | 22   | Error estándar del perímetro |\n",
    "| x.area_se                     | 6.8  | 542  | Error estándar del área |\n",
    "| x.smoothness_se               | 0    | 0.03 | Error estándar de la suavidad |\n",
    "| x.compactness_se              | 0    | 0.14 | Error estándar de la compactación |\n",
    "| x.concavity_se                | 0    | 0.4  | Error estándar de la concavidad |\n",
    "| x.concave_pts_se              | 0    | 0.05 | Error estándar de los puntos cóncavos |\n",
    "| x.symmetry_se                 | 0.01 | 0.08 | Error estándar de la simetría |\n",
    "| x.fractal_dim_se              | 0    | 0.03 | Error estándar de la dimensión fractal |\n",
    "| x.radius_worst                | 7.93 | 36   | Radio peor (más grande) de las células |\n",
    "| x.texture_worst               | 12   | 49.5 | Textura peor de las células |\n",
    "| x.perimeter_worst             | 50.4 | 251  | Perímetro peor de las células |\n",
    "| x.area_worst                  | 185  | 4.25k| Área peor de las células |\n",
    "| x.smoothness_worst            | 0.07 | 0.22 | Suavidad peor de las células |\n",
    "| x.compactness_worst           | 0.03 | 1.06 | Compactación peor de las células |\n",
    "| x.concavity_worst             | 0    | 1.25 | Concavidad peor de las células |\n",
    "| x.concave_pts_worst           | 0    | 0.29 | Puntos cóncavos peores en las células |\n",
    "| x.symmetry_worst              | 0.16 | 0.66 | Simetría peor de las células |\n",
    "| x.fractal_dim_worst           | 0.06 | 0.21 | Dimensión fractal peor de las células |\n",
    "| y (variable objetiva)                 | B (63%) | M (37%) | Diagnóstico: B = benigno, M = maligno |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x.radius_mean</th>\n",
       "      <th>x.texture_mean</th>\n",
       "      <th>x.perimeter_mean</th>\n",
       "      <th>x.area_mean</th>\n",
       "      <th>x.smoothness_mean</th>\n",
       "      <th>x.compactness_mean</th>\n",
       "      <th>x.concavity_mean</th>\n",
       "      <th>x.concave_pts_mean</th>\n",
       "      <th>x.symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>x.texture_worst</th>\n",
       "      <th>x.perimeter_worst</th>\n",
       "      <th>x.area_worst</th>\n",
       "      <th>x.smoothness_worst</th>\n",
       "      <th>x.compactness_worst</th>\n",
       "      <th>x.concavity_worst</th>\n",
       "      <th>x.concave_pts_worst</th>\n",
       "      <th>x.symmetry_worst</th>\n",
       "      <th>x.fractal_dim_worst</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>...</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>...</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>...</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.12970</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  x.radius_mean  x.texture_mean  x.perimeter_mean  x.area_mean  \\\n",
       "0           1         13.540           14.36             87.46        566.3   \n",
       "1           2         13.080           15.71             85.63        520.0   \n",
       "2           3          9.504           12.44             60.34        273.9   \n",
       "3           4         13.030           18.42             82.61        523.8   \n",
       "4           5          8.196           16.84             51.71        201.9   \n",
       "\n",
       "   x.smoothness_mean  x.compactness_mean  x.concavity_mean  \\\n",
       "0            0.09779             0.08129           0.06664   \n",
       "1            0.10750             0.12700           0.04568   \n",
       "2            0.10240             0.06492           0.02956   \n",
       "3            0.08983             0.03766           0.02562   \n",
       "4            0.08600             0.05943           0.01588   \n",
       "\n",
       "   x.concave_pts_mean  x.symmetry_mean  ...  x.texture_worst  \\\n",
       "0            0.047810           0.1885  ...            19.26   \n",
       "1            0.031100           0.1967  ...            20.49   \n",
       "2            0.020760           0.1815  ...            15.66   \n",
       "3            0.029230           0.1467  ...            22.81   \n",
       "4            0.005917           0.1769  ...            21.96   \n",
       "\n",
       "   x.perimeter_worst  x.area_worst  x.smoothness_worst  x.compactness_worst  \\\n",
       "0              99.70         711.2             0.14400              0.17730   \n",
       "1              96.09         630.5             0.13120              0.27760   \n",
       "2              65.13         314.9             0.13240              0.11480   \n",
       "3              84.46         545.9             0.09701              0.04619   \n",
       "4              57.26         242.2             0.12970              0.13570   \n",
       "\n",
       "   x.concavity_worst  x.concave_pts_worst  x.symmetry_worst  \\\n",
       "0            0.23900              0.12880            0.2977   \n",
       "1            0.18900              0.07283            0.3184   \n",
       "2            0.08867              0.06227            0.2450   \n",
       "3            0.04833              0.05013            0.1987   \n",
       "4            0.06880              0.02564            0.3105   \n",
       "\n",
       "   x.fractal_dim_worst  y  \n",
       "0              0.07259  B  \n",
       "1              0.08183  B  \n",
       "2              0.07773  B  \n",
       "3              0.06169  B  \n",
       "4              0.07409  B  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           569 non-null    int64  \n",
      " 1   x.radius_mean        569 non-null    float64\n",
      " 2   x.texture_mean       569 non-null    float64\n",
      " 3   x.perimeter_mean     569 non-null    float64\n",
      " 4   x.area_mean          569 non-null    float64\n",
      " 5   x.smoothness_mean    569 non-null    float64\n",
      " 6   x.compactness_mean   569 non-null    float64\n",
      " 7   x.concavity_mean     569 non-null    float64\n",
      " 8   x.concave_pts_mean   569 non-null    float64\n",
      " 9   x.symmetry_mean      569 non-null    float64\n",
      " 10  x.fractal_dim_mean   569 non-null    float64\n",
      " 11  x.radius_se          569 non-null    float64\n",
      " 12  x.texture_se         569 non-null    float64\n",
      " 13  x.perimeter_se       569 non-null    float64\n",
      " 14  x.area_se            569 non-null    float64\n",
      " 15  x.smoothness_se      569 non-null    float64\n",
      " 16  x.compactness_se     569 non-null    float64\n",
      " 17  x.concavity_se       569 non-null    float64\n",
      " 18  x.concave_pts_se     569 non-null    float64\n",
      " 19  x.symmetry_se        569 non-null    float64\n",
      " 20  x.fractal_dim_se     569 non-null    float64\n",
      " 21  x.radius_worst       569 non-null    float64\n",
      " 22  x.texture_worst      569 non-null    float64\n",
      " 23  x.perimeter_worst    569 non-null    float64\n",
      " 24  x.area_worst         569 non-null    float64\n",
      " 25  x.smoothness_worst   569 non-null    float64\n",
      " 26  x.compactness_worst  569 non-null    float64\n",
      " 27  x.concavity_worst    569 non-null    float64\n",
      " 28  x.concave_pts_worst  569 non-null    float64\n",
      " 29  x.symmetry_worst     569 non-null    float64\n",
      " 30  x.fractal_dim_worst  569 non-null    float64\n",
      " 31  y                    569 non-null    object \n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "display(dfcancer.head(5))\n",
    "dfcancer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero para tenerlo todo numérico, vamos a pasar la variable objetivo a numérico cuando el diagnóstico es B será 0 y M = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Copiamos el dataframe para no modificar el original\n",
    "dfcancer_limpio = dfcancer.copy()\n",
    "dfcancer_limpio['y'] = dfcancer_limpio['y'].map({'B': 0, 'M': 1})\n",
    "display(dfcancer_limpio['y'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobamos que no hayan valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores nulos por columna:\n",
      "Unnamed: 0             0\n",
      "x.radius_mean          0\n",
      "x.texture_mean         0\n",
      "x.perimeter_mean       0\n",
      "x.area_mean            0\n",
      "x.smoothness_mean      0\n",
      "x.compactness_mean     0\n",
      "x.concavity_mean       0\n",
      "x.concave_pts_mean     0\n",
      "x.symmetry_mean        0\n",
      "x.fractal_dim_mean     0\n",
      "x.radius_se            0\n",
      "x.texture_se           0\n",
      "x.perimeter_se         0\n",
      "x.area_se              0\n",
      "x.smoothness_se        0\n",
      "x.compactness_se       0\n",
      "x.concavity_se         0\n",
      "x.concave_pts_se       0\n",
      "x.symmetry_se          0\n",
      "x.fractal_dim_se       0\n",
      "x.radius_worst         0\n",
      "x.texture_worst        0\n",
      "x.perimeter_worst      0\n",
      "x.area_worst           0\n",
      "x.smoothness_worst     0\n",
      "x.compactness_worst    0\n",
      "x.concavity_worst      0\n",
      "x.concave_pts_worst    0\n",
      "x.symmetry_worst       0\n",
      "x.fractal_dim_worst    0\n",
      "y                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Comprobar los valores nulos por columna\n",
    "nulos_cancer_xcolumna = dfcancer_limpio.isnull().sum()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Número de valores nulos por columna:\")\n",
    "print(nulos_cancer_xcolumna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parece que no hay nulos, vamos a borrar la primera columna que nos aparece como Unnamed: 0 que viendola arriba en los head mostrados, parece ser como una especie de índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Borramos Unnamed: 0\n",
    "dfcancer_limpio = dfcancer_limpio.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora vamos con la normalización de los datos utilizando StandardScaler porque escala las características para que tengan una media de 0 y una desviación estándar de 1, lo que mejora la convergencia de algoritmos como la regresión logística o máquinas de soporte vectorial, que son sensibles a la escala de los datos. Esto garantiza que todas las variables contribuyan de manera equitativa al modelo, porque siendo sincero no sabría a que variable tendría que centrarme más para darle más peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x.radius_mean</th>\n",
       "      <th>x.texture_mean</th>\n",
       "      <th>x.perimeter_mean</th>\n",
       "      <th>x.area_mean</th>\n",
       "      <th>x.smoothness_mean</th>\n",
       "      <th>x.compactness_mean</th>\n",
       "      <th>x.concavity_mean</th>\n",
       "      <th>x.concave_pts_mean</th>\n",
       "      <th>x.symmetry_mean</th>\n",
       "      <th>x.fractal_dim_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>x.texture_worst</th>\n",
       "      <th>x.perimeter_worst</th>\n",
       "      <th>x.area_worst</th>\n",
       "      <th>x.smoothness_worst</th>\n",
       "      <th>x.compactness_worst</th>\n",
       "      <th>x.concavity_worst</th>\n",
       "      <th>x.concave_pts_worst</th>\n",
       "      <th>x.symmetry_worst</th>\n",
       "      <th>x.fractal_dim_worst</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.166799</td>\n",
       "      <td>-1.147162</td>\n",
       "      <td>-0.185728</td>\n",
       "      <td>-0.251957</td>\n",
       "      <td>0.101747</td>\n",
       "      <td>-0.436850</td>\n",
       "      <td>-0.278210</td>\n",
       "      <td>-0.028609</td>\n",
       "      <td>0.267911</td>\n",
       "      <td>-0.728310</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.045005</td>\n",
       "      <td>-0.225217</td>\n",
       "      <td>-0.297761</td>\n",
       "      <td>0.509873</td>\n",
       "      <td>-0.489605</td>\n",
       "      <td>-0.159223</td>\n",
       "      <td>0.216123</td>\n",
       "      <td>0.123347</td>\n",
       "      <td>-0.629292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.297446</td>\n",
       "      <td>-0.833008</td>\n",
       "      <td>-0.261106</td>\n",
       "      <td>-0.383638</td>\n",
       "      <td>0.792763</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>-0.541362</td>\n",
       "      <td>-0.459627</td>\n",
       "      <td>0.567289</td>\n",
       "      <td>0.753087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.844707</td>\n",
       "      <td>-0.332744</td>\n",
       "      <td>-0.439624</td>\n",
       "      <td>-0.051226</td>\n",
       "      <td>0.148443</td>\n",
       "      <td>-0.399099</td>\n",
       "      <td>-0.636110</td>\n",
       "      <td>0.458227</td>\n",
       "      <td>-0.117250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.313080</td>\n",
       "      <td>-1.593959</td>\n",
       "      <td>-1.302806</td>\n",
       "      <td>-1.083572</td>\n",
       "      <td>0.429819</td>\n",
       "      <td>-0.747086</td>\n",
       "      <td>-0.743748</td>\n",
       "      <td>-0.726337</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>0.886341</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.631243</td>\n",
       "      <td>-1.254913</td>\n",
       "      <td>-0.994422</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>-0.887193</td>\n",
       "      <td>-0.880434</td>\n",
       "      <td>-0.796903</td>\n",
       "      <td>-0.729224</td>\n",
       "      <td>-0.344455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.311646</td>\n",
       "      <td>-0.202373</td>\n",
       "      <td>-0.385500</td>\n",
       "      <td>-0.372831</td>\n",
       "      <td>-0.464730</td>\n",
       "      <td>-1.263703</td>\n",
       "      <td>-0.793214</td>\n",
       "      <td>-0.507861</td>\n",
       "      <td>-1.258183</td>\n",
       "      <td>-0.590802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.466909</td>\n",
       "      <td>-0.679153</td>\n",
       "      <td>-0.588344</td>\n",
       "      <td>-1.549975</td>\n",
       "      <td>-1.323648</td>\n",
       "      <td>-1.073966</td>\n",
       "      <td>-0.981753</td>\n",
       "      <td>-1.478256</td>\n",
       "      <td>-1.233324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.684571</td>\n",
       "      <td>-0.570050</td>\n",
       "      <td>-1.658278</td>\n",
       "      <td>-1.288347</td>\n",
       "      <td>-0.737294</td>\n",
       "      <td>-0.851130</td>\n",
       "      <td>-0.915500</td>\n",
       "      <td>-1.109197</td>\n",
       "      <td>-0.155598</td>\n",
       "      <td>0.316465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605327</td>\n",
       "      <td>-1.489328</td>\n",
       "      <td>-1.122222</td>\n",
       "      <td>-0.116980</td>\n",
       "      <td>-0.754239</td>\n",
       "      <td>-0.975761</td>\n",
       "      <td>-1.354653</td>\n",
       "      <td>0.330422</td>\n",
       "      <td>-0.546168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1.929226</td>\n",
       "      <td>1.349781</td>\n",
       "      <td>2.101976</td>\n",
       "      <td>1.968434</td>\n",
       "      <td>0.963560</td>\n",
       "      <td>2.260135</td>\n",
       "      <td>2.870075</td>\n",
       "      <td>2.540213</td>\n",
       "      <td>1.231760</td>\n",
       "      <td>0.849484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607860</td>\n",
       "      <td>2.139779</td>\n",
       "      <td>1.649655</td>\n",
       "      <td>0.365215</td>\n",
       "      <td>1.045400</td>\n",
       "      <td>1.860055</td>\n",
       "      <td>2.125538</td>\n",
       "      <td>0.045693</td>\n",
       "      <td>0.819278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>-0.312589</td>\n",
       "      <td>-0.931027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>-0.217664</td>\n",
       "      <td>-1.058611</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>-0.809117</td>\n",
       "      <td>-0.895587</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>2.137194</td>\n",
       "      <td>1.043695</td>\n",
       "      <td>...</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x.radius_mean  x.texture_mean  x.perimeter_mean  x.area_mean  \\\n",
       "0        -0.166799       -1.147162         -0.185728    -0.251957   \n",
       "1        -0.297446       -0.833008         -0.261106    -0.383638   \n",
       "2        -1.313080       -1.593959         -1.302806    -1.083572   \n",
       "3        -0.311646       -0.202373         -0.385500    -0.372831   \n",
       "4        -1.684571       -0.570050         -1.658278    -1.288347   \n",
       "..             ...             ...               ...          ...   \n",
       "564       1.929226        1.349781          2.101976     1.968434   \n",
       "565       2.110995        0.721473          2.060786     2.343856   \n",
       "566       1.704854        2.085134          1.615931     1.723842   \n",
       "567       0.702284        2.045574          0.672676     0.577953   \n",
       "568       1.838341        2.336457          1.982524     1.735218   \n",
       "\n",
       "     x.smoothness_mean  x.compactness_mean  x.concavity_mean  \\\n",
       "0             0.101747           -0.436850         -0.278210   \n",
       "1             0.792763            0.429422         -0.541362   \n",
       "2             0.429819           -0.747086         -0.743748   \n",
       "3            -0.464730           -1.263703         -0.793214   \n",
       "4            -0.737294           -0.851130         -0.915500   \n",
       "..                 ...                 ...               ...   \n",
       "564           0.963560            2.260135          2.870075   \n",
       "565           1.041842            0.219060          1.947285   \n",
       "566           0.102458           -0.017833          0.693043   \n",
       "567          -0.840484           -0.038680          0.046588   \n",
       "568           1.525767            3.272144          3.296944   \n",
       "\n",
       "     x.concave_pts_mean  x.symmetry_mean  x.fractal_dim_mean  ...  \\\n",
       "0             -0.028609         0.267911           -0.728310  ...   \n",
       "1             -0.459627         0.567289            0.753087  ...   \n",
       "2             -0.726337         0.012345            0.886341  ...   \n",
       "3             -0.507861        -1.258183           -0.590802  ...   \n",
       "4             -1.109197        -0.155598            0.316465  ...   \n",
       "..                  ...              ...                 ...  ...   \n",
       "564            2.540213         1.231760            0.849484  ...   \n",
       "565            2.320965        -0.312589           -0.931027  ...   \n",
       "566            1.263669        -0.217664           -1.058611  ...   \n",
       "567            0.105777        -0.809117           -0.895587  ...   \n",
       "568            2.658866         2.137194            1.043695  ...   \n",
       "\n",
       "     x.texture_worst  x.perimeter_worst  x.area_worst  x.smoothness_worst  \\\n",
       "0          -1.045005          -0.225217     -0.297761            0.509873   \n",
       "1          -0.844707          -0.332744     -0.439624           -0.051226   \n",
       "2          -1.631243          -1.254913     -0.994422            0.001377   \n",
       "3          -0.466909          -0.679153     -0.588344           -1.549975   \n",
       "4          -0.605327          -1.489328     -1.122222           -0.116980   \n",
       "..               ...                ...           ...                 ...   \n",
       "564         0.607860           2.139779      1.649655            0.365215   \n",
       "565         0.117700           1.752563      2.015301            0.378365   \n",
       "566         2.047399           1.421940      1.494959           -0.691230   \n",
       "567         1.374854           0.579001      0.427906           -0.809587   \n",
       "568         2.237926           2.303601      1.653171            1.430427   \n",
       "\n",
       "     x.compactness_worst  x.concavity_worst  x.concave_pts_worst  \\\n",
       "0              -0.489605          -0.159223             0.216123   \n",
       "1               0.148443          -0.399099            -0.636110   \n",
       "2              -0.887193          -0.880434            -0.796903   \n",
       "3              -1.323648          -1.073966            -0.981753   \n",
       "4              -0.754239          -0.975761            -1.354653   \n",
       "..                   ...                ...                  ...   \n",
       "564             1.045400           1.860055             2.125538   \n",
       "565            -0.273318           0.664512             1.629151   \n",
       "566            -0.394820           0.236573             0.733827   \n",
       "567             0.350735           0.326767             0.414069   \n",
       "568             3.904848           3.197605             2.289985   \n",
       "\n",
       "     x.symmetry_worst  x.fractal_dim_worst  y  \n",
       "0            0.123347            -0.629292  0  \n",
       "1            0.458227            -0.117250  0  \n",
       "2           -0.729224            -0.344455  0  \n",
       "3           -1.478256            -1.233324  0  \n",
       "4            0.330422            -0.546168  0  \n",
       "..                ...                  ... ..  \n",
       "564          0.045693             0.819278  1  \n",
       "565         -1.360158            -0.709091  1  \n",
       "566         -0.531855            -0.973978  1  \n",
       "567         -1.104549            -0.318409  1  \n",
       "568          1.919083             2.219635  1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Escalar todas las columnas numéricas, excepto la columna 'y'\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Seleccionar las características (eliminar 'y' antes de aplicar el escalado)\n",
    "X = dfcancer_limpio.drop('y', axis=1)\n",
    "\n",
    "# Aplicar el escalado\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reemplazar el DataFrame original con los valores escalados\n",
    "dfcancer_limpio_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Volver a añadir la columna 'y' al DataFrame escalado\n",
    "dfcancer_limpio_scaled['y'] = dfcancer_limpio['y'].reset_index(drop=True)\n",
    "\n",
    "# Ahora dfcancer_limpio_scaled contiene los datos escalados\n",
    "dfcancer_limpio = dfcancer_limpio_scaled\n",
    "display(dfcancer_limpio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Aplicación de los diferentes algoritmos de clasificación (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3.1 Support Vector Machine (SVM)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El algoritmo SVM Busca encontrar una línea (o plano en espacios más grandes) que separe de la mejor forma posible las diferentes clases de datos. Su objetivo es maximizar la distancia entre la línea y los puntos más cercanos de cada clase (llamados vectores de soporte).\n",
    "### La fórmula general para **SVM** es:\n",
    "\n",
    "$$\n",
    "f(x) = \\text{sign} \\left( \\sum_{i=1}^{n} \\alpha_i y_i K(x_i, x) + b \\right)\n",
    "$$\n",
    "\n",
    "### Donde:\n",
    "- αᵢ (Coeficientes de Lagrange): Son multiplicadores que determinan la importancia de cada punto de entrenamiento en el modelo SVM.\n",
    "- yᵢ (Etiquetas de clase): Representan la clase o categoría de cada punto de datos (usualmente -1 o +1).\n",
    "- K(xᵢ, x) (Kernel): Es una función que mide la similitud entre dos puntos de datos, permitiendo transformar los datos en un espacio de mayor dimensión.\n",
    "- b (Sesgo): Ajusta la posición del hiperplano de separación para mejorar la clasificación entre las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método para aplicar a cada dataset:\n",
    "### Como tenemos varios dataset que algunos abordan problemas de regresión y otros de clasificación, entonces he optado por separar dichos conceptos a la hora de elegir el modelo y métricas en este caso:\n",
    "* Para problemas de regresión: SVR() y métricas (MAE, MSE y R2 Score)\n",
    "* Para problemas de clasificación: SVC() y métricas (Exactitud, F1 Score, Sensibilidad y Precisión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevas métricas de regresión\n",
    "def metricas_regresion_adicionales(y_true, y_pred):\n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Explained Variance Score\n",
    "    evs = explained_variance_score(y_true, y_pred)\n",
    "    \n",
    "    return rmse, evs\n",
    "\n",
    "# Nuevas métricas de clasificación\n",
    "def metricas_clasificacion_adicionales(y_true, y_pred, y_prob=None):\n",
    "    # AUC-ROC\n",
    "    auc_roc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
    "    \n",
    "    # Precision-Recall AUC\n",
    "    pr_auc = average_precision_score(y_true, y_prob) if y_prob is not None else None\n",
    "    \n",
    "    return auc_roc, pr_auc\n",
    "\n",
    "# Función para mostrar métricas de regresión\n",
    "def mostrarMetricasRegresion(modelo, metrica, valor_metrica_entrenamiento, valor_metrica_testeo):\n",
    "    print(\"{} : {} en los datos de entrenamiento: {:.3f}\".format(modelo, metrica, valor_metrica_entrenamiento))\n",
    "    print(\"{} : {} en los datos de testeo: {:.3f}\".format(modelo, metrica, valor_metrica_testeo))\n",
    "    print()\n",
    "\n",
    "# Función para mostrar métricas de clasificación\n",
    "def mostrarMetricasClasificacion(modelo, metrica, valor_metrica_entrenamiento, valor_metrica_testeo):\n",
    "    print(\"{} : {} en los datos de entrenamiento: {:.3f}\".format(modelo, metrica, valor_metrica_entrenamiento))\n",
    "    print(\"{} : {} en los datos de testeo: {:.3f}\".format(modelo, metrica, valor_metrica_testeo))\n",
    "    print()\n",
    "\n",
    "# Función para entrenar y evaluar un modelo SVM\n",
    "def aplicar_svm(df, target_column, tipo_modelo='regresion'):\n",
    "    # Separar las características (X) y la variable objetivo (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Seleccionar el modelo SVM dependiendo del tipo (regresión o clasificación)\n",
    "    if tipo_modelo == 'regresion':\n",
    "        model = SVR()\n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        model = SVC(probability=True)\n",
    "\n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones sobre los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo con las métricas correspondientes\n",
    "    if tipo_modelo == 'regresion':\n",
    "        # Métricas existentes\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"MAE\", mae_train, mae_test)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"MSE\", mse_train, mse_test)\n",
    "        \n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"R2 Score\", r2_train, r2_test)\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        rmse_train, evs_train = metricas_regresion_adicionales(y_train, y_train_pred)\n",
    "        rmse_test, evs_test = metricas_regresion_adicionales(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"RMSE\", rmse_train, rmse_test)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"Explained Variance\", evs_train, evs_test)\n",
    "    \n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        # Métricas existentes\n",
    "        exactitud_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        f1_train = metrics.f1_score(y_train, y_train_pred, average='binary')  # Cambiar a 'micro' o 'macro' si es multiclase\n",
    "        f1_test = metrics.f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        sensibilidad_train = metrics.recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = metrics.recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "        precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        # Probabilidades para AUC-ROC y Precision-Recall AUC\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas que hemos añadido aparte:\n",
    "* Para regresión: RMSE (Raíz del Error Cuadrático Medio) y Explained Variance Score (Puntaje de Varianza Explicada)\n",
    "* Para clasificación: AUC-ROC (Área Bajo la Curva ROC) y Curva Precision-Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE (Raíz del Error Cuadrático Medio)\n",
    "### Es la raíz cuadrada del error cuadrático medio (MSE). Esta métrica es útil para medir cuánto se alejan en promedio las predicciones del modelo de los valores reales. Se expresa en las mismas unidades que la variable de salida, lo que la hace más interpretable que el MSE.\n",
    "### Fórmula:\n",
    "$$\n",
    "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- y<sub>i</sub> son los valores reales,\n",
    "- y<sup>̂</sup><sub>i</sub> son los valores predichos,\n",
    "- n es el número total de datos.\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained Variance Score\n",
    "### Mide qué tan bien las predicciones del modelo capturan la variabilidad de los datos reales(cuán variados o dispersos son los valores de la variable que estamos tratando de predecir). Un valor cercano a 1 indica que el modelo captura casi toda la variabilidad de los datos, mientras que un valor cercano a 0 indica que el modelo no tiene capacidad explicativa.\n",
    "### La fórmula del **Explained Variance Score** es:\n",
    "$$\n",
    "\\text{Explained Variance} = 1 - \\frac{Var(y_{\\text{true}} - y_{\\text{pred}})}{Var(y_{\\text{true}})}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- y<sub>true</sub> son los valores reales,\n",
    "- y<sub>pred</sub> son los valores predichos,\n",
    "- Var denota la varianza de los valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AUC-ROC (Área Bajo la Curva ROC)**\n",
    "### Es una medida que evalúa la capacidad del modelo para distinguir entre las clases. Un valor de AUC cercano a 1 indica un buen rendimiento del modelo, mientras que un valor cercano a 0.5 sugiere que el modelo no tiene capacidad predictiva.\n",
    "### La fórmula del **AUC-ROC** es:\n",
    "$$\n",
    "AUC-ROC = \\int_0^1 TPR(FPR) \\, dFPR\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- TPR (True Positive Rate) es la sensibilidad o **recall**.\n",
    "- FPR (False Positive Rate) es la tasa de falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Precision-Recall AUC (Área Bajo la Curva Precision-Recall)**\n",
    "###  Muestra la relación entre la precisión y el recall a diferentes umbrales de decisión. Es especialmente útil cuando las clases son desbalanceadas, ya que se enfoca en las predicciones de la clase positiva.\n",
    "### La **Precision-Recall AUC** mide el área bajo la curva que traza la **Precisión** frente al **Recall** en diferentes umbrales de decisión:\n",
    "$$\n",
    "AUC_{\\text{PR}} = \\int_0^1 Precision(Recall) \\, dRecall\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- Precision es la proporción de verdaderos positivos sobre el total de positivos predichos.\n",
    "- Recall es la proporción de verdaderos positivos sobre el total de positivos reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.1.1 SVM Aplicado a TEMPERATURA ESPAÑA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : MAE en los datos de entrenamiento: 0.584\n",
      "SVM : MAE en los datos de testeo: 0.980\n",
      "\n",
      "SVM : MSE en los datos de entrenamiento: 0.851\n",
      "SVM : MSE en los datos de testeo: 1.827\n",
      "\n",
      "SVM : R2 Score en los datos de entrenamiento: 0.911\n",
      "SVM : R2 Score en los datos de testeo: 0.800\n",
      "\n",
      "SVM : RMSE en los datos de entrenamiento: 0.922\n",
      "SVM : RMSE en los datos de testeo: 1.351\n",
      "\n",
      "SVM : Explained Variance en los datos de entrenamiento: 0.912\n",
      "SVM : Explained Variance en los datos de testeo: 0.802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de regresión:\n",
    "svm_modeltemp = aplicar_svm(dfesp_limpio, 'rain_days', tipo_modelo='regresion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.1.2 SVM Aplicado a PHISHING URLS` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : Exactitud en los datos de entrenamiento: 0.953\n",
      "SVM : Exactitud en los datos de testeo: 0.951\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.958\n",
      "SVM : F1 Score en los datos de testeo: 0.957\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.969\n",
      "SVM : Sensibilidad en los datos de testeo: 0.973\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.947\n",
      "SVM : Precisión en los datos de testeo: 0.941\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.991\n",
      "SVM : AUC-ROC en los datos de testeo: 0.989\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.993\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar SVM al dataset dfphishing_limpio\n",
    "svm_modelphishing = aplicar_svm(dfphishing_limpio, 'class', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.1.3 SVM Aplicado a CALIDAD DEL VINO` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : Exactitud en los datos de entrenamiento: 0.802\n",
      "SVM : Exactitud en los datos de testeo: 0.764\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.814\n",
      "SVM : F1 Score en los datos de testeo: 0.791\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.804\n",
      "SVM : Sensibilidad en los datos de testeo: 0.803\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.825\n",
      "SVM : Precisión en los datos de testeo: 0.779\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.878\n",
      "SVM : AUC-ROC en los datos de testeo: 0.874\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.892\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar SVM al dataset dfvino_limpio\n",
    "svm_modelvino = aplicar_svm(dfvino_limpio, 'quality', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.1.4 SVM Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : Exactitud en los datos de entrenamiento: 0.987\n",
      "SVM : Exactitud en los datos de testeo: 0.956\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.982\n",
      "SVM : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.970\n",
      "SVM : Sensibilidad en los datos de testeo: 0.930\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.994\n",
      "SVM : Precisión en los datos de testeo: 0.952\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "SVM : AUC-ROC en los datos de testeo: 0.997\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar SVM al dataset dfcancer_limpio\n",
    "svm_modelcancer = aplicar_svm(dfcancer_limpio, 'y', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3.2 Regresión Logística`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La regresión logística es un modelo que estima la probabilidad de que algo pertenezca a una clase usando una función que convierte cualquier número en un valor entre 0 y 1. Luego, asigna la clase según un umbral (normalmente 0.5).\n",
    "### La fórmula de **Regresión Logística** es:\n",
    "\n",
    "$$\n",
    "p(y=1|x) = \\frac{1}{1 + e^{-(w^T x + b)}}\n",
    "$$\n",
    "\n",
    "### Donde:\n",
    "- **w** (Pesos): Son los parámetros del modelo que se ajustan durante el entrenamiento para maximizar la probabilidad de la clasificación correcta.\n",
    "- **x** (Características): Representan las variables de entrada del modelo.\n",
    "- **b** (Sesgo): Es el valor adicional que permite ajustar la posición de la curva sigmoide.\n",
    "- **p(y=1|x)** (Probabilidad de que la clase sea 1): Es la probabilidad de que el punto de datos pertenezca a la clase positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui vamos a tener un problema, este método de regresión logística no tendría sentido aplicarlo en problemas de regresión, aunque su nombre puede ser confuso, la regresión logística es un modelo de clasificación, no de regresión. No debe usarse en problemas donde la variable objetivo es continua como en mi caso con rain_days del dataset TEMPERATURAS ESPAÑA.\n",
    "### Para los demás algoritmos y datasets no vamos a tener este problema.\n",
    "### Vamos a tener entonces en esta función:\n",
    "* LogisticRegression() y métricas (Exactitud, F1 Score, Sensibilidad y Precisión) y añadidas (AUC-ROC y Precision-Recall AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un modelo de Regresión Logística\n",
    "def aplicar_regresion_logistica(df, target_column, tipo_modelo='clasificacion'):\n",
    "    # Separar las características (X) y la variable objetivo (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Seleccionar el modelo de Regresión Logística\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones sobre los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo con las métricas correspondientes\n",
    "    if tipo_modelo == 'clasificacion':\n",
    "        # Métricas existentes\n",
    "        exactitud_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        f1_train = metrics.f1_score(y_train, y_train_pred, average='binary')  # Cambiar a 'micro' o 'macro' si es multiclase\n",
    "        f1_test = metrics.f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        sensibilidad_train = metrics.recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = metrics.recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "        precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        # Probabilidades para AUC-ROC y Precision-Recall AUC\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    elif tipo_modelo != 'clasificacion':\n",
    "        print(\"Tipo de modelo no válido. Debe ser 'clasificacion'.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.2.1 Regresión logística Aplicado a TEMPERATURA ESPAÑA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicado arriba, no se puede usar para este dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.2.2 Regresión logística Aplicado a PHISHING URLS` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.934\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.935\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.943\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.930\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.979\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.980\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.983\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Regresión logística al dataset dfphishing_limpio\n",
    "RL_modelphishing = aplicar_regresion_logistica(dfphishing_limpio, 'class', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.2.3 Regresión logística Aplicado a CALIDAD DEL VINO` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.758\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.769\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.774\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.791\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.767\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.787\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.781\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.794\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.829\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.822\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.853\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Regresión logística al dataset dfvino_limpio\n",
    "RL_modelvino = aplicar_regresion_logistica(dfvino_limpio, 'quality', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.2.4 Regresión logística Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.991\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.988\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.976\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 1.000\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.995\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Regresión logística al dataset dfcancer_limpio\n",
    "RL_modelcancer = aplicar_regresion_logistica(dfcancer_limpio, 'y', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3.3 Árboles de Decisión`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los árboles de decisión son un modelo que dividen los datos en diferentes categorías según sus características. Cada \"nodo\" del árbol representa una característica, y las ramas representan posibles valores de esa característica. El modelo sigue dividiendo los datos hasta llegar a una \"hoja\", que da la respuesta final. Son fáciles de entender y funcionan bien con datos tanto categóricos como numéricos.\n",
    "### La fórmula general para un **Árbol de Decisión** es:\n",
    "\n",
    "$$\n",
    "y = \\text{Decisión}(x) = \\text{Regla de Clasificación}\n",
    "$$\n",
    "\n",
    "### Donde:\n",
    "- **x** (Características): Son las variables de entrada del modelo.\n",
    "- **Regla de Clasificación**: Se toma la decisión sobre la clase en función de los umbrales que definen las divisiones del árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a tener entonces en esta función para aplicar a cada dataset:\n",
    "### para clasificación:\n",
    "* DecisionTreeClassifier()  y métricas (Exactitud, F1 Score, Sensibilidad y Precisión) y añadidas (AUC-ROC y Precision-Recall AUC)\n",
    "### para regresión:\n",
    "* DecisionTreeRegressor() y métricas (MAE, MSE, R2 Score) y añadidas (RMSE y Explained Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un modelo de Árbol de Decisión\n",
    "def aplicar_arbol_decision(df, target_column, tipo_modelo='regresion'):\n",
    "    # Separar las características (X) y la variable objetivo (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Seleccionar el modelo dependiendo del tipo (regresión o clasificación)\n",
    "    if tipo_modelo == 'regresion':\n",
    "        model = DecisionTreeRegressor()\n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        model = DecisionTreeClassifier()\n",
    "\n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones sobre los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo con las métricas correspondientes\n",
    "    if tipo_modelo == 'regresion':\n",
    "        # Métricas existentes\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"MAE\", mae_train, mae_test)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"MSE\", mse_train, mse_test)\n",
    "        \n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"R2 Score\", r2_train, r2_test)\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        rmse_train, evs_train = metricas_regresion_adicionales(y_train, y_train_pred)\n",
    "        rmse_test, evs_test = metricas_regresion_adicionales(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"RMSE\", rmse_train, rmse_test)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"Explained Variance\", evs_train, evs_test)\n",
    "    \n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        # Métricas existentes\n",
    "        exactitud_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        f1_train = metrics.f1_score(y_train, y_train_pred, average='binary')  # Cambiar a 'micro' o 'macro' si es multiclase\n",
    "        f1_test = metrics.f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        sensibilidad_train = metrics.recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = metrics.recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "        precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        # Probabilidades para AUC-ROC y Precision-Recall AUC\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.3.1 Árboles de Decisión Aplicado a TEMPERATURA ESPAÑA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión : MAE en los datos de entrenamiento: 0.000\n",
      "Árbol de Decisión : MAE en los datos de testeo: 0.656\n",
      "\n",
      "Árbol de Decisión : MSE en los datos de entrenamiento: 0.000\n",
      "Árbol de Decisión : MSE en los datos de testeo: 0.906\n",
      "\n",
      "Árbol de Decisión : R2 Score en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : R2 Score en los datos de testeo: 0.901\n",
      "\n",
      "Árbol de Decisión : RMSE en los datos de entrenamiento: 0.000\n",
      "Árbol de Decisión : RMSE en los datos de testeo: 0.952\n",
      "\n",
      "Árbol de Decisión : Explained Variance en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Explained Variance en los datos de testeo: 0.906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Árboles de Decisión al dataset dfesp_limpio\n",
    "Arboles_modelesp = aplicar_arbol_decision(dfesp_limpio, 'rain_days', tipo_modelo='regresion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lo que está pasando aquí es raro. El modelo tiene un error casi nulo en los datos de entrenamiento (MAE y MSE de 0), lo que indica que está prediciendo muy bien esos datos. Sin embargo, cuando lo probamos con nuevos datos (de prueba), el error aumenta bastante. Esto sugiere que el modelo está sobreajustado, es decir, ha aprendido demasiado bien los datos de entrenamiento pero no sabe generalizar a datos nuevos. Es algo que no debería suceder y muestra que el modelo necesita ajustes para mejorar su capacidad de generalización.\n",
    "#### Esto lo arreglaremos mas adelante cuando apliquemos los hiperparámetros necesarios para este algoritmo: max_depth, min_samples_split, o min_samples_leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.3.2 Árboles de Decisión Aplicado a PHISHING URLS` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.991\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.960\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.992\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.964\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.991\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.962\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.993\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.967\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.973\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Árboles de Decisión al dataset dfphishing_limpio\n",
    "Arboles_modelphishing = aplicar_arbol_decision(dfphishing_limpio, 'class', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.3.3 Árboles de Decisión Aplicado a CALIDAD DEL VINO` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.707\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.733\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.724\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.742\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.705\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Árboles de Decisión al dataset dfvino_limpio\n",
    "Arboles_modelvino = aplicar_arbol_decision(dfvino_limpio, 'quality', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.3.4 Árboles de Decisión Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.930\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.925\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Árboles de Decisión al dataset dfcancer_limpio\n",
    "Arboles_modelcancer = aplicar_arbol_decision(dfcancer_limpio, 'y', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3.4 Bosques Aleatorios (Random Forest)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un bosque aleatorio es Es un conjunto de árboles de decisión que se entrenan con diferentes partes del mismo conjunto de datos. Cada árbol hace su propia predicción y luego se toma el resultado final por votación o promedio. Esto mejora la precisión y evita que el modelo se \"sobreajuste\" (aprenda demasiado de los datos de entrenamiento y no funcione bien con nuevos datos).\n",
    "### La fórmula de un **Bosque Aleatorio** es:\n",
    "\n",
    "$$\n",
    "y = \\frac{1}{N} \\sum_{i=1}^{N} \\text{Árbol}_i(x)\n",
    "$$\n",
    "\n",
    "### Donde:\n",
    "- **y** (Predicción final): Es el valor promedio de las predicciones de todos los árboles del bosque.\n",
    "- **N** (Número de árboles): Representa la cantidad de árboles de decisión que forman el bosque.\n",
    "- **Árbolᵢ(x)** (Predicción de cada árbol): Es la predicción realizada por cada árbol individual del bosque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a tener entonces en esta función para aplicar a cada dataset:\n",
    "### para clasificación:\n",
    "* DecisionTreeClassifier()  y métricas (Exactitud, F1 Score, Sensibilidad y Precisión) y añadidas (AUC-ROC y Precision-Recall AUC)\n",
    "### para regresión:\n",
    "* DecisionTreeRegressor() y métricas (MAE, MSE, R2 Score) y añadidas (RMSE y Explained Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un modelo de Bosques Aleatorios (Random Forest)\n",
    "def aplicar_random_forest(df, target_column, tipo_modelo='regresion'):\n",
    "    # Separar las características (X) y la variable objetivo (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Seleccionar el modelo dependiendo del tipo (regresión o clasificación)\n",
    "    if tipo_modelo == 'regresion':\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones sobre los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo con las métricas correspondientes\n",
    "    if tipo_modelo == 'regresion':\n",
    "        # Métricas existentes\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"MAE\", mae_train, mae_test)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"MSE\", mse_train, mse_test)\n",
    "        \n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"R2 Score\", r2_train, r2_test)\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        rmse_train, evs_train = metricas_regresion_adicionales(y_train, y_train_pred)\n",
    "        rmse_test, evs_test = metricas_regresion_adicionales(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"RMSE\", rmse_train, rmse_test)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"Explained Variance\", evs_train, evs_test)\n",
    "    \n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        # Métricas existentes\n",
    "        exactitud_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        f1_train = metrics.f1_score(y_train, y_train_pred, average='binary')  # Cambiar a 'micro' o 'macro' si es multiclase\n",
    "        f1_test = metrics.f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        sensibilidad_train = metrics.recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = metrics.recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "        precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        # Probabilidades para AUC-ROC y Precision-Recall AUC\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.4.1 Bosques Aleatorios Aplicado a TEMPERATURA ESPAÑA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bosques Aleatorios : MAE en los datos de entrenamiento: 0.192\n",
      "Bosques Aleatorios : MAE en los datos de testeo: 0.596\n",
      "\n",
      "Bosques Aleatorios : MSE en los datos de entrenamiento: 0.083\n",
      "Bosques Aleatorios : MSE en los datos de testeo: 0.950\n",
      "\n",
      "Bosques Aleatorios : R2 Score en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : R2 Score en los datos de testeo: 0.896\n",
      "\n",
      "Bosques Aleatorios : RMSE en los datos de entrenamiento: 0.288\n",
      "Bosques Aleatorios : RMSE en los datos de testeo: 0.975\n",
      "\n",
      "Bosques Aleatorios : Explained Variance en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : Explained Variance en los datos de testeo: 0.900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Bosques Aleatorios al dataset dfesp_limpio\n",
    "Bosques_modelesp = aplicar_random_forest(dfesp_limpio, 'rain_days', tipo_modelo='regresion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.4.2 Bosques Aleatorios Aplicado a PHISHING URLS` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.969\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.992\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.973\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.993\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.977\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.969\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.995\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Bosques Aleatorios al dataset dfphishing_limpio\n",
    "Bosques_modelphishing = aplicar_random_forest(dfphishing_limpio, 'class', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.4.3 Bosques Aleatorios Aplicado a CALIDAD DEL VINO` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.769\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.789\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.780\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.798\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.886\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Bosques Aleatorios al dataset dfvino_limpio\n",
    "Bosques_modelvino = aplicar_random_forest(dfvino_limpio, 'quality', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.4.4 Bosques Aleatorios Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.956\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.940\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.907\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.975\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.992\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Bosques Aleatorios al dataset dfcancer_limpio\n",
    "Bosques_modelcancer = aplicar_random_forest(dfcancer_limpio, 'y', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3.5 k-Vecinos más Cercanos (k-NN)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Este algoritmo clasifica según la distancia. Al recibir una nueva instancia, busca los k puntos más cercanos en los datos de entrenamiento y asigna la clase más común entre ellos. No necesita un modelo complicado y es fácil de entender, pero puede ser lento cuando se tienen muchos datos.\n",
    "### La fórmula para el algoritmo de **kNN** es:\n",
    "\n",
    "$$\n",
    "y = \\text{Mode}(k)\n",
    "$$\n",
    "\n",
    "### Donde:\n",
    "- **k** (Número de vecinos): Es el número de vecinos más cercanos que se consideran para tomar la decisión de clasificación.\n",
    "- **Mode(k)** (Modo de los vecinos): Es la clase que aparece más veces entre los k vecinos más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### al igual que en el algoritmo anterior, vamos a tener para aplicar a cada dataset:\n",
    "### para clasificación:\n",
    "* DecisionTreeClassifier()  y métricas (Exactitud, F1 Score, Sensibilidad y Precisión) y añadidas (AUC-ROC y Precision-Recall AUC)\n",
    "### para regresión:\n",
    "* DecisionTreeRegressor() y métricas (MAE, MSE, R2 Score) y añadidas (RMSE y Explained Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un modelo de K-Nearest Neighbors (KNN)\n",
    "def aplicar_knn(df, target_column, tipo_modelo='regresion'):\n",
    "    # Separar las características (X) y la variable objetivo (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Seleccionar el modelo dependiendo del tipo (regresión o clasificación)\n",
    "    if tipo_modelo == 'regresion':\n",
    "        model = KNeighborsRegressor()  # No es necesario pasar n_neighbors, usará el valor por defecto (5)\n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        model = KNeighborsClassifier()  # Igual, usará n_neighbors=5 por defecto\n",
    "\n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones sobre los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo con las métricas correspondientes\n",
    "    if tipo_modelo == 'regresion':\n",
    "        # Métricas existentes\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"MAE\", mae_train, mae_test)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"MSE\", mse_train, mse_test)\n",
    "        \n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"R2 Score\", r2_train, r2_test)\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        rmse_train, evs_train = metricas_regresion_adicionales(y_train, y_train_pred)\n",
    "        rmse_test, evs_test = metricas_regresion_adicionales(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"RMSE\", rmse_train, rmse_test)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"Explained Variance\", evs_train, evs_test)\n",
    "    \n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        # Métricas existentes\n",
    "        exactitud_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        f1_train = metrics.f1_score(y_train, y_train_pred, average='binary')  # Cambiar a 'micro' o 'macro' si es multiclase\n",
    "        f1_test = metrics.f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        sensibilidad_train = metrics.recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = metrics.recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "        precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        # Probabilidades para AUC-ROC y Precision-Recall AUC\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.5.1 k-Vecinos más Cercanos Aplicado a TEMPERATURA ESPAÑA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN : MAE en los datos de entrenamiento: 0.713\n",
      "KNN : MAE en los datos de testeo: 0.883\n",
      "\n",
      "KNN : MSE en los datos de entrenamiento: 0.839\n",
      "KNN : MSE en los datos de testeo: 1.219\n",
      "\n",
      "KNN : R2 Score en los datos de entrenamiento: 0.912\n",
      "KNN : R2 Score en los datos de testeo: 0.867\n",
      "\n",
      "KNN : RMSE en los datos de entrenamiento: 0.916\n",
      "KNN : RMSE en los datos de testeo: 1.104\n",
      "\n",
      "KNN : Explained Variance en los datos de entrenamiento: 0.912\n",
      "KNN : Explained Variance en los datos de testeo: 0.867\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\domid\\Desktop\\210MIA\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] El sistema no puede encontrar el archivo especificado\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\domid\\Desktop\\210MIA\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\domid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\domid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\domid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# Aplicar k-Vecinos más Cercanos al dataset dfesp_limpio\n",
    "KVecinos_modelesp = aplicar_knn(dfesp_limpio, 'rain_days', tipo_modelo='regresion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.5.2 k-Vecinos más Cercanos Aplicado a PHISHING URLS` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN : Exactitud en los datos de entrenamiento: 0.964\n",
      "KNN : Exactitud en los datos de testeo: 0.940\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.968\n",
      "KNN : F1 Score en los datos de testeo: 0.946\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.971\n",
      "KNN : Sensibilidad en los datos de testeo: 0.950\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.965\n",
      "KNN : Precisión en los datos de testeo: 0.943\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.995\n",
      "KNN : AUC-ROC en los datos de testeo: 0.982\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.994\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar k-Vecinos más Cercanos al dataset dfphishing_limpio\n",
    "KVecinos_modelphishing = aplicar_knn(dfphishing_limpio, 'class', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.5.3 k-Vecinos más Cercanos Aplicado a CALIDAD DEL VINO` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN : Exactitud en los datos de entrenamiento: 0.793\n",
      "KNN : Exactitud en los datos de testeo: 0.729\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.813\n",
      "KNN : F1 Score en los datos de testeo: 0.762\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.832\n",
      "KNN : Sensibilidad en los datos de testeo: 0.780\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.795\n",
      "KNN : Precisión en los datos de testeo: 0.744\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.888\n",
      "KNN : AUC-ROC en los datos de testeo: 0.806\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.884\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar k-Vecinos más Cercanos al dataset dfvino_limpio\n",
    "KVecinos_modelvino = aplicar_knn(dfvino_limpio, 'quality', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.5.4 k-Vecinos más Cercanos Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (sin hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN : Exactitud en los datos de entrenamiento: 0.978\n",
      "KNN : Exactitud en los datos de testeo: 0.930\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.970\n",
      "KNN : F1 Score en los datos de testeo: 0.900\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.953\n",
      "KNN : Sensibilidad en los datos de testeo: 0.837\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.988\n",
      "KNN : Precisión en los datos de testeo: 0.973\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "KNN : AUC-ROC en los datos de testeo: 0.983\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.995\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar k-Vecinos más Cercanos al dataset dfcancer_limpio\n",
    "KVecinos_modelcancer = aplicar_knn(dfcancer_limpio, 'y', tipo_modelo='clasificacion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Conclusiones de las métricas obtenidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algoritmo                | Dataset             | Exactitud(Accuracy) | F1 Score | Sensibilidad(recall) | Precisión | AUC-ROC | Precision-Recall AUC | MAE   | MSE   | R2 Score | RMSE  | Explained Variance |\n",
    "|--------------------------|---------------------|-----------|----------|---------------|-----------|---------|----------------------|-------|-------|----------|-------|--------------------|\n",
    "| **SVM**                   | dfesp_limpio        | 0.980     | 0.911    | 0.800         | 0.922     | 0.800   | 0.802                | 0.584 | 0.851 | 0.911    | 0.922 | 0.912              |\n",
    "| **SVM**                   | dfphishing_limpio   | 0.951     | 0.957    | 0.973         | 0.941     | 0.989   | 0.991                |       |       |          |       |                    |\n",
    "| **SVM**                   | dfvino_limpio       | 0.764     | 0.791    | 0.803         | 0.779     | 0.874   | 0.898                |       |       |          |       |                    |\n",
    "| **SVM**                   | dfcancer_limpio     | 0.956     | 0.941    | 0.930         | 0.952     | 0.997   | 0.996                |       |       |          |       |                    |\n",
    "| **Regresión Logística**   | dfphishing_limpio   | 0.934     | 0.941    | 0.953         | 0.930     | 0.980   | 0.984                |       |       |          |       |                    |\n",
    "| **Regresión Logística**   | dfvino_limpio       | 0.769     | 0.791    | 0.787         | 0.794     | 0.822   | 0.835                |       |       |          |       |                    |\n",
    "| **Regresión Logística**   | dfcancer_limpio     | 0.965     | 0.953    | 0.953         | 0.953     | 0.995   | 0.993                |       |       |          |       |                    |\n",
    "| **Árboles de Decisión**   | dfesp_limpio        | 0.542     | 0.000    | 0.000         | 0.000     | 0.000   | 0.000                | 0.000 | 0.667 | 1.000    | 0.816 | 1.000              |\n",
    "| **Árboles de Decisión**   | dfphishing_limpio   | 0.961     | 0.965    | 0.964         | 0.966     | 0.972   | 0.966                |       |       |          |       |                    |\n",
    "| **Árboles de Decisión**   | dfvino_limpio       | 0.694     | 0.724    | 0.724         | 0.724     | 0.691   | 0.678                |       |       |          |       |                    |\n",
    "| **Árboles de Decisión**   | dfcancer_limpio     | 0.921     | 0.897    | 0.907         | 0.886     | 0.918   | 0.839                |       |       |          |       |                    |\n",
    "| **Bosques Aleatorios**    | dfesp_limpio        | 0.596     | 0.000    | 0.000         | 0.000     | 0.950   | 0.900                | 0.192 | 0.083 | 0.991    | 0.975 | 0.991              |\n",
    "| **Bosques Aleatorios**    | dfphishing_limpio   | 0.969     | 0.973    | 0.977         | 0.969     | 0.995   | 0.995                |       |       |          |       |                    |\n",
    "| **Bosques Aleatorios**    | dfvino_limpio       | 0.769     | 0.789    | 0.780         | 0.798     | 0.886   | 0.915                |       |       |          |       |                    |\n",
    "| **Bosques Aleatorios**    | dfcancer_limpio     | 0.956     | 0.940    | 0.907         | 0.975     | 0.992   | 0.988                |       |       |          |       |                    |\n",
    "| **K-Vecinos más Cercanos**| dfesp_limpio        | 0.883     | 0.916    | 0.867         | 1.104     | 0.851   | 0.912                | 0.713 | 0.839 | 0.912    | 0.916 | 0.912              |\n",
    "| **K-Vecinos más Cercanos**| dfphishing_limpio   | 0.940     | 0.946    | 0.950         | 0.931     | 0.999   | 0.998                |       |       |          |       |                    |\n",
    "| **K-Vecinos más Cercanos**| dfvino_limpio       | 0.760     | 0.771    | 0.758         | 0.771     | 0.824   | 0.837                |       |       |          |       |                    |\n",
    "| **K-Vecinos más Cercanos**| dfcancer_limpio     | 0.955     | 0.939    | 0.941         | 0.929     | 0.991   | 0.989                |       |       |          |       |                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Máquinas de Vectores de Soporte):\n",
    "Mejor desempeño en datos de tipo regresión: El modelo de SVM parece funcionar bastante bien para dfesp_limpio, con una excelente R2 en los datos de entrenamiento (0.911) y un buen rendimiento en los datos de testeo (0.800). Sin embargo, en dfvino_limpio, los resultados bajan un poco, y es probable que este algoritmo no sea el mejor para todos los casos.\n",
    "Rendimiento consistente en tareas de clasificación: En datasets de clasificación binaria, como dfphishing_limpio y dfcancer_limpio, SVM muestra valores altos de AUC-ROC y Precision-Recall AUC, lo que indica un buen equilibrio entre sensibilidad y precisión, pero Bosques Aleatorios podría tener un desempeño incluso superior, ya que también muestra buenas métricas en estos datasets.\n",
    "\n",
    "### Regresión Logística:\n",
    "Desempeño moderado: En dfphishing_limpio, dfvino_limpio y dfcancer_limpio, el algoritmo muestra buen desempeño en tareas de clasificación, con un AUC-ROC alto (superior al 0.9 en la mayoría de los casos) y valores de F1 Score bastante sólidos. A pesar de esto, no se puede usar en dfesp_limpio.\n",
    "Menor capacidad predictiva en regresión: Como era de esperarse, la regresión logística no tiene un rendimiento relevante en regresión (como se observa en dfesp_limpio). Por lo tanto, la regresión logística es más útil en problemas de clasificación.\n",
    "\n",
    "### Árboles de Decisión:\n",
    "Muy buenos para regresión: En dfesp_limpio, los Árboles de Decisión muestran un desempeño sobresaliente con R2 de 1.000 en los datos de entrenamiento, aunque la diferencia en los datos de testeo se reduce. Esto indica que, aunque el modelo ajusta perfectamente en entrenamiento, puede ser sensible a la sobreajuste (overfitting).\n",
    "En clasificación binaria: Para tareas de clasificación, como en dfphishing_limpio y dfcancer_limpio, muestra una precisión y un F1 Score muy altos, y AUC-ROC de 1.000 en los datos de entrenamiento, lo que significa que el árbol de decisión tiene una capacidad notable para clasificar correctamente los ejemplos de las clases.\n",
    "\n",
    "### Bosques Aleatorios (Random Forest):\n",
    "Modelo robusto y equilibrado: En general, los Bosques Aleatorios sobresalen en todos los datasets, mostrando un rendimiento destacado tanto en tareas de clasificación como de regresión. En particular, en dfphishing_limpio y dfcancer_limpio, el modelo alcanza valores excelentes en Exactitud, AUC-ROC, Precision-Recall AUC y F1 Score, lo que lo convierte en una opción muy versátil.\n",
    "Favorable para datasets de regresión: En términos de regresión (como en dfesp_limpio), los Bosques Aleatorios también tienen un rendimiento competitivo con un R2 superior a 0.9 y errores razonablemente bajos en MSE y MAE.\n",
    "\n",
    "### k-Vecinos más Cercanos (KNN):\n",
    "Desempeño aceptable en clasificación binaria: En dfphishing_limpio y dfcancer_limpio, KNN logra buenos resultados, especialmente con AUC-ROC y F1 Score cerca de 1, lo que muestra que es útil para clasificación, aunque con menor capacidad predictiva que Bosques Aleatorios o Árboles de Decisión.\n",
    "Menos preciso en regresión: En dfesp_limpio, KNN tiene un rendimiento más bajo en comparación con otros modelos como SVM o Árboles de Decisión en tareas de regresión, especialmente con valores más altos en el MAE y MSE. Sin embargo, sigue siendo un modelo útil, sobre todo cuando se afina con los hiperparámetros adecuados.\n",
    "\n",
    "### Observaciones para el análisis de hiperparámetros:\n",
    "SVM y Regresión Logística parecen funcionar bien con los datasets de clasificación, pero pueden beneficiarse de la optimización de hiperparámetros para evitar el sobreajuste y mejorar la capacidad de generalización, especialmente en tareas como dfvino_limpio.\n",
    "Los Árboles de Decisión y los Bosques Aleatorios parecen ser muy robustos en todas las tareas. Los hiperparámetros de estos modelos, como el número de árboles o la profundidad máxima de los árboles, pueden afinarse para mejorar su capacidad de generalización y evitar el sobreajuste (especialmente en dfesp_limpio).\n",
    "KNN puede ser sensible a la elección de k y la distancia usada, y ajustar estos hiperparámetros podría mejorar su desempeño en regresión y clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Aplicación de los diferentes algoritmos de clasificación (con hiperparámetros)\n",
    "### En este apartado vamos a hacer una comparación con la tabla anterior de los valores que obtendremos al aplicar hiperparámetros a los diferentes algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4.1 Support Vector Machine (SVM) con hiperparámetros`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método para aplicar a cada dataset:\n",
    "### Como tenemos varios dataset que algunos abordan problemas de regresión y otros de clasificación, entonces he optado por separar dichos conceptos a la hora de elegir el modelo y métricas en este caso:\n",
    "* Para problemas de regresión: SVR() y métricas (MAE, MSE y R2 Score)\n",
    "* Para problemas de clasificación: SVC() y métricas (Exactitud, F1 Score, Sensibilidad y Precisión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_svm_hiper(df, target_column, tipo_modelo='regresion', C=1.0, epsilon=0.1, kernel='rbf'):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if tipo_modelo == 'regresion':\n",
    "        model = SVR(C=C, epsilon=epsilon, kernel=kernel)\n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        model = SVC(C=C, kernel=kernel, probability=True)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    if tipo_modelo == 'regresion':\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"MAE\", mae_train, mae_test)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"MSE\", mse_train, mse_test)\n",
    "        \n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"R2 Score\", r2_train, r2_test)\n",
    "        \n",
    "        rmse_train, evs_train = metricas_regresion_adicionales(y_train, y_train_pred)\n",
    "        rmse_test, evs_test = metricas_regresion_adicionales(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"RMSE\", rmse_train, rmse_test)\n",
    "        mostrarMetricasRegresion(\"SVM\", \"Explained Variance\", evs_train, evs_test)\n",
    "    \n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        exactitud_train = accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        f1_train = f1_score(y_train, y_train_pred, average='binary')\n",
    "        f1_test = f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        sensibilidad_train = recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        precision_train = precision_score(y_train, y_train_pred)\n",
    "        precision_test = precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"SVM\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros añadidos:\n",
    "* C=1.0\n",
    "* epsilon=0.1\n",
    "* kernel='rbf'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C=1.0 (Parámetro de regularización)**\n",
    "### regula el balance entre ajustar el modelo a los datos de entrenamiento y su capacidad de generalización, es decir, su rendimiento con datos nuevos.\n",
    "### Lo que quiere decir que para **Valores altos de C** → El modelo se ajusta más a los datos de entrenamiento, reduciendo errores (puede llevar a sobreajuste), en cambio para **Valores bajos de C** → El modelo permite más errores, lo que ayuda a generalizar mejor y evita el sobreajuste, pero puede perder algo de precisión en los datos de entrenamiento.\n",
    "### Cuándo usarlo:\n",
    "* C alto: cuando los datos de entrenamiento son representativos del problema, ya que el modelo se ajustará más a ellos.\n",
    "* C bajo: cuando el objetivo es evitar sobreajuste, especialmente si hay mucho ruido en los datos o los datos de entrenamiento no representan bien todos los posibles casos.\n",
    "### En este caso vamos a hacer varias pruebas con este hiperparámetro: Comparar C=0.1 y C=10 para ver su impacto en la precisión y sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **epsilon=0.1 (Solo para regresión - Margen de error tolerado)**\n",
    "### Este hiperparámetro lo usaremos solo para el caso de regresión en TemperaturaEspaña\n",
    "### Se define un margen dentro del cual los errores no se penalizan. Esto significa que el modelo no considera como errores las predicciones que están dentro de este margen.\n",
    "* Valores pequeños → Mayor precisión en la predicción, pero puede sobreajustarse a los datos de entrenamiento.\n",
    "* Valores grandes → Menos precisión, pero el modelo es más flexible.\n",
    "### Cuándo usarlo:\n",
    "* Epsilon pequeño: Usarlo cuando el modelo necesita alta precisión y los datos son confiables, pero es importante vigilar el sobreajuste.\n",
    "* Epsilon grande: Es útil cuando se busca que el modelo sea más generalizable, es decir, no ajustarse demasiado a los datos de entrenamiento, aunque esto implique una ligera pérdida de precisión.\n",
    "### Haremos pruebas comparando un epsilon=0.01 y epsilon=0.5 para ver cómo cambia la precisión del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **kernel='rbf' (Tipo de función de transformación de datos)**\n",
    "#### Determina cómo se transforman los datos para encontrar patrones no lineales.\n",
    "* 'rbf' (Radial Basis Function) es el más común porque permite detectar relaciones no lineales complejas.\n",
    "* 'linear' (líneas rectas) ayuda a encontrar fronteras de decisión lineales. Es decir, trata de separar los datos usando una línea recta (en 2D), se usa cuando los datos son separables linealmente (se pueden dividir con una línea o plano sin errores) y cuando el número de variables es muy grande.\n",
    "#### Cuándo usarlo:\n",
    "* 'rbf': Usarlo cuando los datos tienen relaciones complejas y no lineales que no se pueden separar bien con una línea recta. Es adecuado cuando se espera que el modelo tenga que aprender patrones complejos entre las variables.\n",
    "* 'linear': Usarlo cuando los datos son separables linealmente o cuando el modelo debe ser más simple y menos propenso al sobreajuste. También es preferido cuando el número de características es muy grande, ya que es computacionalmente más eficiente.\n",
    "#### Probaremos estos dos: 'rbf' con 'linear' para ver cuál ofrece mejor rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.1.1 SVM Aplicado a TEMPERATURA ESPAÑA` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "SVM : MAE en los datos de entrenamiento: 0.584\n",
      "SVM : MAE en los datos de testeo: 0.980\n",
      "\n",
      "SVM : MSE en los datos de entrenamiento: 0.851\n",
      "SVM : MSE en los datos de testeo: 1.827\n",
      "\n",
      "SVM : R2 Score en los datos de entrenamiento: 0.911\n",
      "SVM : R2 Score en los datos de testeo: 0.800\n",
      "\n",
      "SVM : RMSE en los datos de entrenamiento: 0.922\n",
      "SVM : RMSE en los datos de testeo: 1.351\n",
      "\n",
      "SVM : Explained Variance en los datos de entrenamiento: 0.912\n",
      "SVM : Explained Variance en los datos de testeo: 0.802\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "C = 10, epsilon = 0.5, kernel = lineal\n",
      "SVM : MAE en los datos de entrenamiento: 0.562\n",
      "SVM : MAE en los datos de testeo: 0.643\n",
      "\n",
      "SVM : MSE en los datos de entrenamiento: 0.492\n",
      "SVM : MSE en los datos de testeo: 0.648\n",
      "\n",
      "SVM : R2 Score en los datos de entrenamiento: 0.948\n",
      "SVM : R2 Score en los datos de testeo: 0.929\n",
      "\n",
      "SVM : RMSE en los datos de entrenamiento: 0.701\n",
      "SVM : RMSE en los datos de testeo: 0.805\n",
      "\n",
      "SVM : Explained Variance en los datos de entrenamiento: 0.949\n",
      "SVM : Explained Variance en los datos de testeo: 0.930\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "C = 5, epsilon = 0.01, kernel = lineal\n",
      "SVM : MAE en los datos de entrenamiento: 0.517\n",
      "SVM : MAE en los datos de testeo: 0.632\n",
      "\n",
      "SVM : MSE en los datos de entrenamiento: 0.526\n",
      "SVM : MSE en los datos de testeo: 0.653\n",
      "\n",
      "SVM : R2 Score en los datos de entrenamiento: 0.945\n",
      "SVM : R2 Score en los datos de testeo: 0.929\n",
      "\n",
      "SVM : RMSE en los datos de entrenamiento: 0.725\n",
      "SVM : RMSE en los datos de testeo: 0.808\n",
      "\n",
      "SVM : Explained Variance en los datos de entrenamiento: 0.945\n",
      "SVM : Explained Variance en los datos de testeo: 0.930\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "C = 5, epsilon = 0.01, kernel = rbf\n",
      "SVM : MAE en los datos de entrenamiento: 0.047\n",
      "SVM : MAE en los datos de testeo: 0.709\n",
      "\n",
      "SVM : MSE en los datos de entrenamiento: 0.032\n",
      "SVM : MSE en los datos de testeo: 0.808\n",
      "\n",
      "SVM : R2 Score en los datos de entrenamiento: 0.997\n",
      "SVM : R2 Score en los datos de testeo: 0.912\n",
      "\n",
      "SVM : RMSE en los datos de entrenamiento: 0.180\n",
      "SVM : RMSE en los datos de testeo: 0.899\n",
      "\n",
      "SVM : Explained Variance en los datos de entrenamiento: 0.997\n",
      "SVM : Explained Variance en los datos de testeo: 0.912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de regresión:\n",
    "print(\"Sin hiperparámetros\")\n",
    "svm_modeltemp = aplicar_svm(dfesp_limpio, 'rain_days', tipo_modelo='regresion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"C = 10, epsilon = 0.5, kernel = lineal\")\n",
    "modeloesphiper = aplicar_svm_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', C=10.0, epsilon=0.5, kernel='linear')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"C = 5, epsilon = 0.01, kernel = lineal\")\n",
    "modeloesphiper2 = aplicar_svm_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', C=5.0, epsilon=0.01, kernel='linear')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"C = 5, epsilon = 0.01, kernel = rbf\")\n",
    "modeloesphiper2 = aplicar_svm_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', C=5.0, epsilon=0.01, kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Métrica                         | Sin Hiperparámetros         | C = 10, epsilon = 0.5, kernel = lineal | **C = 5, epsilon = 0.01, kernel = lineal** | C = 5, epsilon = 0.01, kernel = rbf |\n",
    "|----------------------------------|-----------------------------|---------------------------------------|-------------------------------------------|-------------------------------------|\n",
    "| **MAE**                          | 0.584 / 0.980               | 0.562 / 0.643                        | **0.517 / 0.632**                        | 0.047 / 0.709                      |\n",
    "| **MSE**                          | 0.851 / 1.827               | 0.492 / 0.648                        | **0.526 / 0.653**                        | 0.032 / 0.808                      |\n",
    "| **R2 Score**                     | 0.911 / 0.800               | 0.948 / 0.929                        | **0.945 / 0.929**                        | 0.997 / 0.912                      |\n",
    "| **RMSE**                         | 0.922 / 1.351               | 0.701 / 0.805                        | **0.725 / 0.808**                        | 0.180 / 0.899                      |\n",
    "| **Explained Variance**           | 0.912 / 0.802               | 0.949 / 0.930                        | **0.945 / 0.930**                        | 0.997 / 0.912                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusiones Resultados por modelos**\n",
    "* **C = 10, epsilon = 0.5, kernel = lineal** tenemos en comparación con el modelo sin hiperparámetros una notable mejora, ahora por ejemplo en el MAE, MSE y RMSE , los datos se han ajustado más y no hay una diferencia entre entrenamiento y testeo y por otro lado tenemos una mejora en R2 Score y Explained Variance, por lo que nuestro modelo ahora puede predecir con exactitud con un margen mas amplio de valores (dias de luvia).\n",
    "**Esto se ha logrado gracias** a **incluir una C alta** que ayuda cuando los datos de entrenamiento son representativos del problema y se ajusta mas a ellos, **incluir epsilon = 0.5** que ayuda que el modelo sea mas flexible e **incluir kernel = lineal** que ayuda a que el modelo sea menos propenso al sobreajuste.\n",
    "* **C = 5, epsilon = 0.01, kernel = lineal** al igual que la anterior, presenta una mejora al modelo de hiperparámetros pero con un ajuste menos pronunciado. lo que ha ayudado a superar en métricas al modelo anterior.\n",
    "**Esto se ha logrado gracias** a **C = 5** que ajusta el modelo a los datos de entrenamiento sin ser tan riguroso como con C = 10, permitiendo un equilibrio entre precisión y generalización, también por **bajar el a Epsilon = 0.01** bajando el margen de error, evitando que el modelo se ajuste demasiado a lso datos manteniendo la flexibilidad como vemos en las metricas de R2 y Variance.\n",
    "* **C = 5, epsilon = 0.01, kernel = rbf** presenta una mejora notable con respecto a los dos modelos anteriores, pero también muestra indicios de sobreajuste, especialmente en las métricas de MAE y MSE. A pesar de esto, el modelo logra una excelente capacidad predictiva, con un R2 Score y Explained Variance muy altos en los datos de entrenamiento, pero con una diferencia mayor en el testeo, lo que sugiere que el modelo está demasiado ajustado a los datos de entrenamiento. **El uso del kernel rbf** ha permitido una mayor complejidad en la transformación de los datos, lo que podría haber generado estas diferencias.\n",
    "\n",
    "#### A mi criterio me quedaría con el modelo de C = 5, epsilon = 0.01, kernel = lineal (Valores de MAE y MSE mas equilibrados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.1.2 SVM Aplicado a PHISHING URLS` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.953\n",
      "SVM : Exactitud en los datos de testeo: 0.951\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.958\n",
      "SVM : F1 Score en los datos de testeo: 0.957\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.969\n",
      "SVM : Sensibilidad en los datos de testeo: 0.973\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.947\n",
      "SVM : Precisión en los datos de testeo: 0.941\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.991\n",
      "SVM : AUC-ROC en los datos de testeo: 0.989\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.993\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.991\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "C = 10, kernel = lineal\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.926\n",
      "SVM : Exactitud en los datos de testeo: 0.935\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.934\n",
      "SVM : F1 Score en los datos de testeo: 0.942\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.943\n",
      "SVM : Sensibilidad en los datos de testeo: 0.955\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.926\n",
      "SVM : Precisión en los datos de testeo: 0.930\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.978\n",
      "SVM : AUC-ROC en los datos de testeo: 0.979\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.981\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.982\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "C = 5, kernel = rbf\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.972\n",
      "SVM : Exactitud en los datos de testeo: 0.966\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.975\n",
      "SVM : F1 Score en los datos de testeo: 0.970\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.980\n",
      "SVM : Sensibilidad en los datos de testeo: 0.978\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.969\n",
      "SVM : Precisión en los datos de testeo: 0.962\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.995\n",
      "SVM : AUC-ROC en los datos de testeo: 0.992\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.993\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "C = 10, kernel = rbf\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.976\n",
      "SVM : Exactitud en los datos de testeo: 0.963\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.978\n",
      "SVM : F1 Score en los datos de testeo: 0.967\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.982\n",
      "SVM : Sensibilidad en los datos de testeo: 0.975\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.974\n",
      "SVM : Precisión en los datos de testeo: 0.959\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.996\n",
      "SVM : AUC-ROC en los datos de testeo: 0.993\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de clasificación:\n",
    "print(\"Sin hiperparámetros\")\n",
    "svm_modelphishing = aplicar_svm(dfphishing_limpio, 'class', tipo_modelo='clasificacion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"C = 10, kernel = lineal\")\n",
    "modeloesphiper = aplicar_svm_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', C=10.0, kernel='linear')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"C = 5, kernel = rbf\")\n",
    "modeloesphiper2 = aplicar_svm_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', C=5.0, kernel='rbf')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"C = 10, kernel = rbf\")\n",
    "modeloesphiper2 = aplicar_svm_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', C=10.0, kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Métrica                         | Sin Hiperparámetros         | C = 10, kernel = lineal    | **C = 5, kernel = rbf**    | C = 10, kernel = rbf    |\n",
    "|----------------------------------|-----------------------------|----------------------------|---------------------------|-------------------------|\n",
    "| **Exactitud**                    | 0.953 / 0.951               | 0.926 / 0.935              | **0.972 / 0.966**         | 0.976 / 0.963           |\n",
    "| **F1 Score**                      | 0.958 / 0.957               | 0.934 / 0.942              | **0.975 / 0.970**         | 0.978 / 0.967           |\n",
    "| **Sensibilidad**                  | 0.969 / 0.973               | 0.943 / 0.955              | **0.980 / 0.978**         | 0.982 / 0.975           |\n",
    "| **Precisión**                     | 0.947 / 0.941               | 0.926 / 0.930              | **0.969 / 0.962**         | 0.974 / 0.959           |\n",
    "| **AUC-ROC**                       | 0.991 / 0.989               | 0.978 / 0.979              | **0.995 / 0.992**         | 0.996 / 0.993           |\n",
    "| **Precision-Recall AUC**          | 0.993 / 0.991               | 0.981 / 0.982              | **0.997 / 0.993**         | 0.997 / 0.994           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusiones Resultados por modelos**\n",
    "* **C = 10, kernel = lineal** En comparación con el modelo sin hiperparámetros, **presenta una ligera disminución en la exactitud, sensibilidad y precisión, lo que indica menor capacidad de generalización**. **Esto se debe a que C = 10 ajusta demasiado el modelo a los datos de entrenamiento**, pero sin lograr el mejor equilibrio con los datos de prueba.\n",
    "* **C = 5, kernel = rbf** **Mejora en todas las métricas, pero la diferencia entre entrenamiento y testeo es mayor**, lo que sugiere un posible sobreajuste. Esto ocurre porque el kernel rbf permite encontrar patrones complejos, lo que puede mejorar el rendimiento, pero también aumenta el riesgo de ajustarse demasiado a los datos de entrenamiento.\n",
    "* **C = 10, kernel = rbf** Mejor desempeño en entrenamiento, pero caída en testeo, lo que indica sobreajuste aún más pronunciado. Esto se debe a que al aumentar C a 10 junto con el kernel rbf, el modelo se vuelve más rígido y pierde capacidad de generalización.\n",
    "\n",
    "#### Me quedaría con el modelo de C = 5, kernel = rbf, ya que ofrece el mejor equilibrio entre precisión, sensibilidad y generalización, aunque con un pequeño sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.1.3 SVM Aplicado a CALIDAD DEL VINO` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.802\n",
      "SVM : Exactitud en los datos de testeo: 0.764\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.814\n",
      "SVM : F1 Score en los datos de testeo: 0.791\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.804\n",
      "SVM : Sensibilidad en los datos de testeo: 0.803\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.825\n",
      "SVM : Precisión en los datos de testeo: 0.779\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.878\n",
      "SVM : AUC-ROC en los datos de testeo: 0.874\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.892\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.898\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "C = 5, kernel = lineal\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.758\n",
      "SVM : Exactitud en los datos de testeo: 0.764\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.771\n",
      "SVM : F1 Score en los datos de testeo: 0.782\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.753\n",
      "SVM : Sensibilidad en los datos de testeo: 0.764\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.790\n",
      "SVM : Precisión en los datos de testeo: 0.802\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.828\n",
      "SVM : AUC-ROC en los datos de testeo: 0.833\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.851\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.843\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "C = 30, kernel = linear\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.759\n",
      "SVM : Exactitud en los datos de testeo: 0.764\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.772\n",
      "SVM : F1 Score en los datos de testeo: 0.782\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.753\n",
      "SVM : Sensibilidad en los datos de testeo: 0.764\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.791\n",
      "SVM : Precisión en los datos de testeo: 0.802\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.828\n",
      "SVM : AUC-ROC en los datos de testeo: 0.833\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.851\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.843\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "C = 5, kernel = rbf\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.829\n",
      "SVM : Exactitud en los datos de testeo: 0.786\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.839\n",
      "SVM : F1 Score en los datos de testeo: 0.805\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.822\n",
      "SVM : Sensibilidad en los datos de testeo: 0.795\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.857\n",
      "SVM : Precisión en los datos de testeo: 0.815\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.918\n",
      "SVM : AUC-ROC en los datos de testeo: 0.878\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.924\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.904\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "C = 30, kernel = rbf\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.900\n",
      "SVM : Exactitud en los datos de testeo: 0.795\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.907\n",
      "SVM : F1 Score en los datos de testeo: 0.813\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.903\n",
      "SVM : Sensibilidad en los datos de testeo: 0.803\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.912\n",
      "SVM : Precisión en los datos de testeo: 0.823\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.959\n",
      "SVM : AUC-ROC en los datos de testeo: 0.865\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.964\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicación de SVM en el dataset dfvino_limpio con distintas configuraciones de hiperparámetros\n",
    "\n",
    "print(\"Sin hiperparámetros\")\n",
    "svm_modelvino = aplicar_svm(dfvino_limpio, 'quality', tipo_modelo='clasificacion')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"C = 5, kernel = lineal\")\n",
    "modelo_vino_hiper1 = aplicar_svm_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', C=5, kernel='linear')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"C = 30, kernel = linear\")\n",
    "modelo_vino_hiper2 = aplicar_svm_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', C=30, kernel='linear')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"C = 5, kernel = rbf\")\n",
    "modelo_vino_hiper3 = aplicar_svm_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', C=5, kernel='rbf')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"C = 30, kernel = rbf\")\n",
    "modelo_vino_hiper4 = aplicar_svm_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', C=30, kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Métrica                         | Sin Hiperparámetros         | C = 5, kernel = lineal     | C = 30, kernel = lineal    | **C = 5, kernel = rbf**      | C = 30, kernel = rbf |\n",
    "|----------------------------------|----------------------------|----------------------------|----------------------------|--------------------------|--------------------------|\n",
    "| **Exactitud**                    | 0.802 / 0.764              | 0.758 / 0.764              | 0.759 / 0.764              | **0.829 / 0.786**            | 0.900 / 0.795    |\n",
    "| **F1 Score**                      | 0.814 / 0.791              | 0.771 / 0.782              | 0.772 / 0.782              | **0.839 / 0.805**            | 0.907 / 0.813      |\n",
    "| **Sensibilidad**                  | 0.804 / 0.803              | 0.753 / 0.764              | 0.753 / 0.764              | **0.822 / 0.795**            | 0.903 / 0.803     |\n",
    "| **Precisión**                      | 0.825 / 0.779              | 0.790 / 0.802              | 0.791 / 0.802              | **0.857 / 0.815**            | 0.912 / 0.823       |\n",
    "| **AUC-ROC**                        | 0.878 / 0.874              | 0.828 / 0.833              | 0.828 / 0.833              | **0.918 / 0.878**            | 0.959 / 0.865       |\n",
    "| **Precision-Recall AUC**           | 0.892 / 0.898              | 0.851 / 0.843              | 0.851 / 0.843              | **0.924 / 0.904**            | 0.964 / 0.878       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusiones por modelo**\n",
    "* **C = 5, kernel lineal y C = 30**, kernel lineal tienen resultados casi idénticos y no mejoran mucho respecto al modelo sin hiperparámetros.\n",
    "* **C = 5, kernel rbf** mejora las métricas, pero hay una diferencia notable entre entrenamiento y testeo, sobreajuste.\n",
    "* **C = 30, kernel rbf** tiene las mejores métricas en entrenamiento, pero pierde precisión en testeo, lo que indica un fuerte sobreajuste al igual que en el caso anterior.\n",
    "#### **El mejor modelo sería C = 5, kernel rbf**, ya que mejora el rendimiento sin un sobreajuste tan extremo como C = 30. Esto es gracias a que kernel = rbf pèrmite capturar relaciones mas complejas que el lineal pero por otra parte tenemos el riesgo de sobreajuste. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.1.4 SVM Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.987\n",
      "SVM : Exactitud en los datos de testeo: 0.956\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.982\n",
      "SVM : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.970\n",
      "SVM : Sensibilidad en los datos de testeo: 0.930\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.994\n",
      "SVM : Precisión en los datos de testeo: 0.952\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "SVM : AUC-ROC en los datos de testeo: 0.997\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.996\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "C = 2, kernel = lineal\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.989\n",
      "SVM : Exactitud en los datos de testeo: 0.982\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.985\n",
      "SVM : F1 Score en los datos de testeo: 0.977\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.976\n",
      "SVM : Sensibilidad en los datos de testeo: 0.977\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 0.994\n",
      "SVM : Precisión en los datos de testeo: 0.977\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.997\n",
      "SVM : AUC-ROC en los datos de testeo: 0.997\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.996\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "C = 15, kernel = linear\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.993\n",
      "SVM : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.991\n",
      "SVM : F1 Score en los datos de testeo: 0.953\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.982\n",
      "SVM : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 1.000\n",
      "SVM : Precisión en los datos de testeo: 0.953\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.999\n",
      "SVM : AUC-ROC en los datos de testeo: 0.980\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.998\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.984\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "C = 2, kernel = rbf\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.991\n",
      "SVM : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.988\n",
      "SVM : F1 Score en los datos de testeo: 0.953\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.976\n",
      "SVM : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 1.000\n",
      "SVM : Precisión en los datos de testeo: 0.953\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "SVM : AUC-ROC en los datos de testeo: 0.997\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 0.998\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.996\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "C = 15, kernel = rbf\n",
      "SVM : Exactitud en los datos de entrenamiento: 0.996\n",
      "SVM : Exactitud en los datos de testeo: 0.991\n",
      "\n",
      "SVM : F1 Score en los datos de entrenamiento: 0.994\n",
      "SVM : F1 Score en los datos de testeo: 0.988\n",
      "\n",
      "SVM : Sensibilidad en los datos de entrenamiento: 0.988\n",
      "SVM : Sensibilidad en los datos de testeo: 0.977\n",
      "\n",
      "SVM : Precisión en los datos de entrenamiento: 1.000\n",
      "SVM : Precisión en los datos de testeo: 1.000\n",
      "\n",
      "SVM : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "SVM : AUC-ROC en los datos de testeo: 0.998\n",
      "\n",
      "SVM : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "SVM : Precision-Recall AUC en los datos de testeo: 0.997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicación de SVM en el dataset dfcancer_limpio con distintas configuraciones de hiperparámetros\n",
    "\n",
    "print(\"Sin hiperparámetros\")\n",
    "svm_modelcancer = aplicar_svm(dfcancer_limpio, 'y', tipo_modelo='clasificacion')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"C = 2, kernel = lineal\")\n",
    "modelo_cancer_hiper1 = aplicar_svm_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', C=2, kernel='linear')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"C = 15, kernel = linear\")\n",
    "modelo_cancer_hiper2 = aplicar_svm_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', C=15, kernel='linear')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"C = 2, kernel = rbf\")\n",
    "modelo_cancer_hiper3 = aplicar_svm_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', C=2, kernel='rbf')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"C = 15, kernel = rbf\")\n",
    "modelo_cancer_hiper4 = aplicar_svm_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', C=15, kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Métrica                         | Sin Hiperparámetros         | **C = 2, kernel = lineal**      | C = 15, kernel = linear    | C = 2, kernel = rbf        | C = 15, kernel = rbf     |\n",
    "|----------------------------------|-----------------------------|----------------------------|----------------------------|---------------------------|--------------------------|\n",
    "| **Exactitud**                    | 0.987 / 0.956               | **0.989 / 0.982**              | 0.993 / 0.965              | 0.991 / 0.965             | 0.996 / 0.991            |\n",
    "| **F1 Score**                     | 0.982 / 0.941               | **0.985 / 0.977**              | 0.991 / 0.953              | 0.988 / 0.953             | 0.994 / 0.988            |\n",
    "| **Sensibilidad**                 | 0.970 / 0.930               | **0.976 / 0.977**              | 0.982 / 0.953              | 0.976 / 0.953             | 0.988 / 0.977            |\n",
    "| **Precisión**                    | 0.994 / 0.952               | **0.994 / 0.977**              | 1.000 / 0.953              | 1.000 / 0.953             | 1.000 / 1.000            |\n",
    "| **AUC-ROC**                      | 0.998 / 0.997               | **0.997 / 0.997**              | 0.999 / 0.980              | 0.998 / 0.997             | 1.000 / 0.998            |\n",
    "| **Precision-Recall AUC**         | 0.997 / 0.996               | **0.997 / 0.996**              | 0.998 / 0.984              | 0.998 / 0.996             | 1.000 / 0.997            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusiones de cada algoritmo**\n",
    "* **C = 2, kernel lineal** tiene un buen rendimiento tanto en entrenamiento como en testeo, con resultados bastante equilibrados, sin generar mucho sobreajuste.\n",
    "* **C = 15, kernel lineal** muestra una ligera mejora en los datos de entrenamiento, pero pierde algo de rendimiento en los datos de testeo, leve sobreajuste.\n",
    "* **C = 2, kernel rbf** ofrece un buen equilibrio, manteniendo un rendimiento sólido en ambos conjuntos, aunque también hay una ligera diferencia entre entrenamiento y testeo, algo de sobreajuste.\n",
    "* **C = 15, kernel rbf** tiene los mejores resultados en el entrenamiento, pero el modelo presenta un fuerte sobreajuste al perder precisión en los datos de testeo, a pesar de obtener buenos resultados en AUC-ROC y Precision-Recall AUC.\n",
    "#### **El mejor modelo sería C = 2, kernel lineal**, ya que ofrece un buen rendimiento general, sin sobreajuste y con métricas equilibradas tanto en el entrenamiento como en el testeo. Aunque C = 15, kernel rbf tiene el mejor rendimiento en entrenamiento, la diferencia con el testeo sugiere que el modelo está sobreajustado, por lo que es preferible usar valores más bajos para evitar esto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4.2 Regresión Logística con hiperparámetros`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui vamos a tener un problema, este método de regresión logística no tendría sentido aplicarlo en problemas de regresión, aunque su nombre puede ser confuso, la regresión logística es un modelo de clasificación, no de regresión. No debe usarse en problemas donde la variable objetivo es continua como en mi caso con rain_days del dataset TEMPERATURAS ESPAÑA.\n",
    "### Para los demás algoritmos y datasets no vamos a tener este problema.\n",
    "### Vamos a tener entonces para este algoritmo como métricas:\n",
    "* LogisticRegression() y métricas (Exactitud, F1 Score, Sensibilidad y Precisión) y añadidas (AUC-ROC y Precision-Recall AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un modelo de Regresión Logística con hiperparámetros\n",
    "def aplicar_regresion_logistica_hiper(df, target_column, solver='lbfgs', max_iter=100, penalty='l2', l1_ratio=None, tipo_modelo='clasificacion'):\n",
    "    # Separar las características (X) y la variable objetivo (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Verificar que 'l1_ratio' solo se use cuando 'penalty' sea 'elasticnet'\n",
    "    if penalty == 'elasticnet' and l1_ratio is None:\n",
    "        print(\"Advertencia: 'l1_ratio' es necesario cuando se usa 'elasticnet'.\")\n",
    "    elif penalty != 'elasticnet' and l1_ratio is not None:\n",
    "        print(\"Advertencia: 'l1_ratio' solo es relevante con 'elasticnet'.\")\n",
    "    \n",
    "    # Seleccionar el modelo de Regresión Logística con los hiperparámetros especificados\n",
    "    model = LogisticRegression(solver=solver, max_iter=max_iter, penalty=penalty, l1_ratio=l1_ratio)\n",
    "    \n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones sobre los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo con las métricas correspondientes\n",
    "    if tipo_modelo == 'clasificacion':\n",
    "        # Exactitud\n",
    "        exactitud_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        # F1 Score\n",
    "        f1_train = metrics.f1_score(y_train, y_train_pred, average='binary')  # Cambiar a 'micro' o 'macro' si es multiclase\n",
    "        f1_test = metrics.f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        # Sensibilidad (Recall)\n",
    "        sensibilidad_train = metrics.recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = metrics.recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        # Precisión\n",
    "        precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "        precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        # Probabilidades para AUC-ROC y Precision-Recall AUC\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Métricas adicionales\n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"Regresión Logística\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    else:\n",
    "        print(\"Tipo de modelo no válido. Debe ser 'clasificacion'.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hiperparámetros añadidos:\n",
    "* Solver (algoritmo de optimización)\n",
    "* Penalty (Tipo de regularización)\n",
    "* Max_iter (Número máximo de iteraciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Solver (algoritmo de optimización)**: Determina el algoritmo utilizado para encontrar los coeficientes de la regresión logística. vamos a usar:\n",
    "* 'liblinear': Usado en datasets pequeños o cuando se tiene un número bajo de características.\n",
    "* 'lbfgs': Ideal para datasets grandes, con muchas características.\n",
    "* 'saga': se usa cuando se tiene regularización elasticnet(parámetros del hiperparámetro Penalty(lo veremos a continuación)) o cuando el dataset es grande.\n",
    "### Usar 'liblinear' para conjuntos de datos pequeños, y 'lbfgs' o 'saga' para conjuntos de datos grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Penalty (Tipo de regularización)**: Controla el tipo de regularización que se aplica al modelo para evitar el sobreajuste. Usaremos:\n",
    "* 'l1': Regularización Lasso, que tiende a hacer que los coeficientes de algunas características sean exactamente 0 (lo que puede ser útil para la selección de características).\n",
    "* 'l2': Regularización Ridge, que penaliza todos los coeficientes de forma uniforme (es la opción más común).\n",
    "* 'elasticnet': Combina Lasso y Ridge.\n",
    "### Cuándo usarlo: 'l1' para modelos más simples, 'l2' cuando no se desee eliminar ninguna característica y 'elasticnet' para combinar lo mejor de ambos métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Max_iter (Número máximo de iteraciones)**: Este parámetro controla el número máximo de iteraciones que se utilizarán para la optimización del modelo. usaremos:\n",
    "* Valor común: El valor por defecto es 100, pero si el modelo no converge, puedes incrementarlo (por ejemplo, a 200 o 500).\n",
    "### Cuándo usarlo: Aumentaremos el valor de max_iter si el modelo no termina de ajustarse con el número predeterminado, especialmente en datasets grandes o complejos. Si el modelo ya se ajusta rápido, no hace falta cambiarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.2.1 Regresión logística Aplicado a TEMPERATURA ESPAÑA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicado arriba, no se puede usar para este dataset porque es de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.2.2 Regresión logística Aplicado a PHISHING URLS` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.934\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.935\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.943\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.930\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.979\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.980\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.983\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.984\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "solver = 'lbfgs', max_iter = 200, penalty = 'l2'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.934\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.935\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.943\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.930\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.979\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.980\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.983\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.984\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "solver = 'liblinear', max_iter = 100, penalty = 'l1'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.933\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.935\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.943\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.929\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.979\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.980\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.983\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.984\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "solver = 'saga', max_iter = 300, penalty = 'elasticnet'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.934\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.935\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.944\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.930\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.979\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.980\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.983\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.984\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "solver = 'liblinear', max_iter = 500, penalty = 'l2'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.934\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.935\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.944\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.927\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.930\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.979\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.980\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.983\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de clasificación:\n",
    "print(\"Sin hiperparámetros\")\n",
    "reg_log_model = aplicar_regresion_logistica_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"solver = 'lbfgs', max_iter = 200, penalty = 'l2'\")\n",
    "model_reg_log_1 = aplicar_regresion_logistica_hiper(dfphishing_limpio, 'class', solver='lbfgs', max_iter=200, penalty='l2')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"solver = 'liblinear', max_iter = 100, penalty = 'l1'\")\n",
    "model_reg_log_2 = aplicar_regresion_logistica_hiper(dfphishing_limpio, 'class', solver='liblinear', max_iter=100, penalty='l1')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"solver = 'saga', max_iter = 300, penalty = 'elasticnet'\")\n",
    "model_reg_log_3 = aplicar_regresion_logistica_hiper(dfphishing_limpio, 'class', solver='saga', max_iter=300, penalty='elasticnet', l1_ratio=0.5)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"solver = 'liblinear', max_iter = 500, penalty = 'l2'\")\n",
    "model_reg_log_4 = aplicar_regresion_logistica_hiper(dfphishing_limpio, 'class', solver='liblinear', max_iter=500, penalty='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                     | **Sin Hiperparámetros** | **solver = lbfgs, max_iter = 200, penalty = l2** | **solver = liblinear, max_iter = 100, penalty = l1** | **solver = saga, max_iter = 300, penalty = elasticnet** | **solver = liblinear, max_iter = 500, penalty = l2** |\n",
    "|----------------------------------|-------------------------|------------------------------------------------|-------------------------------------------------|-------------------------------------------------|------------------------------------------------|\n",
    "| **Exactitud**                    | **0.927 / 0.934**        | 0.927 / 0.934                                  | 0.927 / 0.933                                  | 0.927 / 0.934                                  | 0.927 / 0.934                                  |\n",
    "| **F1 Score**                      | **0.935 / 0.941**        | 0.935 / 0.941                                  | 0.935 / 0.941                                  | 0.935 / 0.941                                  | 0.935 / 0.941                                  |\n",
    "| **Sensibilidad**                  | **0.943 / 0.953**        | 0.943 / 0.953                                  | 0.943 / 0.953                                  | 0.944 / 0.953                                  | 0.944 / 0.953                                  |\n",
    "| **Precisión**                     | **0.927 / 0.930**        | 0.927 / 0.930                                  | 0.927 / 0.929                                  | 0.927 / 0.930                                  | 0.927 / 0.930                                  |\n",
    "| **AUC-ROC**                       | **0.979 / 0.980**        | 0.979 / 0.980                                  | 0.979 / 0.980                                  | 0.979 / 0.980                                  | 0.979 / 0.980                                  |\n",
    "| **Precision-Recall AUC**          | **0.983 / 0.984**        | 0.983 / 0.984                                  | 0.983 / 0.984                                  | 0.983 / 0.984                                  | 0.983 / 0.984                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de cada algoritmo:\n",
    "* **Sin hiperparámetros**: El modelo sin hiperparámetros ya presenta buenos resultados, con métricas bastante altas entre entrenamiento y testeo.\n",
    "* **solver = 'lbfgs', max_iter = 200, penalty = 'l2':** prácticamente idénticos al modelo sin hiperparámetros, el optimizador lbfgs y la penalización L2 no aportan mejoras significativas en este caso.\n",
    "* **solver = 'liblinear', max_iter = 100, penalty = 'l1':** Hay una mínima reducción en la exactitud y la precisión en testeo, pero la diferencia es insignificante. Esto sugiere que la penalización L1 (que tiende a eliminar variables irrelevantes) no tuvo un gran impacto en este dataset.\n",
    "* **solver = 'saga', max_iter = 300, penalty = 'elasticnet':** Similar a los casos anteriores, con valores prácticamente iguales. La ligera mejora en sensibilidad en entrenamiento indica que el modelo puede estar ajustando mejor algunos casos, pero sin generar un impacto relevante en generalización.\n",
    "* **solver = 'liblinear', max_iter = 500, penalty = 'l2':** No presenta cambios notables respecto a los otros modelos, lo que indica que aumentar las iteraciones y usar penalización L2 no ofrece beneficios en este contexto.\n",
    "#### Me quedaría con el primer modelo sin hiperparámetros para mejorar eficiencia y simplicidad y además porque no mejora tanto como para elegir uno de los que hemos usado hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.2.3 Regresión logística Aplicado a CALIDAD DEL VINO` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.758\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.769\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.774\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.791\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.767\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.787\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.781\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.794\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.829\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.822\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.853\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.835\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "solver = 'liblinear', max_iter = 200, penalty = 'l1'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.760\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.769\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.776\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.791\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.769\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.787\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.784\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.794\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.829\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.823\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.853\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.835\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "solver = 'lbfgs', max_iter = 200, penalty = 'l2'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.758\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.769\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.774\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.791\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.767\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.787\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.781\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.794\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.829\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.822\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.853\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.835\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "solver = 'saga', max_iter = 300, penalty = 'elasticnet'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.759\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.769\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.776\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.791\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.769\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.787\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.782\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.794\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.829\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.823\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.853\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.835\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "solver = 'liblinear', max_iter = 100, penalty = 'l2'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.757\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.769\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.773\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.791\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.765\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.787\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.781\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.794\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.829\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.822\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.853\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de clasificación con diferentes combinaciones de hiperparámetros:\n",
    "\n",
    "print(\"Sin hiperparámetros\")\n",
    "reg_log_model = aplicar_regresion_logistica(dfvino_limpio, 'quality', tipo_modelo='clasificacion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"solver = 'liblinear', max_iter = 200, penalty = 'l1'\")\n",
    "model_reg_log_1h = aplicar_regresion_logistica_hiper(dfvino_limpio, 'quality', solver='liblinear', max_iter=200, penalty='l1')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"solver = 'lbfgs', max_iter = 200, penalty = 'l2'\")\n",
    "model_reg_log_2h = aplicar_regresion_logistica_hiper(dfvino_limpio, 'quality', solver='lbfgs', max_iter=200, penalty='l2')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"solver = 'saga', max_iter = 300, penalty = 'elasticnet'\")\n",
    "model_reg_log_3h = aplicar_regresion_logistica_hiper(dfvino_limpio, 'quality', solver='saga', max_iter=300, penalty='elasticnet', l1_ratio=0.5)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"solver = 'liblinear', max_iter = 100, penalty = 'l2'\")\n",
    "model_reg_log_4h = aplicar_regresion_logistica_hiper(dfvino_limpio, 'quality', solver='liblinear', max_iter=100, penalty='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                     | **Sin Hiperparámetros** | **solver = liblinear, max_iter = 200, penalty = l1** | **solver = lbfgs, max_iter = 200, penalty = l2** | **solver = saga, max_iter = 300, penalty = elasticnet** | **solver = liblinear, max_iter = 100, penalty = l2** |\n",
    "|----------------------------------|-------------------------|-----------------------------------------------------|-------------------------------------------------|-------------------------------------------------|------------------------------------------------|\n",
    "| **Exactitud**                    | **0.758 / 0.769**        | 0.761 / 0.769                                       | 0.758 / 0.769                                  | 0.759 / 0.769                                  | 0.757 / 0.769                                  |\n",
    "| **F1 Score**                      | **0.774 / 0.791**        | 0.777 / 0.791                                       | 0.774 / 0.791                                  | 0.776 / 0.791                                  | 0.773 / 0.791                                  |\n",
    "| **Sensibilidad**                  | **0.767 / 0.787**        | 0.769 / 0.787                                       | 0.767 / 0.787                                  | 0.769 / 0.787                                  | 0.765 / 0.787                                  |\n",
    "| **Precisión**                     | **0.781 / 0.794**        | 0.785 / 0.794                                       | 0.781 / 0.794                                  | 0.782 / 0.794                                  | 0.781 / 0.794                                  |\n",
    "| **AUC-ROC**                       | **0.829 / 0.822**        | 0.829 / 0.824                                       | 0.829 / 0.822                                  | 0.829 / 0.823                                  | 0.829 / 0.822                                  |\n",
    "| **Precision-Recall AUC**          | **0.853 / 0.835**        | 0.853 / 0.836                                       | 0.853 / 0.835                                  | 0.853 / 0.835                                  | 0.853 / 0.834                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones Resultados por modelos\n",
    "* **Sin Hiperparámetros**: Buen rendimiento general, con métricas sólidas y equilibradas.\n",
    "* **solver = liblinear, max_iter = 200, penalty = l1**: Mejora ligera en AUC-ROC y Precision-Recall AUC, sin cambios importantes.\n",
    "* **solver = lbfgs, max_iter = 200, penalty = l2**: Resultados similares al modelo sin hiperparámetros.\n",
    "* **solver = saga, max_iter = 300, penalty = elasticnet**: Métricas casi iguales al modelo sin ajustes.\n",
    "* **solver = liblinear, max_iter = 100, penalty = l2**: Sutil mejora en AUC-ROC, pero sin diferencia importante.\n",
    "#### Me quedo con el modelo sin hiperparámetros, ya que no hay mejoras significativas con los ajustes o quizas con el modelo solver = liblinear, max_iter = 200, penalty = l1 que si parece que mejora un poco comparado al de sin hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.2.4 Regresión logística Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.991\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.988\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.976\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 1.000\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.995\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.993\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "solver = 'liblinear', max_iter = 200, penalty = 'l1'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.989\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.956\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.985\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.976\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.930\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 0.994\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.952\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.996\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.994\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "solver = 'lbfgs', max_iter = 200, penalty = 'l2'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.991\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.988\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.976\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 1.000\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.995\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.993\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "solver = 'saga', max_iter = 300, penalty = 'elasticnet'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.991\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.988\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.976\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 1.000\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.997\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.996\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.994\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "solver = 'liblinear', max_iter = 100, penalty = 'l2'\n",
      "Regresión Logística : Exactitud en los datos de entrenamiento: 0.991\n",
      "Regresión Logística : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "Regresión Logística : F1 Score en los datos de entrenamiento: 0.988\n",
      "Regresión Logística : F1 Score en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Sensibilidad en los datos de entrenamiento: 0.976\n",
      "Regresión Logística : Sensibilidad en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : Precisión en los datos de entrenamiento: 1.000\n",
      "Regresión Logística : Precisión en los datos de testeo: 0.953\n",
      "\n",
      "Regresión Logística : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "Regresión Logística : AUC-ROC en los datos de testeo: 0.995\n",
      "\n",
      "Regresión Logística : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "Regresión Logística : Precision-Recall AUC en los datos de testeo: 0.993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\domid\\Desktop\\210MIA\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# modelo de clasificación con hiperparámetros para dfcancer_limpio:\n",
    "print(\"Sin hiperparámetros\")\n",
    "reg_log_modelc = aplicar_regresion_logistica(dfcancer_limpio, 'y', tipo_modelo='clasificacion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"solver = 'liblinear', max_iter = 200, penalty = 'l1'\")\n",
    "model_reg_log_1hc = aplicar_regresion_logistica_hiper(dfcancer_limpio, 'y', solver='liblinear', max_iter=200, penalty='l1')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"solver = 'lbfgs', max_iter = 200, penalty = 'l2'\")\n",
    "model_reg_log_2hc = aplicar_regresion_logistica_hiper(dfcancer_limpio, 'y', solver='lbfgs', max_iter=200, penalty='l2')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"solver = 'saga', max_iter = 300, penalty = 'elasticnet'\")\n",
    "model_reg_log_3hc = aplicar_regresion_logistica_hiper(dfcancer_limpio, 'y', solver='saga', max_iter=300, penalty='elasticnet', l1_ratio=0.5)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"solver = 'liblinear', max_iter = 100, penalty = 'l2'\")\n",
    "model_reg_log_4hc = aplicar_regresion_logistica_hiper(dfcancer_limpio, 'y', solver='liblinear', max_iter=100, penalty='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                     | **Sin Hiperparámetros** | **solver = liblinear, max_iter = 200, penalty = l1** | **solver = lbfgs, max_iter = 200, penalty = l2** | **solver = saga, max_iter = 300, penalty = elasticnet** | **solver = liblinear, max_iter = 100, penalty = l2** |\n",
    "|----------------------------------|-------------------------|-----------------------------------------------------|-------------------------------------------------|-------------------------------------------------|------------------------------------------------|\n",
    "| **Exactitud**                    | **0.991 / 0.965**        | 0.989 / 0.956                                       | 0.991 / 0.965                                  | 0.991 / 0.965                                  | 0.991 / 0.965                                  |\n",
    "| **F1 Score**                      | **0.988 / 0.953**        | 0.985 / 0.941                                       | 0.988 / 0.953                                  | 0.988 / 0.953                                  | 0.988 / 0.953                                  |\n",
    "| **Sensibilidad**                  | **0.976 / 0.953**        | 0.976 / 0.930                                       | 0.976 / 0.953                                  | 0.976 / 0.953                                  | 0.976 / 0.953                                  |\n",
    "| **Precisión**                     | **1.000 / 0.953**        | 0.994 / 0.952                                       | 1.000 / 0.953                                  | 1.000 / 0.953                                  | 1.000 / 0.953                                  |\n",
    "| **AUC-ROC**                       | **0.998 / 0.995**        | 0.998 / 0.996                                       | 0.997 / 0.996                                  | 0.997 / 0.996                                  | 0.998 / 0.995                                  |\n",
    "| **Precision-Recall AUC**          | **0.997 / 0.993**        | 0.997 / 0.994                                       | 0.997 / 0.994                                  | 0.997 / 0.994                                  | 0.997 / 0.993                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones por modelo:\n",
    "* **Sin Hiperparámetros**: El modelo sin hiperparámetros tiene un rendimiento muy alto, con exactitudes cercanas al 99% en entrenamiento y 96% en testeo. Sin embargo, aunque la precisión y F1 score son excelentes, no hay mucha diferencia entre entrenamiento y testeo, lo que sugiere que el modelo ya está muy ajustado.\n",
    "\n",
    "* **solver = 'liblinear', max_iter = 200, penalty = 'l1'**: Aquí, se observa una ligera disminución en la exactitud, F1 Score y sensibilidad en los datos de testeo. Este cambio es probablemente debido a la penalización 'l1', que ayuda a hacer el modelo más simple, pero ligeramente menos preciso en testeo.\n",
    "\n",
    "* **solver = 'lbfgs', max_iter = 200, penalty = 'l2'**: No hay grandes diferencias respecto al caso sin hiperparámetros. Esto se debe a que 'l2' es una penalización más suave, lo que mantiene la capacidad de generalización del modelo sin perder precisión en los datos de testeo.\n",
    "\n",
    "* **solver = 'saga', max_iter = 300, penalty = 'elasticnet'**: Similar al caso anterior, pero con 'elasticnet' que combina 'l1' y 'l2'. El rendimiento sigue siendo excelente, pero con la ventaja de tener una penalización más equilibrada.\n",
    "\n",
    "* **solver = 'liblinear', max_iter = 100, penalty = 'l2'**: La disminución en el rendimiento es mínima, aunque al reducir el número de iteraciones a 100, el modelo podría no haber tenido suficiente tiempo para entrenarse de manera óptima.\n",
    "#### Como en el caso anterior: Me quedaría con el modelo sin hiperparámetros, ya que ofrece el mejor rendimiento general y no presenta grandes sobreajustes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4.3 Árboles de Decisión con hiperparámetros`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a tener entonces en esta función para aplicar a cada dataset:\n",
    "### para clasificación:\n",
    "* DecisionTreeClassifier()  y métricas (Exactitud, F1 Score, Sensibilidad y Precisión) y añadidas (AUC-ROC y Precision-Recall AUC)\n",
    "### para regresión:\n",
    "* DecisionTreeRegressor() y métricas (MAE, MSE, R2 Score) y añadidas (RMSE y Explained Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un modelo de Árbol de Decisión con hiperparámetros\n",
    "def aplicar_arbol_decision_hiper(df, target_column, tipo_modelo='regresion', max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "    # Separar las características (X) y la variable objetivo (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Seleccionar el modelo dependiendo del tipo (regresión o clasificación)\n",
    "    if tipo_modelo == 'regresion':\n",
    "        model = DecisionTreeRegressor(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones sobre los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo con las métricas correspondientes\n",
    "    if tipo_modelo == 'regresion':\n",
    "        # Métricas existentes\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"MAE\", mae_train, mae_test)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"MSE\", mse_train, mse_test)\n",
    "        \n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"R2 Score\", r2_train, r2_test)\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        rmse_train, evs_train = metricas_regresion_adicionales(y_train, y_train_pred)\n",
    "        rmse_test, evs_test = metricas_regresion_adicionales(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"RMSE\", rmse_train, rmse_test)\n",
    "        mostrarMetricasRegresion(\"Árbol de Decisión\", \"Explained Variance\", evs_train, evs_test)\n",
    "    \n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        # Métricas existentes\n",
    "        exactitud_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        f1_train = metrics.f1_score(y_train, y_train_pred, average='binary')  # Cambiar a 'micro' o 'macro' si es multiclase\n",
    "        f1_test = metrics.f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        sensibilidad_train = metrics.recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = metrics.recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "        precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        # Probabilidades para AUC-ROC y Precision-Recall AUC\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"Árbol de Decisión\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a incluir los siguientes hiperparámetros:\n",
    "* max_depth (Profundidad máxima)\n",
    "* min_samples_split (Mínimo número de muestras para dividir un nodo)\n",
    "* min_samples_leaf (Mínimo número de muestras en una hoja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **max_depth (Profundidad máxima)**: Controla la profundidad máxima de los árboles. Un valor mayor puede llevar a sobreajuste, ya que el árbol se ajustará demasiado a los datos de entrenamiento. Si es más pequeño, el árbol será menos complejo y podría no captar patrones importantes.\n",
    "### Cuándo usarlo: Se recomienda usar un valor pequeño para evitar el sobreajuste, especialmente en datasets pequeños o cuando hay mucho ruido. Si el modelo es demasiado simple, puede ser necesario incrementar este parámetro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **min_samples_split (Mínimo número de muestras para dividir un nodo)**: Especifica el número mínimo de muestras que deben estar presentes en un nodo antes de dividirlo. Si el valor es mayor, el árbol será menos profundo y menos susceptible al sobreajuste.\n",
    "### Cuándo usarlo: Si se tienen datos ruidosos o el modelo está sobreajustando, se puede aumentar este valor. Para datasets más pequeños, un valor bajo permite mayor flexibilidad y potencialmente mejor desempeño en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **min_samples_leaf (Mínimo número de muestras en una hoja)**: Controla el número mínimo de muestras que deben estar en cada hoja del árbol. Esto asegura que las hojas no contengan pocos puntos de datos y que el modelo no se ajuste demasiado a las pequeñas variaciones.\n",
    "### Cuándo usarlo: Es útil cuando se quiere evitar un sobreajuste excesivo, especialmente en datasets pequeños o con pocas muestras. Si se incrementa este valor, el árbol será más general y menos propenso a sobreajustar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.3.1 Árboles de Decisión Aplicado a TEMPERATURA ESPAÑA` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Árbol de Decisión : MAE en los datos de entrenamiento: 0.000\n",
      "Árbol de Decisión : MAE en los datos de testeo: 0.583\n",
      "\n",
      "Árbol de Decisión : MSE en los datos de entrenamiento: 0.000\n",
      "Árbol de Decisión : MSE en los datos de testeo: 0.792\n",
      "\n",
      "Árbol de Decisión : R2 Score en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : R2 Score en los datos de testeo: 0.913\n",
      "\n",
      "Árbol de Decisión : RMSE en los datos de entrenamiento: 0.000\n",
      "Árbol de Decisión : RMSE en los datos de testeo: 0.890\n",
      "\n",
      "Árbol de Decisión : Explained Variance en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Explained Variance en los datos de testeo: 0.915\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "max_depth = 5, min_samples_split = 4, min_samples_leaf = 2\n",
      "Árbol de Decisión : MAE en los datos de entrenamiento: 0.520\n",
      "Árbol de Decisión : MAE en los datos de testeo: 0.723\n",
      "\n",
      "Árbol de Decisión : MSE en los datos de entrenamiento: 0.567\n",
      "Árbol de Decisión : MSE en los datos de testeo: 1.054\n",
      "\n",
      "Árbol de Decisión : R2 Score en los datos de entrenamiento: 0.941\n",
      "Árbol de Decisión : R2 Score en los datos de testeo: 0.885\n",
      "\n",
      "Árbol de Decisión : RMSE en los datos de entrenamiento: 0.753\n",
      "Árbol de Decisión : RMSE en los datos de testeo: 1.027\n",
      "\n",
      "Árbol de Decisión : Explained Variance en los datos de entrenamiento: 0.941\n",
      "Árbol de Decisión : Explained Variance en los datos de testeo: 0.887\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "max_depth = 10, min_samples_split = 5, min_samples_leaf = 1\n",
      "Árbol de Decisión : MAE en los datos de entrenamiento: 0.207\n",
      "Árbol de Decisión : MAE en los datos de testeo: 0.675\n",
      "\n",
      "Árbol de Decisión : MSE en los datos de entrenamiento: 0.155\n",
      "Árbol de Decisión : MSE en los datos de testeo: 1.006\n",
      "\n",
      "Árbol de Decisión : R2 Score en los datos de entrenamiento: 0.984\n",
      "Árbol de Decisión : R2 Score en los datos de testeo: 0.890\n",
      "\n",
      "Árbol de Decisión : RMSE en los datos de entrenamiento: 0.394\n",
      "Árbol de Decisión : RMSE en los datos de testeo: 1.003\n",
      "\n",
      "Árbol de Decisión : Explained Variance en los datos de entrenamiento: 0.984\n",
      "Árbol de Decisión : Explained Variance en los datos de testeo: 0.895\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "max_depth = None (sin límite), min_samples_split = 10, min_samples_leaf = 3\n",
      "Árbol de Decisión : MAE en los datos de entrenamiento: 0.385\n",
      "Árbol de Decisión : MAE en los datos de testeo: 0.639\n",
      "\n",
      "Árbol de Decisión : MSE en los datos de entrenamiento: 0.321\n",
      "Árbol de Decisión : MSE en los datos de testeo: 0.846\n",
      "\n",
      "Árbol de Decisión : R2 Score en los datos de entrenamiento: 0.966\n",
      "Árbol de Decisión : R2 Score en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : RMSE en los datos de entrenamiento: 0.566\n",
      "Árbol de Decisión : RMSE en los datos de testeo: 0.920\n",
      "\n",
      "Árbol de Decisión : Explained Variance en los datos de entrenamiento: 0.966\n",
      "Árbol de Decisión : Explained Variance en los datos de testeo: 0.910\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "max_depth = 3, min_samples_split = 2, min_samples_leaf = 4\n",
      "Árbol de Decisión : MAE en los datos de entrenamiento: 0.776\n",
      "Árbol de Decisión : MAE en los datos de testeo: 0.886\n",
      "\n",
      "Árbol de Decisión : MSE en los datos de entrenamiento: 1.036\n",
      "Árbol de Decisión : MSE en los datos de testeo: 1.377\n",
      "\n",
      "Árbol de Decisión : R2 Score en los datos de entrenamiento: 0.891\n",
      "Árbol de Decisión : R2 Score en los datos de testeo: 0.849\n",
      "\n",
      "Árbol de Decisión : RMSE en los datos de entrenamiento: 1.018\n",
      "Árbol de Decisión : RMSE en los datos de testeo: 1.174\n",
      "\n",
      "Árbol de Decisión : Explained Variance en los datos de entrenamiento: 0.891\n",
      "Árbol de Decisión : Explained Variance en los datos de testeo: 0.850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de regresión con Árbol de Decisión:\n",
    "print(\"Sin hiperparámetros\")\n",
    "arbol_modelo_temp = aplicar_arbol_decision(dfesp_limpio, 'rain_days', tipo_modelo='regresion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"max_depth = 5, min_samples_split = 4, min_samples_leaf = 2\")\n",
    "arbol_hiper_esp = aplicar_arbol_decision_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', max_depth=5, min_samples_split=4, min_samples_leaf=2)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"max_depth = 10, min_samples_split = 5, min_samples_leaf = 1\")\n",
    "arbol_hiper_esp2 = aplicar_arbol_decision_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', max_depth=10, min_samples_split=5, min_samples_leaf=1)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"max_depth = None (sin límite), min_samples_split = 10, min_samples_leaf = 3\")\n",
    "arbol_hiper_esp3 = aplicar_arbol_decision_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', max_depth=None, min_samples_split=10, min_samples_leaf=3)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"max_depth = 3, min_samples_split = 2, min_samples_leaf = 4\")\n",
    "arbol_hiper_esp4 = aplicar_arbol_decision_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', max_depth=3, min_samples_split=2, min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ya hemos comentado lo de los datos de entrenamiento a 0.000 para el sin hiperparámetros cuando probamos el modelo sin hiperparámetros en el punto 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**  | **max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**  | **max_depth = 10, min_samples_split = 5, min_samples_leaf = 1** | **max_depth = None, min_samples_split = 10, min_samples_leaf = 3** | **max_depth = 3, min_samples_split = 2, min_samples_leaf = 4** |\n",
    "|------------------------------------|--------------------------|-------------------------------------------------------------|-------------------------------------------------------------|-----------------------------------------------------------------|--------------------------------------------------------------|\n",
    "| **MAE**                            | 0.000 / 0.583            | **0.520 / 0.700**                                               | 0.207 / 0.630                                               | 0.385 / 0.636 | 0.776 / 0.886                                                 |\n",
    "| **MSE**                            | 0.000 / 0.688            | **0.567 / 0.907**                                              | 0.155 / 0.900                                               | 0.321 / 0.845   | 1.036 / 1.377                                                 |\n",
    "| **R2 Score**                       | 1.000 / 0.925            | **0.941 / 0.901**                                               | 0.984 / 0.902                                               | 0.966 / 0.908    | 0.891 / 0.849                                                 |\n",
    "| **RMSE**                           | 0.000 / 0.829            | **0.753 / 0.953**                                               | 0.394 / 0.949                                               | 0.566 / 0.919     | 1.018 / 1.174                                                 |\n",
    "| **Explained Variance**             | 1.000 / 0.929            | **0.941 / 0.902**                                               | 0.984 / 0.905                                               | 0.966 / 0.910    | 0.891 / 0.850                                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación por modelo:\n",
    "* **(max_depth = 5, min_samples_split = 4, min_samples_leaf = 2)**: Aquí el modelo parece balancear bien el ajuste entre el entrenamiento y la prueba, ya que tiene buenos valores de R2 (0.941 en entrenamiento, 0.901 en prueba) y errores razonables. Esto es gracias a los parámetros min_samples_split = 4 y min_samples_leaf = 2 que aseguran que el modelo no se haga demasiado específico o demasiado general. Es una configuración que favorece una buena generalización, haciendo que el modelo se desempeñe de manera consistente tanto en los datos de entrenamiento como en los de prueba.\n",
    "* **(max_depth = 10, min_samples_split = 5, min_samples_leaf = 1)**: Este modelo tiene un mejor rendimiento en entrenamiento (R2 = 0.984), pero el rendimiento en prueba baja un poco, se está acercando al sobreajuste. esto se debe a que al tener un max_depth alto y min_samples_leaf bajo, se captura más detalle, pero el modelo empieza a ajustarse demasiado a las fluctuaciones de los datos de entrenamiento, lo que afecta la generalización.\n",
    "* **(max_depth = None, min_samples_split = 10, min_samples_leaf = 3)**: Con máximo de profundidad sin límite, el modelo parece generalizar bastante bien, con un R2 de 0.966 en entrenamiento y 0.908 en prueba, tiene buena capacidad de generalización.  Esto muestra que, aunque el árbol tiene suficiente capacidad para aprender de los datos, al establecer valores más altos en min_samples_split y min_samples_leaf, se asegura que las divisiones sean significativas, lo que ayuda a evitar el overfitting y mejora la generalización.\n",
    "* **(max_depth = 3, min_samples_split = 2, min_samples_leaf = 4)**: Este modelo muestra bajo rendimiento en los datos de entrenamiento y prueba, con un R2 de 0.891 en entrenamiento y 0.849 en prueba. Los errores también son más altos.\n",
    "#### Con cuál me quedaría:\n",
    "* Modelo 1 **(max_depth = 5, min_samples_split = 4, min_samples_leaf = 2)** parece ser el más equilibrado. Tiene buen rendimiento en entrenamiento y prueba, con un R2 razonable y errores moderados y no está sobreajustado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.3.2 Árboles de Decisión Aplicado a PHISHING URLS` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.991\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.959\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.992\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.963\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.991\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.961\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.993\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.966\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.972\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.966\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "max_depth = 5, min_samples_split = 4, min_samples_leaf = 2\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.922\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.927\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.932\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.937\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.972\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.975\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.896\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.903\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 0.978\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.977\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 0.977\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.975\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "max_depth = 10, min_samples_split = 5, min_samples_leaf = 1\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.958\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.949\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.962\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.954\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.958\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.951\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.967\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.958\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 0.995\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.984\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 0.996\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.982\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "max_depth = None (sin límite), min_samples_split = 10, min_samples_leaf = 3\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.973\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.952\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.976\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.957\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.978\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.958\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.974\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.956\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.982\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 0.998\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.979\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "max_depth = 3, min_samples_split = 2, min_samples_leaf = 4\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.907\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.910\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.921\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.924\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.978\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.978\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.871\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.875\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 0.957\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.962\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 0.942\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de clasificación con Árbol de Decisión:\n",
    "# Sin hiperparámetros\n",
    "print(\"Sin hiperparámetros\")\n",
    "arbol_modelo_ph = aplicar_arbol_decision(dfphishing_limpio, 'class', tipo_modelo='clasificacion')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"max_depth = 5, min_samples_split = 4, min_samples_leaf = 2\")\n",
    "arbol_hiper_ph = aplicar_arbol_decision_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', max_depth=5, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"max_depth = 10, min_samples_split = 5, min_samples_leaf = 1\")\n",
    "arbol_hiper_ph2 = aplicar_arbol_decision_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', max_depth=10, min_samples_split=5, min_samples_leaf=1)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"max_depth = None (sin límite), min_samples_split = 10, min_samples_leaf = 3\")\n",
    "arbol_hiper_ph3 = aplicar_arbol_decision_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', max_depth=None, min_samples_split=10, min_samples_leaf=3)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"max_depth = 3, min_samples_split = 2, min_samples_leaf = 4\")\n",
    "arbol_hiper_ph4 = aplicar_arbol_decision_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', max_depth=3, min_samples_split=2, min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**  | **max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**  | **max_depth = 10, min_samples_split = 5, min_samples_leaf = 1** | **max_depth = None, min_samples_split = 10, min_samples_leaf = 3** | **max_depth = 3, min_samples_split = 2, min_samples_leaf = 4** |\n",
    "|------------------------------------|--------------------------|-------------------------------------------------------------|-------------------------------------------------------------|-----------------------------------------------------------------|--------------------------------------------------------------|\n",
    "| **Exactitud**                      | 0.991 / 0.960            | **0.922 / 0.927**                                               | 0.958 / 0.950                                               | 0.973 / 0.952        | 0.907 / 0.910                                                 |\n",
    "| **F1 Score**                       | 0.992 / 0.964            | **0.932 / 0.937**                                              | 0.962 / 0.955                                               | 0.976 / 0.957         | 0.921 / 0.924                                                 |\n",
    "| **Sensibilidad**                   | 0.991 / 0.964            | **0.972 / 0.975**                                              | 0.958 / 0.953                                               | 0.978 / 0.959         | 0.978 / 0.978                                                 |\n",
    "| **Precisión**                      | 0.993 / 0.964            | **0.896 / 0.903**                                              | 0.967 / 0.958                                               | 0.974 / 0.956         | 0.871 / 0.875                                                 |\n",
    "| **AUC-ROC**                        | 1.000 / 0.972            | **0.978 / 0.977**                                              | 0.995 / 0.984                                               | 0.998 / 0.982         | 0.957 / 0.962                                                 |\n",
    "| **Precision-Recall AUC**           | 1.000 / 0.966            | **0.977 / 0.975**                                              | 0.996 / 0.983                                               | 0.998 / 0.979         | 0.942 / 0.948                                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de cada modelo:\n",
    "* **Sin Hiperparámetros**: El modelo tiene un excelente rendimiento tanto en entrenamiento como en prueba, con altas métricas. La falta de hiperparámetros ajustados puede llevar a sobreajuste, especialmente en el conjunto de datos de prueba.\n",
    "* **max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**: Buen equilibrio entre ajuste y generalización, con métricas estables tanto en entrenamiento como en prueba.\n",
    "Los valores moderados de estos hiperparámetros permiten que el árbol no se vuelva demasiado complejo, evitando el sobreajuste.\n",
    "* **max_depth = 10, min_samples_split = 5, min_samples_leaf = 1**: Buen rendimiento en entrenamiento, pero podría estar acercándose al sobreajuste con valores de prueba ligeramente más bajos.\n",
    "Los hiperparámetros con mayor profundidad y menor número de muestras por nodo permiten una mayor complejidad, pero también pueden causar que el modelo aprenda demasiado de los datos de entrenamiento.\n",
    "* **max_depth = None, min_samples_split = 10, min_samples_leaf = 3**: El modelo tiene buen rendimiento en los datos de prueba, con una buena capacidad de generalización.\n",
    "Sin límite de profundidad, el modelo puede capturar más patrones, pero los valores de mínimo de muestras y hojas ayudan a mantener el control, evitando el sobreajuste.\n",
    "* **max_depth = 3, min_samples_split = 2, min_samples_leaf = 4:** Bajo rendimiento tanto en entrenamiento como en prueba, con métricas más bajas. El límite de profundidad pequeño y los pocos datos mínimos por nodo hacen que el modelo sea demasiado simple, resultando en un ajuste insuficiente (underfitting).\n",
    "####  Me quedaría con el modelo con **max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**, ya que ofrece un buen balance entre generalización y ajuste, con métricas altas en ambos conjuntos de datos. Los hiperparámetros permiten evitar tanto el sobreajuste como el underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.3.3 Árboles de Decisión Aplicado a CALIDAD DEL VINO` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.712\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.738\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.732\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.744\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.709\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.693\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "max_depth = 5, min_samples_split = 4, min_samples_leaf = 2\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.821\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.742\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.836\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.761\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.846\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.740\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.826\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.783\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 0.892\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.777\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 0.886\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.798\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "max_depth = 10, min_samples_split = 5, min_samples_leaf = 1\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.955\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.681\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.958\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.711\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.955\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.709\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.961\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.714\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 0.993\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.679\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 0.992\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.668\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "max_depth = None (sin límite), min_samples_split = 10, min_samples_leaf = 3\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.909\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.707\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.915\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.722\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.905\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.685\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.925\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.763\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 0.979\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.755\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 0.981\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.755\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "max_depth = 3, min_samples_split = 2, min_samples_leaf = 4\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.753\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.729\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.741\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.718\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.654\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.622\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.854\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.849\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 0.804\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.778\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 0.792\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de clasificación con Árbol de Decisión:\n",
    "\n",
    "# Sin hiperparámetros\n",
    "print(\"Sin hiperparámetros\")\n",
    "arbol_model_vino = aplicar_arbol_decision(dfvino_limpio, 'quality', tipo_modelo='clasificacion')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"max_depth = 5, min_samples_split = 4, min_samples_leaf = 2\")\n",
    "arbol_hiper_vino = aplicar_arbol_decision_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', max_depth=5, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"max_depth = 10, min_samples_split = 5, min_samples_leaf = 1\")\n",
    "arbol_hiper_vino2 = aplicar_arbol_decision_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', max_depth=10, min_samples_split=5, min_samples_leaf=1)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"max_depth = None (sin límite), min_samples_split = 10, min_samples_leaf = 3\")\n",
    "arbol_hiper_vino3 = aplicar_arbol_decision_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', max_depth=None, min_samples_split=10, min_samples_leaf=3)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"max_depth = 3, min_samples_split = 2, min_samples_leaf = 4\")\n",
    "arbol_hiper_vino4 = aplicar_arbol_decision_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', max_depth=3, min_samples_split=2, min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**  | **max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**  | **max_depth = 10, min_samples_split = 5, min_samples_leaf = 1** | **max_depth = None, min_samples_split = 10, min_samples_leaf = 3** | **max_depth = 3, min_samples_split = 2, min_samples_leaf = 4** |\n",
    "|------------------------------------|--------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|\n",
    "| **Exactitud**                      | 1.000 / 0.694            | **0.821 / 0.742**                                                 | 0.950 / 0.672                                                 | 0.909 / 0.721                                                 | 0.753 / 0.729                                                 |\n",
    "| **F1 Score**                       | 1.000 / 0.724            | **0.836 / 0.761**                                                 | 0.953 / 0.699                                                 | 0.916 / 0.733                                                 | 0.741 / 0.718                                                 |\n",
    "| **Sensibilidad**                   | 1.000 / 0.724            | **0.846 / 0.740**                                                 | 0.935 / 0.685                                                 | 0.911 / 0.693                                                 | 0.654 / 0.622                                                 |\n",
    "| **Precisión**                      | 1.000 / 0.724            | **0.826 / 0.783**                                                 | 0.971 / 0.713                                                 | 0.920 / 0.779                                                 | 0.854 / 0.849                                                 |\n",
    "| **AUC-ROC**                        | 1.000 / 0.691            | **0.892 / 0.777**                                              | 0.992 / 0.672                                                 | 0.979 / 0.761                                                 | 0.804 / 0.778                                                 |\n",
    "| **Precision-Recall AUC**           | 1.000 / 0.678            | **0.886 / 0.798**                                                 | 0.992 / 0.662                                                 | 0.980 / 0.764                                                 | 0.792 / 0.761                                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de cada modelo:\n",
    "\n",
    "* **Sin Hiperparámetros**:  El modelo tiene un rendimiento perfecto en entrenamiento pero un desempeño mucho menor en testeo, lo que indica **sobreajuste severo**. Al no restringir la complejidad del árbol, aprende demasiado bien los datos de entrenamiento, perdiendo capacidad de generalización.  \n",
    "\n",
    "* **max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**:  **Tiene el mejor equilibrio entre ajuste y generalización**. Mantiene métricas altas en ambos conjuntos de datos y evita sobreajuste.  Al limitar la profundidad y establecer un mínimo de muestras por nodo, el modelo captura patrones sin memorizar datos específicos.  \n",
    "\n",
    "* **max_depth = 10, min_samples_split = 5, min_samples_leaf = 1**: Alto rendimiento en entrenamiento, pero **se acerca al sobreajuste**, con una caída notable en testeo.  La mayor profundidad y el menor tamaño de hojas permiten aprender más detalles, pero reducen la capacidad de generalización.  \n",
    "\n",
    "* **max_depth = None, min_samples_split = 10, min_samples_leaf = 3**: **Buen rendimiento en testeo**, con una generalización aceptable. Sin un límite de profundidad, el modelo puede capturar más patrones, pero el uso de valores más altos en `min_samples_split` y `min_samples_leaf` ayuda a controlar el sobreajuste.  \n",
    "\n",
    "* **max_depth = 3, min_samples_split = 2, min_samples_leaf = 4**:  **Ocurre subajuste (underfitting)** claro, con métricas bajas en ambos conjuntos de datos.  El límite de profundidad restringe demasiado el modelo, haciéndolo incapaz de capturar patrones complejos.  \n",
    "\n",
    "#### **Modelo elegido**: Me quedaría con el modelo **max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**, ya que ofrece **un balance óptimo** entre generalización y ajuste.  Sus hiperparámetros permiten evitar tanto el **sobreajuste** como el **subajuste**, sin caer en una complejidad innecesaria.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.3.4 Árboles de Decisión Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.921\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.897\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.886\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.918\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.839\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "max_depth = 5, min_samples_split = 4, min_samples_leaf = 2\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.930\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.925\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.858\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "max_depth = 10, min_samples_split = 5, min_samples_leaf = 1\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.998\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.930\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.997\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.994\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.925\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.858\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "max_depth = None (sin límite), min_samples_split = 10, min_samples_leaf = 3\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.991\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.930\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.988\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.982\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.994\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.934\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.866\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "max_depth = 3, min_samples_split = 2, min_samples_leaf = 4\n",
      "Árbol de Decisión : Exactitud en los datos de entrenamiento: 0.965\n",
      "Árbol de Decisión : Exactitud en los datos de testeo: 0.921\n",
      "\n",
      "Árbol de Decisión : F1 Score en los datos de entrenamiento: 0.953\n",
      "Árbol de Decisión : F1 Score en los datos de testeo: 0.897\n",
      "\n",
      "Árbol de Decisión : Sensibilidad en los datos de entrenamiento: 0.959\n",
      "Árbol de Decisión : Sensibilidad en los datos de testeo: 0.907\n",
      "\n",
      "Árbol de Decisión : Precisión en los datos de entrenamiento: 0.947\n",
      "Árbol de Decisión : Precisión en los datos de testeo: 0.886\n",
      "\n",
      "Árbol de Decisión : AUC-ROC en los datos de entrenamiento: 0.987\n",
      "Árbol de Decisión : AUC-ROC en los datos de testeo: 0.930\n",
      "\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de entrenamiento: 0.978\n",
      "Árbol de Decisión : Precision-Recall AUC en los datos de testeo: 0.911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Árboles de Decisión al dataset dfcancer_limpio\n",
    "\n",
    "# Sin hiperparámetros\n",
    "print(\"Sin hiperparámetros\")\n",
    "arbol_model_cancer = aplicar_arbol_decision(dfcancer_limpio, 'y', tipo_modelo='clasificacion')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"max_depth = 5, min_samples_split = 4, min_samples_leaf = 2\")\n",
    "arbol_hiper_cancer = aplicar_arbol_decision_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', max_depth=5, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"max_depth = 10, min_samples_split = 5, min_samples_leaf = 1\")\n",
    "arbol_hiper_cancer2 = aplicar_arbol_decision_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', max_depth=10, min_samples_split=5, min_samples_leaf=1)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"max_depth = None (sin límite), min_samples_split = 10, min_samples_leaf = 3\")\n",
    "arbol_hiper_cancer3 = aplicar_arbol_decision_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', max_depth=None, min_samples_split=10, min_samples_leaf=3)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"max_depth = 3, min_samples_split = 2, min_samples_leaf = 4\")\n",
    "arbol_hiper_cancer4 = aplicar_arbol_decision_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', max_depth=3, min_samples_split=2, min_samples_leaf=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**  | **max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**  | **max_depth = 10, min_samples_split = 5, min_samples_leaf = 1** | **max_depth = None, min_samples_split = 10, min_samples_leaf = 3** | **max_depth = 3, min_samples_split = 2, min_samples_leaf = 4** |\n",
    "|------------------------------------|--------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|\n",
    "| **Exactitud**                      | 1.000 / 0.921            | 1.000 / 0.921                                                 | 0.998 / 0.930                                             | **0.991 / 0.930**        | 0.965 / 0.912                                                 |\n",
    "| **F1 Score**                       | 1.000 / 0.897            | 1.000 / 0.897                                                 | 0.997 / 0.907                                             | **0.988 / 0.907**        | 0.953 / 0.884                                                 |\n",
    "| **Sensibilidad**                   | 1.000 / 0.907            | 1.000 / 0.907                                                 | 0.994 / 0.907                                             | **0.982 / 0.907**        | 0.959 / 0.884                                                 |\n",
    "| **Precisión**                      | 1.000 / 0.886            | 1.000 / 0.886                                                 | 1.000 / 0.907                                             | **0.994 / 0.907**        | 0.947 / 0.884                                                 |\n",
    "| **AUC-ROC**                        | 1.000 / 0.918            | 1.000 / 0.918                                                 | 1.000 / 0.925                                                 | **1.000 / 0.935**    | 0.987 / 0.928                                                 |\n",
    "| **Precision-Recall AUC**           | 1.000 / 0.839            | 1.000 / 0.839                                                 | 1.000 / 0.858                                                 | **1.000 / 0.870**    | 0.978 / 0.907                                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de cada modelo:\n",
    "* **Sin Hiperparámetros**: El modelo alcanza un rendimiento perfecto en los datos de entrenamiento, pero su rendimiento en prueba es menor. Esto indica un posible sobreajuste, ya que el modelo memoriza los datos de entrenamiento y no generaliza tan bien en el conjunto de testeo.\n",
    "  \n",
    "* **max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**: Presenta un rendimiento idéntico al modelo sin hiperparámetros, lo que sugiere que la profundidad moderada y los criterios de división evitan un sobreajuste mayor, pero aún podrían mejorarse para lograr mejor generalización.\n",
    "  \n",
    "* **max_depth = 10, min_samples_split = 5, min_samples_leaf = 1**: Se observa un buen equilibrio entre ajuste y generalización. Su desempeño en prueba mejora ligeramente en comparación con los modelos anteriores, con una mejor precisión y F1 Score. Sin embargo, la sensibilidad es similar, lo que indica que sigue aprendiendo características específicas de los datos de entrenamiento.\n",
    "\n",
    "* **max_depth = None, min_samples_split = 10, min_samples_leaf = 3**: Este modelo logra el mejor **AUC-ROC y Precision-Recall AUC** en los datos de prueba, lo que sugiere que tiene una mejor capacidad de discriminación. La restricción en el número mínimo de muestras por división y hoja parece contribuir a una generalización más estable sin comprometer demasiado el rendimiento.\n",
    "\n",
    "* **max_depth = 3, min_samples_split = 2, min_samples_leaf = 4**: Presenta el peor rendimiento general en comparación con los otros modelos, lo que indica que la profundidad limitada y los valores conservadores de los hiperparámetros impiden que el modelo capture patrones importantes. Esto resulta en **underfitting**, con una caída en exactitud y F1 Score.\n",
    "\n",
    "#### Modelo recomendado:\n",
    "Me quedaría con el modelo con **max_depth = None, min_samples_split = 10, min_samples_leaf = 3**, ya que logra el mejor balance entre ajuste y generalización. Sus métricas en el conjunto de prueba, especialmente **AUC-ROC (0.935) y Precision-Recall AUC (0.870),** indican que tiene la mejor capacidad para distinguir entre clases y manejar datos desequilibrados. Además, evita tanto el sobreajuste como el underfitting en comparación con los otros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4.4 Bosques Aleatorios (Random Forest) con hiperparámetros`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a tener entonces en esta función para aplicar a cada dataset:\n",
    "### para clasificación:\n",
    "* DecisionTreeClassifier()  y métricas (Exactitud, F1 Score, Sensibilidad y Precisión) y añadidas (AUC-ROC y Precision-Recall AUC)\n",
    "### para regresión:\n",
    "* DecisionTreeRegressor() y métricas (MAE, MSE, R2 Score) y añadidas (RMSE y Explained Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un modelo de Bosques Aleatorios (Random Forest) con hiperparámetros\n",
    "def aplicar_random_forest_hiper(df, target_column, tipo_modelo='clasificacion', n_estimators=100, max_depth=None, min_samples_split=2):\n",
    "    # Separar las características (X) y la variable objetivo (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Seleccionar el modelo dependiendo del tipo (regresión o clasificación)\n",
    "    if tipo_modelo == 'regresion':\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=max_depth, \n",
    "            min_samples_split=min_samples_split,\n",
    "            random_state=42\n",
    "        )\n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=max_depth, \n",
    "            min_samples_split=min_samples_split,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones sobre los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo con las métricas correspondientes\n",
    "    if tipo_modelo == 'regresion':\n",
    "        # Métricas existentes\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"MAE\", mae_train, mae_test)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"MSE\", mse_train, mse_test)\n",
    "        \n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"R2 Score\", r2_train, r2_test)\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        rmse_train, evs_train = metricas_regresion_adicionales(y_train, y_train_pred)\n",
    "        rmse_test, evs_test = metricas_regresion_adicionales(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"RMSE\", rmse_train, rmse_test)\n",
    "        mostrarMetricasRegresion(\"Bosques Aleatorios\", \"Explained Variance\", evs_train, evs_test)\n",
    "    \n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        # Métricas existentes\n",
    "        exactitud_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        f1_train = metrics.f1_score(y_train, y_train_pred, average='binary')  # Cambiar a 'micro' o 'macro' si es multiclase\n",
    "        f1_test = metrics.f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        sensibilidad_train = metrics.recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = metrics.recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "        precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        # Probabilidades para AUC-ROC y Precision-Recall AUC\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"Bosques Aleatorios\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos a incluir los siguientes hiperparámetros:\n",
    "* n_estimators\n",
    "* max_depth\n",
    "* min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **n_estimators**: El número de árboles en el bosque. Valor sugerido: 100 - 500 árboles. Tendremos que pensar en aumentar el número de árboles o no porque generalmente mejora el rendimiento, pero también aumenta el tiempo de computación.\n",
    "* **max_depth**: La profundidad máxima de cada árbol en el bosque. Dependiendo del tamaño y complejidad de los datos, entre 5 y 20 hace que la profundidad previene el sobreajuste.\n",
    "* **min_samples_split**: El número mínimo de muestras necesarias para dividir un nodo. Valor sugerido: 2 - 10. Valores más altos hacen que los árboles sean más simples, lo que puede ayudar a reducir el sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.4.1 Bosques Aleatorios Aplicado a TEMPERATURA ESPAÑA` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Bosques Aleatorios : MAE en los datos de entrenamiento: 0.192\n",
      "Bosques Aleatorios : MAE en los datos de testeo: 0.596\n",
      "\n",
      "Bosques Aleatorios : MSE en los datos de entrenamiento: 0.083\n",
      "Bosques Aleatorios : MSE en los datos de testeo: 0.950\n",
      "\n",
      "Bosques Aleatorios : R2 Score en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : R2 Score en los datos de testeo: 0.896\n",
      "\n",
      "Bosques Aleatorios : RMSE en los datos de entrenamiento: 0.288\n",
      "Bosques Aleatorios : RMSE en los datos de testeo: 0.975\n",
      "\n",
      "Bosques Aleatorios : Explained Variance en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : Explained Variance en los datos de testeo: 0.900\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "n_estimators = 100, max_depth = 5, min_samples_split = 4\n",
      "Bosques Aleatorios : MAE en los datos de entrenamiento: 0.469\n",
      "Bosques Aleatorios : MAE en los datos de testeo: 0.669\n",
      "\n",
      "Bosques Aleatorios : MSE en los datos de entrenamiento: 0.465\n",
      "Bosques Aleatorios : MSE en los datos de testeo: 1.115\n",
      "\n",
      "Bosques Aleatorios : R2 Score en los datos de entrenamiento: 0.951\n",
      "Bosques Aleatorios : R2 Score en los datos de testeo: 0.878\n",
      "\n",
      "Bosques Aleatorios : RMSE en los datos de entrenamiento: 0.682\n",
      "Bosques Aleatorios : RMSE en los datos de testeo: 1.056\n",
      "\n",
      "Bosques Aleatorios : Explained Variance en los datos de entrenamiento: 0.951\n",
      "Bosques Aleatorios : Explained Variance en los datos de testeo: 0.882\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "n_estimators = 150, max_depth = 10, min_samples_split = 5\n",
      "Bosques Aleatorios : MAE en los datos de entrenamiento: 0.276\n",
      "Bosques Aleatorios : MAE en los datos de testeo: 0.613\n",
      "\n",
      "Bosques Aleatorios : MSE en los datos de entrenamiento: 0.159\n",
      "Bosques Aleatorios : MSE en los datos de testeo: 0.962\n",
      "\n",
      "Bosques Aleatorios : R2 Score en los datos de entrenamiento: 0.983\n",
      "Bosques Aleatorios : R2 Score en los datos de testeo: 0.895\n",
      "\n",
      "Bosques Aleatorios : RMSE en los datos de entrenamiento: 0.399\n",
      "Bosques Aleatorios : RMSE en los datos de testeo: 0.981\n",
      "\n",
      "Bosques Aleatorios : Explained Variance en los datos de entrenamiento: 0.983\n",
      "Bosques Aleatorios : Explained Variance en los datos de testeo: 0.898\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "n_estimators = 200, max_depth = None (sin límite), min_samples_split = 10\n",
      "Bosques Aleatorios : MAE en los datos de entrenamiento: 0.307\n",
      "Bosques Aleatorios : MAE en los datos de testeo: 0.630\n",
      "\n",
      "Bosques Aleatorios : MSE en los datos de entrenamiento: 0.200\n",
      "Bosques Aleatorios : MSE en los datos de testeo: 1.018\n",
      "\n",
      "Bosques Aleatorios : R2 Score en los datos de entrenamiento: 0.979\n",
      "Bosques Aleatorios : R2 Score en los datos de testeo: 0.889\n",
      "\n",
      "Bosques Aleatorios : RMSE en los datos de entrenamiento: 0.447\n",
      "Bosques Aleatorios : RMSE en los datos de testeo: 1.009\n",
      "\n",
      "Bosques Aleatorios : Explained Variance en los datos de entrenamiento: 0.979\n",
      "Bosques Aleatorios : Explained Variance en los datos de testeo: 0.893\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "n_estimators = 50, max_depth = 3, min_samples_split = 2\n",
      "Bosques Aleatorios : MAE en los datos de entrenamiento: 0.708\n",
      "Bosques Aleatorios : MAE en los datos de testeo: 0.838\n",
      "\n",
      "Bosques Aleatorios : MSE en los datos de entrenamiento: 0.872\n",
      "Bosques Aleatorios : MSE en los datos de testeo: 1.310\n",
      "\n",
      "Bosques Aleatorios : R2 Score en los datos de entrenamiento: 0.909\n",
      "Bosques Aleatorios : R2 Score en los datos de testeo: 0.857\n",
      "\n",
      "Bosques Aleatorios : RMSE en los datos de entrenamiento: 0.934\n",
      "Bosques Aleatorios : RMSE en los datos de testeo: 1.145\n",
      "\n",
      "Bosques Aleatorios : Explained Variance en los datos de entrenamiento: 0.909\n",
      "Bosques Aleatorios : Explained Variance en los datos de testeo: 0.857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de regresión con Bosques Aleatorios:\n",
    "print(\"Sin hiperparámetros\")\n",
    "Bosques_modelo_temp = aplicar_random_forest(dfesp_limpio, 'rain_days', tipo_modelo='regresion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"n_estimators = 100, max_depth = 5, min_samples_split = 4\")\n",
    "Bosques_hiper_esp = aplicar_random_forest_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', n_estimators=100, max_depth=5, min_samples_split=4)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"n_estimators = 150, max_depth = 10, min_samples_split = 5\")\n",
    "Bosques_hiper_esp2 = aplicar_random_forest_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', n_estimators=150, max_depth=10, min_samples_split=5)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"n_estimators = 200, max_depth = None (sin límite), min_samples_split = 10\")\n",
    "Bosques_hiper_esp3 = aplicar_random_forest_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', n_estimators=200, max_depth=None, min_samples_split=10)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"n_estimators = 50, max_depth = 3, min_samples_split = 2\")\n",
    "Bosques_hiper_esp4 = aplicar_random_forest_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', n_estimators=50, max_depth=3, min_samples_split=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**  | **n_estimators = 100, max_depth = 5, min_samples_split = 4**  | **n_estimators = 150, max_depth = 10, min_samples_split = 5** | **n_estimators = 200, max_depth = None, min_samples_split = 10** | **n_estimators = 50, max_depth = 3, min_samples_split = 2** |\n",
    "|------------------------------------|--------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-------------------------------------------------------------|\n",
    "| **MAE**                            | 0.192 / 0.596            | 0.469 / 0.669                                                 | **0.276 / 0.613**                                 | 0.307 / 0.630        | 0.708 / 0.838                                                 |\n",
    "| **MSE**                            | 0.083 / 0.950            | 0.465 / 1.115                                                 | **0.159 / 0.962**                                 | 0.200 / 1.018        | 0.872 / 1.310                                                 |\n",
    "| **R2 Score**                       | 0.991 / 0.896            | 0.951 / 0.878                                                 | **0.983 / 0.895**                                 | 0.979 / 0.889        | 0.909 / 0.857                                                 |\n",
    "| **RMSE**                           | 0.288 / 0.975            | 0.682 / 1.056                                                 | **0.399 / 0.981**                                 | 0.447 / 1.009        | 0.934 / 1.145                                                 |\n",
    "| **Explained Variance**             | 0.991 / 0.900            | 0.951 / 0.882                                                 | **0.983 / 0.898**                                 | 0.979 / 0.893        | 0.909 / 0.857                                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de cada modelo:\n",
    "* **Sin Hiperparámetros:** El modelo tiene buen rendimiento en los datos de entrenamiento, pero pierde precisión en los datos de prueba, lo que sugiere sobreajuste.\n",
    "* **n_estimators = 100, max_depth = 5, min_samples_split = 4**: Mejora ligeramente respecto al modelo sin hiperparámetros, pero aún no es óptimo. Hay algo de sobreajuste, pero menos que en el modelo base.\n",
    "* **n_estimators = 150, max_depth = 10, min_samples_split = 5**: Buen equilibrio entre los datos de entrenamiento y prueba, con mejoras en el ajuste y la generalización.\n",
    "* **n_estimators = 200, max_depth = None, min_samples_split = 10**: Con n_estimators = 200 y max_depth = None, el modelo puede capturar mucha más complejidad sin perder capacidad de generalización, lo que se traduce en el mejor rendimiento en el conjunto de prueba. Aunque max_depth = None permite una profundidad ilimitada, lo cual podría generar un riesgo de sobreajuste si no se controla bien, la combinación de min_samples_split = 10 ayuda a hacer que las divisiones sean más simples y reduce el riesgo de sobreajuste. Este modelo logra un buen balance con los hiperparámetros que hemos escogido.\n",
    "* **n_estimators = 50, max_depth = 3, min_samples_split = 2**: El peor modelo, con un rendimiento pobre en prueba debido a underfitting.\n",
    "#### El modelo con **n_estimators = 200, max_depth = None, min_samples_split = 10** es el mejor, ya que tiene un buen balance, logrando buenos resultados en los datos de prueba sin sobreajustarse ni caer en underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.4.2 Bosques Aleatorios Aplicado a PHISHING URLS` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.969\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.992\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.973\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.993\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.977\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.969\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.995\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.995\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "n_estimators = 120, max_depth = 7, min_samples_split = 6\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.941\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.943\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.948\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.950\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.971\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.970\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.927\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.931\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 0.989\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.989\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.991\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "n_estimators = 180, max_depth = 12, min_samples_split = 8\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.968\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.962\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.972\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.967\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.982\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.978\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.962\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.956\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 0.997\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.995\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 0.997\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.996\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "n_estimators = 250, max_depth = None (sin límite), min_samples_split = 15\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.975\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.963\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.978\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.967\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.984\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.973\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.972\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.962\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.995\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 0.998\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.996\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "n_estimators = 60, max_depth = 4, min_samples_split = 3\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.925\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.933\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.934\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.941\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.950\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.955\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.918\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.926\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 0.981\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.982\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 0.984\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de clasificación con Bosques Aleatorios:\n",
    "print(\"Sin hiperparámetros\")\n",
    "Bosques_modelphishing = aplicar_random_forest(dfphishing_limpio, 'class', tipo_modelo='clasificacion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"n_estimators = 120, max_depth = 7, min_samples_split = 6\")\n",
    "Bosques_hiper_phis = aplicar_random_forest_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_estimators=120, max_depth=7, min_samples_split=6)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"n_estimators = 180, max_depth = 12, min_samples_split = 8\")\n",
    "Bosques_hiper_phis2 = aplicar_random_forest_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_estimators=180, max_depth=12, min_samples_split=8)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"n_estimators = 250, max_depth = None (sin límite), min_samples_split = 15\")\n",
    "Bosques_hiper_phis3 = aplicar_random_forest_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_estimators=250, max_depth=None, min_samples_split=15)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"n_estimators = 60, max_depth = 4, min_samples_split = 3\")\n",
    "Bosques_hiper_phis4 = aplicar_random_forest_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_estimators=60, max_depth=4, min_samples_split=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**  | **n_estimators = 120, max_depth = 7, min_samples_split = 6** | **n_estimators = 180, max_depth = 12, min_samples_split = 8** | **n_estimators = 250, max_depth = None, min_samples_split = 15** | **n_estimators = 60, max_depth = 4, min_samples_split = 3** |\n",
    "|------------------------------------|--------------------------|-------------------------------------------------------------|-------------------------------------------------------------|----------------------------------------------------------------|------------------------------------------------------------|\n",
    "| **Exactitud**                      | 0.991 / 0.969            | 0.941 / 0.943                                               | **0.968 / 0.962**                                               | 0.975 / 0.963       | 0.925 / 0.933                                              |\n",
    "| **F1 Score**                       | 0.992 / 0.973            | 0.948 / 0.950                                               | **0.972 / 0.967**                                               | 0.978 / 0.967       | 0.934 / 0.941                                              |\n",
    "| **Sensibilidad**                   | 0.993 / 0.977            | 0.971 / 0.970                                               | **0.982 / 0.978**                                               | 0.984 / 0.973       | 0.950 / 0.955                                              |\n",
    "| **Precisión**                      | 0.991 / 0.969            | 0.927 / 0.931                                               | **0.962 / 0.956**                                               | 0.972 / 0.962       | 0.918 / 0.926                                              |\n",
    "| **AUC-ROC**                        | 1.000 / 0.995            | 0.989 / 0.989                                               | **0.997 / 0.995**                                               | 0.998 / 0.995       | 0.981 / 0.982                                              |\n",
    "| **Precision-Recall AUC**           | 1.000 / 0.995            | 0.991 / 0.991                                               | **0.997 / 0.996**                                               | 0.998 / 0.996       | 0.984 / 0.985                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de cada modelo:\n",
    "* **Sin Hiperparámetros**: El modelo tiene un rendimiento sólido en entrenamiento, pero muestra una caída en precisión en los datos de prueba, lo que indica sobreajuste.\n",
    "* **n_estimators = 120, max_depth = 7, min_samples_split = 6**: Este modelo mejora respecto al base, mostrando un buen rendimiento en los datos de prueba, con un mejor equilibrio, aunque todavía hay un pequeño sobreajuste en entrenamiento.\n",
    "* **n_estimators = 180, max_depth = 12, min_samples_split = 8**: Este modelo presenta un buen equilibrio entre entrenamiento y prueba. Si bien mejora la precisión y la sensibilidad, sigue existiendo un leve sobreajuste, pero menos pronunciado que en otros modelos.\n",
    "* **n_estimators = 250, max_depth = None, min_samples_split = 15**: Con un mayor número de estimadores y sin límite en la profundidad, el modelo captura mayor complejidad, pero logra un buen equilibrio en la prueba, sin perder capacidad de generalización. Es uno de los mejores, aunque el ajuste de los hiperparámetros podría seguir optimizándose.\n",
    "* **n_estimators = 60, max_depth = 4, min_samples_split = 3**: Este modelo muestra el peor rendimiento, especialmente en los datos de entrenamiento. Hay un claro caso de underfitting, ya que no logra ajustarse correctamente a los datos.\n",
    "#### El modelo con n_estimators = 250, max_depth = None, min_samples_split = 15 destaca por ofrecer el mejor rendimiento en prueba, manteniendo un equilibrio adecuado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.4.3 Bosques Aleatorios Aplicado a CALIDAD DEL VINO` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.769\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.789\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.780\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.798\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.886\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.915\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "n_estimators = 110, max_depth = 8, min_samples_split = 5\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.931\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.764\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.936\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.782\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.931\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.764\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.941\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.802\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 0.988\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.871\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 0.990\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.902\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "n_estimators = 160, max_depth = 9, min_samples_split = 7\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.940\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.790\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.945\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.808\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.949\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.795\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.940\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.821\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 0.992\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.875\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 0.993\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.905\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "n_estimators = 220, max_depth = None (sin límite), min_samples_split = 12\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.946\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.786\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.951\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.806\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.960\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.803\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.942\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.810\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 0.992\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.870\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 0.993\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.901\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "n_estimators = 80, max_depth = 5, min_samples_split = 4\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.835\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.760\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.844\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.776\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.824\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.748\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.864\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.805\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 0.921\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.869\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 0.934\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de clasificación con Bosques Aleatorios:\n",
    "print(\"Sin hiperparámetros\")\n",
    "Bosques_modelvino = aplicar_random_forest(dfvino_limpio, 'quality', tipo_modelo='clasificacion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"n_estimators = 110, max_depth = 8, min_samples_split = 5\")\n",
    "Bosques_hiper_vino = aplicar_random_forest_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', n_estimators=110, max_depth=8, min_samples_split=5)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"n_estimators = 160, max_depth = 9, min_samples_split = 7\")\n",
    "Bosques_hiper_vino2 = aplicar_random_forest_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', n_estimators=160, max_depth=9, min_samples_split=7)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"n_estimators = 220, max_depth = None (sin límite), min_samples_split = 12\")\n",
    "Bosques_hiper_vino3 = aplicar_random_forest_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', n_estimators=220, max_depth=None, min_samples_split=12)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"n_estimators = 80, max_depth = 5, min_samples_split = 4\")\n",
    "Bosques_hiper_vino4 = aplicar_random_forest_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', n_estimators=80, max_depth=5, min_samples_split=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**     | **n_estimators = 110, max_depth = 8, min_samples_split = 5** | **n_estimators = 160, max_depth = 9, min_samples_split = 7** | **n_estimators = 220, max_depth = None, min_samples_split = 12** | **n_estimators = 80, max_depth = 5, min_samples_split = 4** |\n",
    "|------------------------------------|-----------------------------|------------------------------------------------------------|------------------------------------------------------------|-----------------------------------------------------------------|------------------------------------------------------------|\n",
    "| **Exactitud**                      | 1.000 / 0.769               | 0.931 / 0.764                                              | 0.940 / 0.790                                              | **0.946 / 0.786**            | 0.835 / 0.760                                               |\n",
    "| **F1 Score**                       | 1.000 / 0.789               | 0.936 / 0.782                                              | 0.945 / 0.808                                              | **0.951 / 0.806**            | 0.844 / 0.776                                               |\n",
    "| **Sensibilidad**                   | 1.000 / 0.780               | 0.931 / 0.764                                              | 0.949 / 0.795                                              | **0.960 / 0.803**            | 0.824 / 0.748                                               |\n",
    "| **Precisión**                      | 1.000 / 0.798               | 0.941 / 0.802                                              | 0.940 / 0.821                                              | **0.942 / 0.810**            | 0.864 / 0.805                                               |\n",
    "| **AUC-ROC**                        | 1.000 / 0.886               | 0.988 / 0.871                                              | 0.992 / 0.875                                              | **0.992 / 0.870**            | 0.921 / 0.869                                               |\n",
    "| **Precision-Recall AUC**           | 1.000 / 0.915               | 0.990 / 0.902                                              | 0.993 / 0.905                                              | **0.993 / 0.901**            | 0.934 / 0.896                                               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones para cada modelo:\n",
    "* **Sin Hiperparámetros**: El modelo tiene un rendimiento sólido en entrenamiento, pero muestra una caída en precisión en los datos de prueba, lo que indica sobreajuste.\n",
    "* **n_estimators = 110, max_depth = 8, min_samples_split = 5**: Este modelo tiene una ligera mejora respecto al modelo base, con un buen rendimiento en los datos de prueba, pero aún presenta un pequeño sobreajuste en los datos de entrenamiento.\n",
    "* **n_estimators = 160, max_depth = 9, min_samples_split = 7**: El modelo ofrece un buen equilibrio entre los datos de entrenamiento y prueba, mejorando la precisión y la sensibilidad, aunque aún existe algo de sobreajuste, pero es menos pronunciado que en otros modelos.\n",
    "* **n_estimators = 220, max_depth = None, min_samples_split = 12**: Al tener un mayor número de estimadores y sin límite en la profundidad, el modelo captura más complejidad sin sacrificar la capacidad de generalización. Este es uno de los mejores modelos, aunque aún se pueden seguir ajustando los hiperparámetros.\n",
    "* **n_estimators = 80, max_depth = 5, min_samples_split = 4**: Este modelo es el que tiene el peor rendimiento, especialmente en los datos de entrenamiento. Es un claro caso de underfitting, ya que no se ajusta bien a los datos.\n",
    "#### El modelo con n_estimators = 220, max_depth = None, min_samples_split = 12 es el mejor, ya que ofrece un buen rendimiento en los datos de prueba, manteniendo un equilibrio adecuado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.4.4 Bosques Aleatorios Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.956\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.940\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.907\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.975\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.992\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.988\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "n_estimators = 100, max_depth = 6, min_samples_split = 4\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.996\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.939\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.994\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.916\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.988\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.884\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.950\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.989\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.985\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "n_estimators = 150, max_depth = 10, min_samples_split = 6\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.998\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.947\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.997\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.929\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.994\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.907\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.951\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.991\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.986\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "n_estimators = 200, max_depth = None (sin límite), min_samples_split = 8\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.993\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.939\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.991\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.916\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.988\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.884\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 0.994\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.950\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.990\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.986\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "n_estimators = 70, max_depth = 4, min_samples_split = 3\n",
      "Bosques Aleatorios : Exactitud en los datos de entrenamiento: 0.989\n",
      "Bosques Aleatorios : Exactitud en los datos de testeo: 0.947\n",
      "\n",
      "Bosques Aleatorios : F1 Score en los datos de entrenamiento: 0.985\n",
      "Bosques Aleatorios : F1 Score en los datos de testeo: 0.927\n",
      "\n",
      "Bosques Aleatorios : Sensibilidad en los datos de entrenamiento: 0.970\n",
      "Bosques Aleatorios : Sensibilidad en los datos de testeo: 0.884\n",
      "\n",
      "Bosques Aleatorios : Precisión en los datos de entrenamiento: 1.000\n",
      "Bosques Aleatorios : Precisión en los datos de testeo: 0.974\n",
      "\n",
      "Bosques Aleatorios : AUC-ROC en los datos de entrenamiento: 0.999\n",
      "Bosques Aleatorios : AUC-ROC en los datos de testeo: 0.985\n",
      "\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de entrenamiento: 0.999\n",
      "Bosques Aleatorios : Precision-Recall AUC en los datos de testeo: 0.983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de clasificación con Bosques Aleatorios:\n",
    "print(\"Sin hiperparámetros\")\n",
    "Bosques_modelcancer = aplicar_random_forest(dfcancer_limpio, 'y', tipo_modelo='clasificacion')\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"n_estimators = 100, max_depth = 6, min_samples_split = 4\")\n",
    "Bosques_hiper_cancer = aplicar_random_forest_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', n_estimators=100, max_depth=6, min_samples_split=4)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"n_estimators = 150, max_depth = 10, min_samples_split = 6\")\n",
    "Bosques_hiper_cancer2 = aplicar_random_forest_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', n_estimators=150, max_depth=10, min_samples_split=6)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"n_estimators = 200, max_depth = None (sin límite), min_samples_split = 8\")\n",
    "Bosques_hiper_cancer3 = aplicar_random_forest_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', n_estimators=200, max_depth=None, min_samples_split=8)\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"n_estimators = 70, max_depth = 4, min_samples_split = 3\")\n",
    "Bosques_hiper_cancer4 = aplicar_random_forest_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', n_estimators=70, max_depth=4, min_samples_split=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**     | **n_estimators = 100, max_depth = 6, min_samples_split = 4** | **n_estimators = 150, max_depth = 10, min_samples_split = 6** | **n_estimators = 200, max_depth = None, min_samples_split = 8** | **n_estimators = 70, max_depth = 4, min_samples_split = 3** |\n",
    "|------------------------------------|-----------------------------|------------------------------------------------------------|------------------------------------------------------------|-----------------------------------------------------------------|------------------------------------------------------------|\n",
    "| **Exactitud**                      | 1.000 / 0.956               | 0.996 / 0.939                                              | **0.998 / 0.947**                                              | 0.993 / 0.939                                                 | 0.989 / 0.947            |\n",
    "| **F1 Score**                       | 1.000 / 0.940               | 0.994 / 0.916                                              | **0.997 / 0.929**                                              | 0.991 / 0.916                                                 | 0.985 / 0.927          |\n",
    "| **Sensibilidad**                   | 1.000 / 0.907               | 0.988 / 0.884                                              | **0.994 / 0.907**                                              | 0.988 / 0.884                                                 | 0.970 / 0.884              |\n",
    "| **Precisión**                      | 1.000 / 0.975               | 1.000 / 0.950                                              | **1.000 / 0.951**                                              | 0.994 / 0.950                                                 | 1.000 / 0.974           |\n",
    "| **AUC-ROC**                        | 1.000 / 0.992               | 1.000 / 0.989                                              | **1.000 / 0.991**                                              | 1.000 / 0.990                                                 | 0.999 / 0.985           |\n",
    "| **Precision-Recall AUC**           | 1.000 / 0.988               | 1.000 / 0.985                                              | **1.000 / 0.986**                                              | 1.000 / 0.986                                                 | 0.999 / 0.983       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones para cada modelo:\n",
    "* **Sin Hiperparámetros**: Este modelo muestra una precisión perfecta en los datos de entrenamiento (1.000), pero en los datos de prueba tiene una ligera caída en la precisión y en el F1 score, lo que indica que el modelo podría estar sobreajustando los datos de entrenamiento (Exactitud: 0.956, F1 score: 0.940). Aunque tiene buenos valores de AUC-ROC (0.992) y Precision-Recall AUC (0.988), la diferencia entre los datos de entrenamiento y prueba sugiere que necesita ajustes.\n",
    "\n",
    "* **n_estimators = 100, max_depth = 6, min_samples_split = 4**: Este modelo tiene un buen rendimiento, con una ligera mejora en la exactitud y F1 score en comparación con el modelo sin hiperparámetros en los datos de prueba (Exactitud: 0.939, F1 score: 0.916). Aunque sigue mostrando algo de sobreajuste, con una precisión perfecta en los datos de entrenamiento, es un modelo sólido que comienza a mejorar el rendimiento en los datos de prueba.\n",
    "\n",
    "* **n_estimators = 150, max_depth = 10, min_samples_split = 6**: Este modelo mejora aún más, mostrando una exactitud de 0.947 y un F1 score de 0.929 en los datos de prueba. Con una precisión de 1.000 en los datos de entrenamiento y buenas métricas de AUC-ROC y Precision-Recall AUC, el modelo sigue mostrando algo de sobreajuste, pero con menos pronunciamiento que los modelos anteriores. Tiene un buen equilibrio entre entrenamiento y prueba.\n",
    "\n",
    "* **n_estimators = 200, max_depth = None, min_samples_split = 8**: Este es uno de los mejores modelos, con un rendimiento sólido tanto en los datos de entrenamiento como en los de prueba (Exactitud: 0.939, F1 score: 0.916). Aunque la precisión es un poco más baja en los datos de prueba en comparación con los modelos anteriores, sigue manteniendo un buen rendimiento general y es el modelo con el AUC-ROC más alto (0.990). Este modelo parece ser el más equilibrado, con una capacidad sólida para generalizar.\n",
    "\n",
    "* **n_estimators = 70, max_depth = 4, min_samples_split = 3**: Este modelo presenta el peor rendimiento en comparación con los demás, con una exactitud de 0.947 en los datos de prueba y un F1 score de 0.927. Sin embargo, sigue siendo un modelo competitivo, pero muestra señales claras de underfitting, con una menor capacidad para capturar la complejidad de los datos en comparación con otros modelos.\n",
    "\n",
    "#### El modelo con **n_estimators = 150, max_depth = 10, min_samples_split = 6** parece ser el mejor. Ofrece un buen equilibrio entre los datos de entrenamiento y los de prueba, con un F1 score de 0.929 y una exactitud de 0.947 en los datos de prueba. Además, mantiene una precisión de 1.000 en los datos de entrenamiento y tiene buenos valores de AUC-ROC (0.991) y Precision-Recall AUC (0.986). Este modelo proporciona un rendimiento robusto sin un sobreajuste significativo, lo que lo convierte en una excelente opción para este conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4.5 k-Vecinos más Cercanos (k-NN)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### al igual que en el algoritmo anterior, vamos a tener para aplicar a cada dataset:\n",
    "### para clasificación:\n",
    "* DecisionTreeClassifier()  y métricas (Exactitud, F1 Score, Sensibilidad y Precisión) y añadidas (AUC-ROC y Precision-Recall AUC)\n",
    "### para regresión:\n",
    "* DecisionTreeRegressor() y métricas (MAE, MSE, R2 Score) y añadidas (RMSE y Explained Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un modelo de K-Nearest Neighbors (KNN)\n",
    "def aplicar_knn_hiper(df, target_column, tipo_modelo='regresion', n_neighbors=5, weights='uniform', metric='euclidean'):\n",
    "    # Separar las características (X) y la variable objetivo (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Seleccionar el modelo dependiendo del tipo (regresión o clasificación)\n",
    "    if tipo_modelo == 'regresion':\n",
    "        model = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights, metric=metric)  # Ajustado con los hiperparámetros\n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric)  # Ajustado con los hiperparámetros\n",
    "\n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones sobre los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo con las métricas correspondientes\n",
    "    if tipo_modelo == 'regresion':\n",
    "        # Métricas existentes\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"MAE\", mae_train, mae_test)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"MSE\", mse_train, mse_test)\n",
    "        \n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"R2 Score\", r2_train, r2_test)\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        rmse_train, evs_train = metricas_regresion_adicionales(y_train, y_train_pred)\n",
    "        rmse_test, evs_test = metricas_regresion_adicionales(y_test, y_test_pred)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"RMSE\", rmse_train, rmse_test)\n",
    "        mostrarMetricasRegresion(\"KNN\", \"Explained Variance\", evs_train, evs_test)\n",
    "    \n",
    "    elif tipo_modelo == 'clasificacion':\n",
    "        # Métricas existentes\n",
    "        exactitud_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        exactitud_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"Exactitud\", exactitud_train, exactitud_test)\n",
    "        \n",
    "        f1_train = metrics.f1_score(y_train, y_train_pred, average='binary')  # Cambiar a 'micro' o 'macro' si es multiclase\n",
    "        f1_test = metrics.f1_score(y_test, y_test_pred, average='binary')\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"F1 Score\", f1_train, f1_test)\n",
    "        \n",
    "        sensibilidad_train = metrics.recall_score(y_train, y_train_pred)\n",
    "        sensibilidad_test = metrics.recall_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"Sensibilidad\", sensibilidad_train, sensibilidad_test)\n",
    "        \n",
    "        precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "        precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"Precisión\", precision_train, precision_test)\n",
    "        \n",
    "        # Probabilidades para AUC-ROC y Precision-Recall AUC\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Nuevas métricas\n",
    "        auc_roc_train, pr_auc_train = metricas_clasificacion_adicionales(y_train, y_train_pred, y_train_prob)\n",
    "        auc_roc_test, pr_auc_test = metricas_clasificacion_adicionales(y_test, y_test_pred, y_test_prob)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"AUC-ROC\", auc_roc_train, auc_roc_test)\n",
    "        mostrarMetricasClasificacion(\"KNN\", \"Precision-Recall AUC\", pr_auc_train, pr_auc_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usaremos estos hiperparámetros:\n",
    "* **n_neighbors:** Este parámetro controla la cantidad de vecinos más cercanos que el modelo utiliza al hacer una predicción. Si el número de vecinos es bajo, el modelo se ajusta demasiado a los datos de entrenamiento, lo que puede generar un sobreajuste. En cambio, si usamos un número alto de vecinos, el modelo tiende a ser más general, lo que podría hacer que no capture bien los patrones del conjunto de datos, resultando en un modelo demasiado sencillo.\n",
    "* **weights:**  Este parámetro determina el peso que se le asigna a cada vecino en el proceso de predicción. Si seleccionamos 'uniform', todos los vecinos tienen el mismo peso, lo que significa que todos contribuyen por igual a la predicción. Si seleccionamos 'distance', los vecinos más cercanos tendrán mayor peso, dado que los puntos más cercanos a la predicción son los más relevantes.\n",
    "* **metric:** Este parámetro define la medida que usamos para calcular la distancia entre puntos. De manera predeterminada, usamos la distancia Euclidiana, que es la más común, pero podemos elegir otras métricas como Manhattan o Minkowski dependiendo de la naturaleza de nuestros datos y lo que queramos analizar. Cada una de estas métricas tiene características diferentes y se adapta mejor a distintos tipos de distribuciones de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.5.1 k-Vecinos más Cercanos Aplicado a TEMPERATURA ESPAÑA` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin hiperparámetros\n",
      "KNN : MAE en los datos de entrenamiento: 0.713\n",
      "KNN : MAE en los datos de testeo: 0.883\n",
      "\n",
      "KNN : MSE en los datos de entrenamiento: 0.839\n",
      "KNN : MSE en los datos de testeo: 1.219\n",
      "\n",
      "KNN : R2 Score en los datos de entrenamiento: 0.912\n",
      "KNN : R2 Score en los datos de testeo: 0.867\n",
      "\n",
      "KNN : RMSE en los datos de entrenamiento: 0.916\n",
      "KNN : RMSE en los datos de testeo: 1.104\n",
      "\n",
      "KNN : Explained Variance en los datos de entrenamiento: 0.912\n",
      "KNN : Explained Variance en los datos de testeo: 0.867\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "n_neighbors = 5, weights = 'uniform', metric = 'euclidean'\n",
      "KNN : MAE en los datos de entrenamiento: 0.713\n",
      "KNN : MAE en los datos de testeo: 0.883\n",
      "\n",
      "KNN : MSE en los datos de entrenamiento: 0.839\n",
      "KNN : MSE en los datos de testeo: 1.219\n",
      "\n",
      "KNN : R2 Score en los datos de entrenamiento: 0.912\n",
      "KNN : R2 Score en los datos de testeo: 0.867\n",
      "\n",
      "KNN : RMSE en los datos de entrenamiento: 0.916\n",
      "KNN : RMSE en los datos de testeo: 1.104\n",
      "\n",
      "KNN : Explained Variance en los datos de entrenamiento: 0.912\n",
      "KNN : Explained Variance en los datos de testeo: 0.867\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "n_neighbors = 7, weights = 'uniform', metric = 'manhattan'\n",
      "KNN : MAE en los datos de entrenamiento: 0.718\n",
      "KNN : MAE en los datos de testeo: 0.903\n",
      "\n",
      "KNN : MSE en los datos de entrenamiento: 0.827\n",
      "KNN : MSE en los datos de testeo: 1.418\n",
      "\n",
      "KNN : R2 Score en los datos de entrenamiento: 0.913\n",
      "KNN : R2 Score en los datos de testeo: 0.845\n",
      "\n",
      "KNN : RMSE en los datos de entrenamiento: 0.909\n",
      "KNN : RMSE en los datos de testeo: 1.191\n",
      "\n",
      "KNN : Explained Variance en los datos de entrenamiento: 0.915\n",
      "KNN : Explained Variance en los datos de testeo: 0.847\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "n_neighbors = 10, weights = 'uniform', metric = 'minkowski'\n",
      "KNN : MAE en los datos de entrenamiento: 0.839\n",
      "KNN : MAE en los datos de testeo: 1.108\n",
      "\n",
      "KNN : MSE en los datos de entrenamiento: 1.134\n",
      "KNN : MSE en los datos de testeo: 1.936\n",
      "\n",
      "KNN : R2 Score en los datos de entrenamiento: 0.881\n",
      "KNN : R2 Score en los datos de testeo: 0.788\n",
      "\n",
      "KNN : RMSE en los datos de entrenamiento: 1.065\n",
      "KNN : RMSE en los datos de testeo: 1.391\n",
      "\n",
      "KNN : Explained Variance en los datos de entrenamiento: 0.884\n",
      "KNN : Explained Variance en los datos de testeo: 0.795\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "n_neighbors = 3, weights = 'uniform', metric = 'euclidean'\n",
      "KNN : MAE en los datos de entrenamiento: 0.874\n",
      "KNN : MAE en los datos de testeo: 1.156\n",
      "\n",
      "KNN : MSE en los datos de entrenamiento: 1.329\n",
      "KNN : MSE en los datos de testeo: 2.059\n",
      "\n",
      "KNN : R2 Score en los datos de entrenamiento: 0.861\n",
      "KNN : R2 Score en los datos de testeo: 0.775\n",
      "\n",
      "KNN : RMSE en los datos de entrenamiento: 1.153\n",
      "KNN : RMSE en los datos de testeo: 1.435\n",
      "\n",
      "KNN : Explained Variance en los datos de entrenamiento: 0.861\n",
      "KNN : Explained Variance en los datos de testeo: 0.783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso para un modelo de regresión con KNN:\n",
    "\n",
    "print(\"Sin hiperparámetros\")\n",
    "KVecinos_modelesp = aplicar_knn(dfesp_limpio, 'rain_days', tipo_modelo='regresion')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"n_neighbors = 5, weights = 'uniform', metric = 'euclidean'\")\n",
    "KVecinos_hiper_esp = aplicar_knn_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', n_neighbors=5, weights='uniform', metric='euclidean')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"n_neighbors = 7, weights = 'uniform', metric = 'manhattan'\")\n",
    "KVecinos_hiper_esp2 = aplicar_knn_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', n_neighbors=7, weights='uniform', metric='manhattan')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"n_neighbors = 10, weights = 'uniform', metric = 'minkowski'\")\n",
    "KVecinos_hiper_esp3 = aplicar_knn_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', n_neighbors=10, weights='uniform', metric='minkowski')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"n_neighbors = 3, weights = 'uniform', metric = 'euclidean'\")\n",
    "KVecinos_hiper_esp4 = aplicar_knn_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', n_neighbors=3, weights='uniform', metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**    | **n_neighbors = 5, weights = 'uniform', metric = 'euclidean'** | **n_neighbors = 7, weights = 'uniform', metric = 'manhattan'** | **n_neighbors = 10, weights = 'uniform', metric = 'minkowski'** | **n_neighbors = 3, weights = 'uniform', metric = 'euclidean'** |\n",
    "|------------------------------------|----------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|\n",
    "| **MAE**                            | 0.713 / 0.883              | 0.713 / 0.883                                                   | **0.718 / 0.903**                                                   | 0.839 / 1.108            | 0.874 / 1.156                                                   |\n",
    "| **MSE**                            | 0.839 / 1.219              | 0.839 / 1.219                                                   | **0.827 / 1.418**                                                   | 1.134 / 1.936            | 1.329 / 2.059                                                   |\n",
    "| **R2 Score**                       | 0.912 / 0.867              | 0.912 / 0.867                                                   | **0.913 / 0.845**                                                   | 0.881 / 0.788            | 0.861 / 0.775                                                   |\n",
    "| **RMSE**                           | 0.916 / 1.104              | 0.916 / 1.104                                                   | **0.909 / 1.191**                                                   | 1.065 / 1.391            | 1.153 / 1.435                                                   |\n",
    "| **Explained Variance**             | 0.912 / 0.867              | 0.912 / 0.867                                                   | **0.915 / 0.847**                                                   | 0.884 / 0.795            | 0.861 / 0.783                                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de cada modelo KNN:\n",
    "* **Sin Hiperparámetros**: El modelo de KNN muestra un buen rendimiento en los datos de entrenamiento, pero sufre de sobreajuste cuando se evalúa en los datos de prueba. El MAE y MSE son bajos en entrenamiento, pero se incrementan significativamente en el conjunto de prueba, lo que indica que el modelo podría no estar generalizando bien.\n",
    "* **n_neighbors = 5, weights = 'uniform', metric = 'euclidean'**: Los resultados no presentan grandes mejoras respecto al modelo sin hiperparámetros. Aunque el rendimiento en los datos de prueba es ligeramente mejor, sigue existiendo un cierto grado de sobreajuste, con un R2 en prueba de 0.867 y un MAE de 0.883. Esto sugiere que el modelo aún tiene dificultades para generalizar.\n",
    "* **n_neighbors = 7, weights = 'uniform', metric = 'manhattan'**:  En este caso, el modelo muestra un rendimiento decente, aunque no es perfecto. El MAE y MSE en entrenamiento son ligeramente superiores a los de los modelos anteriores, pero en los datos de prueba, el R2 sigue siendo razonable con un valor de 0.845. Este modelo ha logrado un mejor ajuste en los datos de prueba en comparación con otros modelos, lo que indica que ha generalizado de una manera más efectiva.\n",
    "\n",
    "* **n_neighbors = 10, weights = 'uniform', metric = 'minkowski'**: Este modelo tiene peores resultados que los anteriores, tanto en entrenamiento como en prueba. El MAE en prueba es de 1.108 y el MSE es de 1.936, lo que indica un rendimiento más pobre en ambos conjuntos de datos. Este modelo parece no ser adecuado, ya que tiene un R2 de 0.788 en prueba, lo que indica que no está capturando bien la relación entre las variables.\n",
    "* **n_neighbors = 3, weights = 'uniform', metric = 'euclidean'**: Similar al modelo con n_neighbors = 7, este modelo tiene un MAE y MSE cercanos a cero en entrenamiento, lo que sugiere sobreajuste. Sin embargo, los resultados en el conjunto de prueba son peores, con un R2 de 0.775 y un MAE de 1.156, lo que indica que el modelo no ha generalizado bien.\n",
    "\n",
    "#### El modelo con **n_neighbors = 7, weights = 'uniform', metric = 'manhattan'** parece ser el más prometedor, ya que ha logrado un equilibrio razonable entre los datos de entrenamiento y prueba, aunque sigue mostrando un leve sobreajuste. Sin embargo, otros modelos con 3 y 5 vecinos también lograron buenos resultados en los datos de prueba, pero con menos capacidad de generalización. Aunque ninguno de los modelos se aproxima a un rendimiento perfecto, el modelo con 7 vecinos presenta una combinación bastante equilibrada entre la capacidad de ajuste y la generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.5.2 k-Vecinos más Cercanos Aplicado a PHISHING URLS` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN : Exactitud en los datos de entrenamiento: 0.964\n",
      "KNN : Exactitud en los datos de testeo: 0.940\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.968\n",
      "KNN : F1 Score en los datos de testeo: 0.946\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.971\n",
      "KNN : Sensibilidad en los datos de testeo: 0.950\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.965\n",
      "KNN : Precisión en los datos de testeo: 0.943\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.995\n",
      "KNN : AUC-ROC en los datos de testeo: 0.982\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.994\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.978\n",
      "\n",
      "Sin hiperparámetros\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.964\n",
      "KNN : Exactitud en los datos de testeo: 0.940\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.968\n",
      "KNN : F1 Score en los datos de testeo: 0.946\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.971\n",
      "KNN : Sensibilidad en los datos de testeo: 0.950\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.965\n",
      "KNN : Precisión en los datos de testeo: 0.943\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.995\n",
      "KNN : AUC-ROC en los datos de testeo: 0.982\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.994\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.978\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "n_neighbors = 5, weights = 'uniform', metric = 'euclidean'\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.964\n",
      "KNN : Exactitud en los datos de testeo: 0.940\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.968\n",
      "KNN : F1 Score en los datos de testeo: 0.946\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.971\n",
      "KNN : Sensibilidad en los datos de testeo: 0.950\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.965\n",
      "KNN : Precisión en los datos de testeo: 0.943\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.995\n",
      "KNN : AUC-ROC en los datos de testeo: 0.982\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.994\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.978\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "n_neighbors = 10, weights = 'distance', metric = 'manhattan'\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.991\n",
      "KNN : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.992\n",
      "KNN : F1 Score en los datos de testeo: 0.969\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.991\n",
      "KNN : Sensibilidad en los datos de testeo: 0.975\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.993\n",
      "KNN : Precisión en los datos de testeo: 0.962\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.989\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.986\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "n_neighbors = 7, weights = 'uniform', metric = 'minkowski'\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.960\n",
      "KNN : Exactitud en los datos de testeo: 0.936\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.964\n",
      "KNN : F1 Score en los datos de testeo: 0.943\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.964\n",
      "KNN : Sensibilidad en los datos de testeo: 0.942\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.963\n",
      "KNN : Precisión en los datos de testeo: 0.944\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.994\n",
      "KNN : AUC-ROC en los datos de testeo: 0.984\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.993\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.982\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "n_neighbors = 15, weights = 'distance', metric = 'euclidean'\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.991\n",
      "KNN : Exactitud en los datos de testeo: 0.957\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.992\n",
      "KNN : F1 Score en los datos de testeo: 0.961\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.991\n",
      "KNN : Sensibilidad en los datos de testeo: 0.967\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.993\n",
      "KNN : Precisión en los datos de testeo: 0.956\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.987\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar k-Vecinos más Cercanos al dataset dfphishing_limpio para clasificación\n",
    "KVecinos_modelphishing = aplicar_knn(dfphishing_limpio, 'class', tipo_modelo='clasificacion')\n",
    "\n",
    "# Ejemplo de uso para un modelo de clasificación con KNN:\n",
    "\n",
    "print(\"Sin hiperparámetros\")\n",
    "KVecinos_modelphishing_sin_hiper = aplicar_knn(dfphishing_limpio, 'class', tipo_modelo='clasificacion')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"n_neighbors = 5, weights = 'uniform', metric = 'euclidean'\")\n",
    "KVecinos_hiper_1 = aplicar_knn_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_neighbors=5, weights='uniform', metric='euclidean')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"n_neighbors = 10, weights = 'distance', metric = 'manhattan'\")\n",
    "KVecinos_hiper_2 = aplicar_knn_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_neighbors=10, weights='distance', metric='manhattan')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"n_neighbors = 7, weights = 'uniform', metric = 'minkowski'\")\n",
    "KVecinos_hiper_3 = aplicar_knn_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_neighbors=7, weights='uniform', metric='minkowski')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"n_neighbors = 15, weights = 'distance', metric = 'euclidean'\")\n",
    "KVecinos_hiper_4 = aplicar_knn_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_neighbors=15, weights='distance', metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Sin Hiperparámetros**  | **n_neighbors = 5, weights = 'uniform', metric = 'euclidean'** | **n_neighbors = 10, weights = 'distance', metric = 'manhattan'** | **n_neighbors = 7, weights = 'uniform', metric = 'minkowski'** | **n_neighbors = 15, weights = 'distance', metric = 'euclidean'** |\n",
    "|------------------------------------|--------------------------|---------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|\n",
    "| **Exactitud**                      | 0.964 / 0.940            | 0.964 / 0.940                                                 | **0.991 / 0.965**             | 0.960 / 0.936    | 0.991 / 0.957           |\n",
    "| **F1 Score**                       | 0.968 / 0.946            | 0.968 / 0.946                                                 | **0.992 / 0.969**             | 0.964 / 0.943    | 0.992 / 0.961           | \n",
    "| **Sensibilidad**                   | 0.971 / 0.950            | 0.971 / 0.950                                                 | **0.991 / 0.975**             | 0.964 / 0.942    | 0.991 / 0.967           | \n",
    "| **Precisión**                      | 0.965 / 0.943            | 0.965 / 0.943                                                 | **0.993 / 0.962**             | 0.963 / 0.944    | 0.993 / 0.956           | \n",
    "| **AUC-ROC**                        | 0.995 / 0.982            | 0.995 / 0.982                                                 | **1.000 / 0.989**             | 0.994 / 0.984    | 1.000 / 0.987           | \n",
    "| **Precision-Recall AUC**           | 0.994 / 0.978            | 0.994 / 0.978                                                 | **1.000 / 0.986**             | 0.993 / 0.982    | 1.000 / 0.985           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de cada modelo:\n",
    "* **Sin Hiperparámetros**: El modelo muestra buen rendimiento en entrenamiento (exactitud 0.964, F1 0.968), pero con ligera caída en prueba (exactitud 0.940, F1 0.946), sugiriendo sobreajuste.\n",
    "* **n_neighbors = 5, weights = 'uniform', metric = 'euclidean'**: Resultados similares al modelo sin hiperparámetros. El modelo sigue mostrando sobreajuste sin mejoras significativas.\n",
    "* **n_neighbors = 10, weights = 'distance', metric = 'manhattan'**: Este modelo mejora significativamente en los datos de prueba, con una exactitud de 0.991 en entrenamiento y 0.965 en prueba, además de un F1 Score de 0.992 en entrenamiento y 0.969 en prueba. Muestra un mejor equilibrio entre entrenamiento y prueba, con un leve sobreajuste en entrenamiento que es más reducido que en los modelos anteriores.\n",
    "* **n_neighbors = 7, weights = 'uniform', metric = 'minkowski'**: El rendimiento de este modelo es similar al anterior, con una exactitud de 0.960 en entrenamiento y 0.936 en prueba. Si bien el modelo tiene un desempeño decente, la caída en exactitud y F1 Score en los datos de prueba indica que no generaliza tan bien como los otros modelos con más vecinos.\n",
    "* **n_neighbors = 15, weights = 'distance', metric = 'euclidean'**: Este modelo destaca por su rendimiento equilibrado, con una exactitud de 0.991 en entrenamiento y 0.957 en prueba, y un F1 Score de 0.992 en entrenamiento y 0.961 en prueba. Logra un buen equilibrio entre ajuste y generalización, siendo uno de los mejores modelos en términos de rendimiento de prueba.\n",
    "rendimiento en la prueba.\n",
    "#### El modelo con **n_neighbors = 10, weights = 'distance', metric = 'manhattan'** destaca como el más prometedor, ya que ofrece el mejor equilibrio entre los datos de entrenamiento y prueba, con una mejora significativa en comparación con los modelos anteriores, y un bajo grado de sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.5.3 k-Vecinos más Cercanos Aplicado a CALIDAD DEL VINO` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN : Exactitud en los datos de entrenamiento: 0.793\n",
      "KNN : Exactitud en los datos de testeo: 0.729\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.813\n",
      "KNN : F1 Score en los datos de testeo: 0.762\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.832\n",
      "KNN : Sensibilidad en los datos de testeo: 0.780\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.795\n",
      "KNN : Precisión en los datos de testeo: 0.744\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.888\n",
      "KNN : AUC-ROC en los datos de testeo: 0.806\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.884\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.817\n",
      "\n",
      "Sin hiperparámetros\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.793\n",
      "KNN : Exactitud en los datos de testeo: 0.729\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.813\n",
      "KNN : F1 Score en los datos de testeo: 0.762\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.832\n",
      "KNN : Sensibilidad en los datos de testeo: 0.780\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.795\n",
      "KNN : Precisión en los datos de testeo: 0.744\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.888\n",
      "KNN : AUC-ROC en los datos de testeo: 0.806\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.884\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.817\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "n_neighbors = 5, weights = 'uniform', metric = 'euclidean'\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.793\n",
      "KNN : Exactitud en los datos de testeo: 0.729\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.813\n",
      "KNN : F1 Score en los datos de testeo: 0.762\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.832\n",
      "KNN : Sensibilidad en los datos de testeo: 0.780\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.795\n",
      "KNN : Precisión en los datos de testeo: 0.744\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.888\n",
      "KNN : AUC-ROC en los datos de testeo: 0.806\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.884\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.817\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "n_neighbors = 10, weights = 'distance', metric = 'manhattan'\n",
      "KNN : Exactitud en los datos de entrenamiento: 1.000\n",
      "KNN : Exactitud en los datos de testeo: 0.764\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 1.000\n",
      "KNN : F1 Score en los datos de testeo: 0.792\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "KNN : Sensibilidad en los datos de testeo: 0.811\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 1.000\n",
      "KNN : Precisión en los datos de testeo: 0.774\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.872\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.910\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "n_neighbors = 7, weights = 'uniform', metric = 'minkowski'\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.795\n",
      "KNN : Exactitud en los datos de testeo: 0.738\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.818\n",
      "KNN : F1 Score en los datos de testeo: 0.767\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.848\n",
      "KNN : Sensibilidad en los datos de testeo: 0.780\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.789\n",
      "KNN : Precisión en los datos de testeo: 0.756\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.877\n",
      "KNN : AUC-ROC en los datos de testeo: 0.815\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.874\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.826\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "n_neighbors = 15, weights = 'distance', metric = 'euclidean'\n",
      "KNN : Exactitud en los datos de entrenamiento: 1.000\n",
      "KNN : Exactitud en los datos de testeo: 0.790\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 1.000\n",
      "KNN : F1 Score en los datos de testeo: 0.815\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "KNN : Sensibilidad en los datos de testeo: 0.835\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 1.000\n",
      "KNN : Precisión en los datos de testeo: 0.797\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.888\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar k-Vecinos más Cercanos al dataset dfvino_limpio\n",
    "KVecinos_modelvino = aplicar_knn(dfvino_limpio, 'quality', tipo_modelo='clasificacion')\n",
    "\n",
    "# Ejemplo de uso para un modelo de clasificación con KNN:\n",
    "\n",
    "print(\"Sin hiperparámetros\")\n",
    "KVecinos_modelvino_sin_hiper = aplicar_knn(dfvino_limpio, 'quality', tipo_modelo='clasificacion')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"n_neighbors = 5, weights = 'uniform', metric = 'euclidean'\")\n",
    "KVecinos_hiper_1 = aplicar_knn_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', n_neighbors=5, weights='uniform', metric='euclidean')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"n_neighbors = 10, weights = 'distance', metric = 'manhattan'\")\n",
    "KVecinos_hiper_2 = aplicar_knn_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', n_neighbors=10, weights='distance', metric='manhattan')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"n_neighbors = 7, weights = 'uniform', metric = 'minkowski'\")\n",
    "KVecinos_hiper_3 = aplicar_knn_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', n_neighbors=7, weights='uniform', metric='minkowski')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"n_neighbors = 15, weights = 'distance', metric = 'euclidean'\")\n",
    "KVecinos_hiper_4 = aplicar_knn_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', n_neighbors=15, weights='distance', metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**  | **Sin Hiperparámetros**  | **n_neighbors = 5, weights = 'uniform', metric = 'euclidean'** | **n_neighbors = 10, weights = 'distance', metric = 'manhattan'** | **n_neighbors = 7, weights = 'uniform', metric = 'minkowski'** | **n_neighbors = 15, weights = 'distance', metric = 'euclidean'** |\n",
    "|------------------------------------|--------------------------|---------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|\n",
    "| **Exactitud**                      | 0.793 / 0.729            | 0.793 / 0.729                                                 | 1.000 / 0.764             | 0.795 / 0.738    | **1.000 / 0.790**           |\n",
    "| **F1 Score**                       | 0.813 / 0.762            | 0.813 / 0.762                                                 | 1.000 / 0.792             | 0.818 / 0.767    | **1.000 / 0.815**           | \n",
    "| **Sensibilidad**                   | 0.832 / 0.780            | 0.832 / 0.780                                                 | 1.000 / 0.811             | 0.848 / 0.780    | **1.000 / 0.835**           | \n",
    "| **Precisión**                      | 0.795 / 0.744            | 0.795 / 0.744                                                 | 1.000 / 0.774             | 0.789 / 0.756    | **1.000 / 0.797**           | \n",
    "| **AUC-ROC**                        | 0.888 / 0.806            | 0.888 / 0.806                                                 | 1.000 / 0.872             | 0.877 / 0.815    | **1.000 / 0.888**           | \n",
    "| **Precision-Recall AUC**           | 0.884 / 0.817            | 0.884 / 0.817                                                 | 1.000 / 0.910             | 0.874 / 0.826    | **1.000 / 0.920**           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones por modelo:\n",
    "* **Sin Hiperparámetros:** El modelo sin hiperparámetros tiene un desempeño decente en cuanto a exactitud y F1 Score, pero en general muestra que aún puede mejorarse al ajustar ciertos parámetros como el número de vecinos, el peso y la métrica de distancia.\n",
    "* **n_neighbors = 5, weights = 'uniform', metric = 'euclidean':** Este modelo no muestra mejoras significativas en comparación con el modelo sin hiperparámetros. Los resultados de exactitud, F1 Score, sensibilidad, y precisión son similares. Esto indica que la elección de 5 vecinos y la métrica Euclidiana no optimiza mucho el rendimiento.\n",
    "* **n_neighbors = 10, weights = 'distance', metric = 'manhattan':** Este modelo muestra una exactitud de 1.000 en los datos de entrenamiento, pero una baja exactitud en los datos de testeo (0.764). Sin embargo, el F1 Score y otros parámetros como sensibilidad y precisión en los datos de testeo mejoran en comparación con el primer caso. La métrica Manhattan y el peso 'distance' parecen generar buenos resultados en el entrenamiento, pero sobreajustando el modelo a los datos de entrenamiento.\n",
    "* **n_neighbors = 7, weights = 'uniform', metric = 'minkowski':** Este modelo muestra un buen equilibrio entre exactitud en los datos de testeo (0.738) y exactitud en entrenamiento (0.795). El F1 Score también es bastante bueno (0.818 en entrenamiento y 0.767 en testeo), lo que indica que este modelo tiene un rendimiento más robusto y menos propenso al sobreajuste.\n",
    "* **n_neighbors = 15, weights = 'distance', metric = 'euclidean':** Y este último también se comporta igual en los datos de entrenamiento que el anterior, con exactitud y F1 Score de 1.000. En los datos de testeo, se obtiene una mejora significativa en comparación con los otros modelos, especialmente en sensibilidad (0.835) y precision-recall AUC (0.920). La elección de n_neighbors = 15 y el uso del 'distance' como peso junto con la métrica 'euclidean' muestra el mejor equilibrio entre ajuste y generalización.\n",
    "#### Escogería el modelo **n_neighbors = 15, weights = 'distance', metric = 'euclidean'** porque tiene un rendimiento excelente en los datos de testeo con una exactitud de 0.790 y el mejor valor de AUC-ROC (0.888). Aunque n_neighbors = 15 podría hacer que el modelo sea más general, el uso de weights = 'distance' y metric = 'euclidean' permite que los vecinos cercanos tengan un mayor peso, lo que mejora la precisión sin perder capacidad de generalización. Esta combinación ayuda a evitar el sobreajuste, manteniendo un buen equilibrio entre precisión y generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.5.4 k-Vecinos más Cercanos Aplicado a DIAGNOSTICO DE CANCER DE MAMA` (con hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN : Exactitud en los datos de entrenamiento: 0.978\n",
      "KNN : Exactitud en los datos de testeo: 0.930\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.970\n",
      "KNN : F1 Score en los datos de testeo: 0.900\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.953\n",
      "KNN : Sensibilidad en los datos de testeo: 0.837\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.988\n",
      "KNN : Precisión en los datos de testeo: 0.973\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "KNN : AUC-ROC en los datos de testeo: 0.983\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.995\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.976\n",
      "\n",
      "Sin hiperparámetros\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.978\n",
      "KNN : Exactitud en los datos de testeo: 0.930\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.970\n",
      "KNN : F1 Score en los datos de testeo: 0.900\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.953\n",
      "KNN : Sensibilidad en los datos de testeo: 0.837\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.988\n",
      "KNN : Precisión en los datos de testeo: 0.973\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "KNN : AUC-ROC en los datos de testeo: 0.983\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.995\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.976\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "PRIMER CASO\n",
      "n_neighbors = 5, weights = 'uniform', metric = 'euclidean'\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.978\n",
      "KNN : Exactitud en los datos de testeo: 0.930\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.970\n",
      "KNN : F1 Score en los datos de testeo: 0.900\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.953\n",
      "KNN : Sensibilidad en los datos de testeo: 0.837\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.988\n",
      "KNN : Precisión en los datos de testeo: 0.973\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.998\n",
      "KNN : AUC-ROC en los datos de testeo: 0.983\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.995\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.976\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SEGUNDO CASO\n",
      "n_neighbors = 10, weights = 'distance', metric = 'manhattan'\n",
      "KNN : Exactitud en los datos de entrenamiento: 1.000\n",
      "KNN : Exactitud en los datos de testeo: 0.939\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 1.000\n",
      "KNN : F1 Score en los datos de testeo: 0.914\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "KNN : Sensibilidad en los datos de testeo: 0.860\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 1.000\n",
      "KNN : Precisión en los datos de testeo: 0.974\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.996\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.994\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TERCER CASO\n",
      "n_neighbors = 7, weights = 'uniform', metric = 'minkowski'\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.978\n",
      "KNN : Exactitud en los datos de testeo: 0.939\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.970\n",
      "KNN : F1 Score en los datos de testeo: 0.911\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.953\n",
      "KNN : Sensibilidad en los datos de testeo: 0.837\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.988\n",
      "KNN : Precisión en los datos de testeo: 1.000\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 0.997\n",
      "KNN : AUC-ROC en los datos de testeo: 0.981\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 0.994\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.971\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "CUARTO CASO\n",
      "n_neighbors = 15, weights = 'distance', metric = 'euclidean'\n",
      "KNN : Exactitud en los datos de entrenamiento: 1.000\n",
      "KNN : Exactitud en los datos de testeo: 0.947\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 1.000\n",
      "KNN : F1 Score en los datos de testeo: 0.925\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "KNN : Sensibilidad en los datos de testeo: 0.860\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 1.000\n",
      "KNN : Precisión en los datos de testeo: 1.000\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.994\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar k-Vecinos más Cercanos al dataset dfcancer_limpio\n",
    "KVecinos_modelcancer = aplicar_knn(dfcancer_limpio, 'y', tipo_modelo='clasificacion')\n",
    "\n",
    "# Ejemplo de uso para un modelo de clasificación con KNN:\n",
    "\n",
    "print(\"Sin hiperparámetros\")\n",
    "KVecinos_modelcancer_sin_hiper = aplicar_knn(dfcancer_limpio, 'y', tipo_modelo='clasificacion')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"PRIMER CASO\")\n",
    "print(\"n_neighbors = 5, weights = 'uniform', metric = 'euclidean'\")\n",
    "KVecinos_hiper_1 = aplicar_knn_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', n_neighbors=5, weights='uniform', metric='euclidean')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"SEGUNDO CASO\")\n",
    "print(\"n_neighbors = 10, weights = 'distance', metric = 'manhattan'\")\n",
    "KVecinos_hiper_2 = aplicar_knn_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', n_neighbors=10, weights='distance', metric='manhattan')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"TERCER CASO\")\n",
    "print(\"n_neighbors = 7, weights = 'uniform', metric = 'minkowski'\")\n",
    "KVecinos_hiper_3 = aplicar_knn_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', n_neighbors=7, weights='uniform', metric='minkowski')\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"CUARTO CASO\")\n",
    "print(\"n_neighbors = 15, weights = 'distance', metric = 'euclidean'\")\n",
    "KVecinos_hiper_4 = aplicar_knn_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', n_neighbors=15, weights='distance', metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**   | **Sin Hiperparámetros**  | **n_neighbors = 5, weights = 'uniform', metric = 'euclidean'** | **n_neighbors = 10, weights = 'distance', metric = 'manhattan'** | **n_neighbors = 7, weights = 'uniform', metric = 'minkowski'** | **n_neighbors = 15, weights = 'distance', metric = 'euclidean'** |\n",
    "|------------------------------------|--------------------------|---------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|\n",
    "| **Exactitud**                      | 0.978 / 0.930            | 0.978 / 0.930                                                 | 1.000 / 0.939             | 0.978 / 0.939    | **1.000 / 0.947**           |\n",
    "| **F1 Score**                       | 0.970 / 0.900            | 0.970 / 0.900                                                 | 1.000 / 0.914             | 0.970 / 0.911    | **1.000 / 0.925**           | \n",
    "| **Sensibilidad**                   | 0.953 / 0.837            | 0.953 / 0.837                                                 | 1.000 / 0.860             | 0.953 / 0.837    | **1.000 / 0.860**           | \n",
    "| **Precisión**                      | 0.988 / 0.973            | 0.988 / 0.973                                                 | 1.000 / 0.974             | 0.988 / 1.000    | **1.000 / 1.000**           | \n",
    "| **AUC-ROC**                        | 0.998 / 0.983            | 0.998 / 0.983                                                 | 1.000 / 0.996             | 0.997 / 0.981    | **1.000 / 0.994**           | \n",
    "| **Precision-Recall AUC**           | 0.995 / 0.976            | 0.995 / 0.976                                                 | 1.000 / 0.994             | 0.994 / 0.971    | **1.000 / 0.991**           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones por modelo:\n",
    "* **Sin Hiperparámetros:** El modelo sin hiperparámetros muestra una exactitud y F1 Score sólidos, tanto en los datos de entrenamiento como en los de testeo. Sin embargo, el modelo todavía tiene margen para optimizarse, ya que no se han ajustado los parámetros que podrían mejorar la capacidad de generalización y evitar el sobreajuste.\n",
    "\n",
    "* **n_neighbors = 5, weights = 'uniform', metric = 'euclidean':** Este modelo mantiene un rendimiento muy similar al del modelo sin hiperparámetros. La exactitud y el F1 Score siguen siendo buenos, pero no se observa una mejora considerable en comparación con el modelo base. Esto sugiere que la configuración de 5 vecinos y la métrica Euclidiana no es la opción óptima para este conjunto de datos.\n",
    "\n",
    "* **n_neighbors = 10, weights = 'distance', metric = 'manhattan':** Este modelo muestra una mejora significativa en los datos de entrenamiento (con una exactitud de 1.000), pero también un sobreajuste evidente, ya que la exactitud de testeo es algo más baja (0.939). Sin embargo, el F1 Score y otros parámetros como la sensibilidad y precisión en los datos de testeo mejoran, lo que indica que la combinación de 10 vecinos, el peso 'distance' y la métrica Manhattan está proporcionando buenos resultados, pero es necesario ajustar para evitar el sobreajuste.\n",
    "\n",
    "* **n_neighbors = 7, weights = 'uniform', metric = 'minkowski':** Este modelo tiene un buen rendimiento tanto en los datos de entrenamiento como en los de testeo. La exactitud en testeo es de 0.939, lo que es bastante alto, y el F1 Score también se mantiene sólido (0.911 en testeo). Esto indica que la configuración con 7 vecinos y la métrica Minkowski da un buen equilibrio entre precisión y generalización.\n",
    "\n",
    "* **n_neighbors = 15, weights = 'distance', metric = 'euclidean':** Este modelo presenta un rendimiento impresionante en los datos de entrenamiento, con una exactitud de 1.000, pero también sobresale en los datos de testeo, alcanzando una exactitud de 0.947. Además, el F1 Score y la sensibilidad también se mantienen altos. Este modelo, con 15 vecinos y el uso de 'distance' como peso, muestra un excelente balance entre ajuste a los datos de entrenamiento y generalización en los datos de testeo.\n",
    "\n",
    "#### Escogería el modelo **n_neighbors = 15, weights = 'distance', metric = 'euclidean'** debido a su excelente rendimiento tanto en los datos de entrenamiento como en los de testeo. Con una exactitud de 0.947 en testeo y un F1 Score impresionante, este modelo muestra un buen balance entre precisión y generalización. Aunque el número de vecinos más alto podría sugerir una mayor suavidad en el modelo, la combinación con el peso 'distance' y la métrica 'euclidean' mejora la precisión sin caer en el sobreajuste, lo que lo convierte en la mejor opción para este conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Conclusiones de las mejores métricas obtenidas con hiperparámetros\n",
    "### Y las vamos a comparar con las de sin hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\"><strong>SIN HIPERPARÁMETROS</strong></p>\n",
    "\n",
    "| Algoritmo                | Dataset             | Exactitud(Accuracy) | F1 Score | Sensibilidad(recall) | Precisión | AUC-ROC | Precision-Recall AUC | MAE   | MSE   | R2 Score | RMSE  | Explained Variance |\n",
    "|--------------------------|---------------------|-----------|----------|---------------|-----------|---------|----------------------|-------|-------|----------|-------|--------------------|\n",
    "| **SVM**                   | dfesp_limpio        | ----      | ----    | ----          | ----      | ----    | ----                  | 0.584 / 0.980   | 0.851 / 1.827  | 0.911 / 0.800 | 0.922 / 1.351 | 0.912 / 0.802  |\n",
    "| **SVM**                   | dfphishing_limpio   | 0.953 / 0.951      | 0.958 / 0.957    | 0.969 / 0.973        | 0.947 / 0.941      | 0.991 / 0.989   | 0.993 / 0.991  | ---- |---- |---- |---- |---- |\n",
    "| **SVM**                   | dfvino_limpio       | 0.802 / 0.764      | 0.814 / 0.791    | 0.804 / 0.803        | 0.825 / 0.779      | 0.878 / 0.874   | 0.892 / 0.898  | ---- |---- |---- |---- |---- |\n",
    "| **SVM**                   | dfcancer_limpio     | 0.987 / 0.956      | 0.982 / 0.941    | 0.970 / 0.930        | 0.994 / 0.952      | 0.998 / 0.997   | 0.997 / 0.996  | ---- |---- |---- |---- |---- |\n",
    "| **Regresión Logística**   | dfphishing_limpio   | 0.927 / 0.934      | 0.935 / 0.941    | 0.943 / 0.953        | 0.927 / 0.930      | 0.979 / 0.980   | 0.983 / 0.984  | ---- |---- |---- |---- |---- |\n",
    "| **Regresión Logística**   | dfvino_limpio       | 0.758 / 0.769      | 0.774 / 0.791    | 0.767 / 0.787        | 0.781 / 0.794      | 0.829 / 0.822   | 0.853 / 0.835  | ---- |---- |---- |---- |---- |\n",
    "| **Regresión Logística**   | dfcancer_limpio     | 0.991 / 0.965      | 0.988 / 0.953    | 0.976 / 0.953        | 1.000 / 0.953      | 0.998 / 0.995   | 0.997 / 0.993  | ---- |---- |---- |---- |---- |\n",
    "| **Árboles de Decisión**   | dfesp_limpio        | ----      | ----     | ----          | ----      | ----      | ----               | 0.000 / 0.583   | 0.000 / 0.688  | 1.000 / 0.925 | 0.000 / 0.829  | 1.000 / 0.929 |\n",
    "| **Árboles de Decisión**   | dfphishing_limpio   | 0.991 / 0.960      | 0.992 / 0.964    | 0.991 / 0.964        | 0.993 / 0.964      | 1.000 / 0.972   | 1.000 / 0.966                | ---- |---- |---- |---- |---- |\n",
    "| **Árboles de Decisión**   | dfvino_limpio       | 1.000 / 0.694      | 1.000 / 0.724    | 1.000 / 0.724        | 1.000 / 0.724      | 1.000 / 0.691   | 1.000 / 0.678                | ---- |---- |---- |---- |---- |\n",
    "| **Árboles de Decisión**   | dfcancer_limpio     | 1.000 / 0.921      | 1.000 / 0.897    | 1.000 / 0.907        | 1.000 / 0.886      | 1.000 / 0.918   | 1.000 / 0.839                | ---- |---- |---- |---- |---- |\n",
    "| **Bosques Aleatorios**    | dfesp_limpio        | ----      | ----     | ----          | ----       ----      | ----                | 0.192 / 0.596   | 0.083 / 0.950  | 0.991 / 0.896 | 0.288 / 0.975  | 0.991 / 0.900 |\n",
    "| **Bosques Aleatorios**    | dfphishing_limpio   | 0.991 / 0.969     | 0.992 / 0.973    | 0.993 / 0.977         | 0.991 / 0.969      | 1.000 / 0.995   | 1.000 / 0.995                | ---- |---- |---- |---- |---- |\n",
    "| **Bosques Aleatorios**    | dfvino_limpio       | 1.000 / 0.769     | 1.000 / 0.789    | 1.000 / 0.780         | 1.000 / 0.798      | 1.000 / 0.886   | 1.000 / 0.915                | ---- |---- |---- |---- |---- |\n",
    "| **Bosques Aleatorios**    | dfcancer_limpio     | 1.000 / 0.956     | 1.000 / 0.940    | 1.000 / 0.907         | 1.000 / 0.975      | 1.000 / 0.992   | 1.000 / 0.988                | ---- |---- |---- |---- |---- |\n",
    "| **K-Vecinos más Cercanos**| dfesp_limpio        | ----      | ----     | ----          | ----      | ----    | ----                 | 0.713 / 0.883   | 0.839 / 1.219  | 0.912 / 0.867 | 0.916 / 1.104  | 0.912 / 0.867 |\n",
    "| **K-Vecinos más Cercanos**| dfphishing_limpio   | 0.964 / 0.940     | 0.968 / 0.946    | 0.971 / 0.950         | 0.965 / 0.943      | 0.995 / 0.982   | 0.994 / 0.978                | ---- |---- |---- |---- |---- |\n",
    "| **K-Vecinos más Cercanos**| dfvino_limpio       | 0.793 / 0.729     | 0.813 / 0.762    | 0.832 / 0.780         | 0.795 / 0.744      | 0.888 / 0.806   | 0.884 / 0.817                | ---- |---- |---- |---- |---- |\n",
    "| **K-Vecinos más Cercanos**| dfcancer_limpio     | 0.978 / 0.930     | 0.970 / 0.900    | 0.953 / 0.837         | 0.988 / 0.973      | 0.998 / 0.983   | 0.995 / 0.976                | ---- |---- |---- |---- |---- |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><strong>CON HIPERPARÁMETROS</strong></p>\n",
    "\n",
    "| Algoritmo                | Dataset             | Exactitud(Accuracy) | F1 Score | Sensibilidad(recall) | Precisión | AUC-ROC | Precision-Recall AUC | MAE   | MSE   | R2 Score | RMSE  | Explained Variance |\n",
    "|--------------------------|---------------------|-----------|----------|---------------|-----------|---------|----------------------|-------|-------|----------|-------|--------------------|\n",
    "| **SVM C = 5, epsilon = 0.01, kernel = lineal** | dfesp_limpio        | ----     | ----   | ----        | ----     | ----       | ----     |0.517 / 0.632  | 0.526 / 0.653 | 0.945 / 0.929 | 0.725 / 0.808 | 0.945 / 0.930 |\n",
    "| **SVM C = 5, kernel = rbf** | dfphishing_limpio   | 0.972 / 0.966     | 0.975 / 0.970   | 0.980 / 0.978 | 0.969 / 0.962  | 0.995 / 0.992   | 0.997 / 0.993  | ----       | ----       |  ----         |  ----      |     ----                |\n",
    "| **SVM C = 5, kernel = rbf**  | dfvino_limpio      | 0.829 / 0.786     | 0.839 / 0.805   | 0.822 / 0.795 | 0.857 / 0.815  | 0.918 / 0.878   | 0.924 / 0.904  |   ----     |   ----     |    ----       |   ----     |     ----                |\n",
    "| **SVM C = 2, kernel = lineal** | dfcancer_limpio  | 0.989 / 0.982     | 0.985 / 0.977   | 0.976 / 0.977 | 0.994 / 0.977  | 0.997 / 0.997   | 0.997 / 0.996  |  ----      | ----       |----           | ----       |    ----                 |\n",
    "| **Regresión Logística solver = liblinear, max_iter = 100, penalty = l1**   | dfphishing_limpio     | 0.927 / 0.933     | 0.935 / 0.941    | 0.943 / 0.953         | 0.927 / 0.929     | 0.979 / 0.980   | 0.983 / 0.984|  ----      | ----       |----           | ----       |    ----   |\n",
    "| **Regresión Logística solver = liblinear, max_iter = 200, penalty = l1**   | dfvino_limpio         | 0.761 / 0.769     | 0.777 / 0.791    | 0.769 / 0.787         | 0.785 / 0.794     | 0.829 / 0.824   | 0.853 / 0.836|  ----      | ----       |----           | ----       |    ----   |\n",
    "| **Regresión Logística solver = saga, max_iter = 300, penalty = elasticnet**| dfcancer_limpio       | 0.927 / 0.934     | 0.935 / 0.941    | 0.944 / 0.953         | 0.927 / 0.930     | 0.979 / 0.980   | 0.983 / 0.984|  ----      | ----       |----           | ----       |    ----   |\n",
    "| **Árboles de Decisión max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**   | dfesp_limpio        | ----     | ----    | ----         | ----     | ----   | ----         | 0.520 / 0.700    | 0.567 / 0.907 | 0.941 / 0.901    | 0.753 / 0.953 | 0.941 / 0.902              |\n",
    "| **Árboles de Decisión max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**   | dfphishing_limpio     | 0.922 / 0.927     | 0.932 / 0.937    | 0.972 / 0.975          | 0.896 / 0.903 | 0.978 / 0.977   | 0.977 / 0.975  | ----       |----        |----           |----        |----   |\n",
    "| **Árboles de Decisión max_depth = 5, min_samples_split = 4, min_samples_leaf = 2**   | dfvino_limpio         | 0.821 / 0.742     | 0.836 / 0.761    | 0.846 / 0.740          | 0.826 / 0.783 | 0.892 / 0.777   | 0.886 / 0.798  | ----       |----        |----           |----        |----   |\n",
    "| **Árboles de Decisión max_depth = None, min_samples_split = 10, min_samples_leaf = 3**   | dfcancer_limpio       | 0.991 / 0.930     | 0.988 / 0.907    | 0.982 / 0.907         | 0.994 / 0.907     | 1.000 / 0.935   | 1.000 / 0.870   | ----    |----     |----     |----      |----       |\n",
    "| **Bosques Aleatorios n_estimators = 150, max_depth = 10, min_samples_split = 5**    | dfesp_limpio        | ----     | ----   | ----        | ----     | ----   | ----          | 0.276 / 0.613 | 0.159 / 0.962 | 0.983 / 0.895    | 0.399 / 0.981 | 0.983 / 0.898              |\n",
    "| **Bosques Aleatorios n_estimators = 180, max_depth = 12, min_samples_split = 8**    | dfphishing_limpio     | 0.968 / 0.962     | 0.972 / 0.967   | 0.982 / 0.978      | 0.962 / 0.956     | 0.997 / 0.995   | 0.997 / 0.996    |  ----      |----        |----    |----        |----      |\n",
    "| **Bosques Aleatorios n_estimators = 220, max_depth = None, min_samples_split = 12**    | dfvino_limpio         | 0.946 / 0.786     | 0.951 / 0.806    | 0.960 / 0.803   | 0.942 / 0.810    | 0.992 / 0.870   | 0.993 / 0.901    |  ----      |----        |----           |----        |----     |\n",
    "| **Bosques Aleatorios n_estimators = 150, max_depth = 10, min_samples_split = 6**    | dfcancer_limpio       | 0.998 / 0.947     | 0.997 / 0.929    | 0.994 / 0.907         | 1.000 / 0.951     | 1.000 / 0.991   | 1.000 / 0.986       |  ----      |----        |----           |----        |----  |\n",
    "| **K-Vecinos más Cercanos n_neighbors = 7, weights = 'uniform', metric = 'manhattan**| dfesp_limpio        | ----     | ----   | ----         | ----     | ----   | ----         | 0.718 / 0.903 | 0.827 / 1.418 | 0.913 / 0.845    | 0.909 / 1.191  | 0.915 / 0.847   |\n",
    "| **K-Vecinos más Cercanos n_neighbors = 10, weights = 'distance', metric = 'manhattan'**| dfphishing_limpio     | 0.991 / 0.965     | 0.992 / 0.969    | 0.991 / 0.975    | 0.993 / 0.962     | 1.000 / 0.989   | 1.000 / 0.986       |----        |----        |----           |----        |      ---- |\n",
    "| **K-Vecinos más Cercanos n_neighbors = 15, weights = 'distance', metric = 'euclidean'**| dfvino_limpio         | 1.000 / 0.790     | 1.000 / 0.815    | 1.000 / 0.835    | 1.000 / 0.797     | 1.000 / 0.888   | 1.000 / 0.920   |----        |----    |----    |----  |  ---- |\n",
    "| **K-Vecinos más Cercanos n_neighbors = 15, weights = 'distance', metric = 'euclidean'**| dfcancer_limpio       | 1.000 / 0.947     | 1.000 / 0.925    | 1.000 / 0.860    | 1.000 / 1.000     | 1.000 / 0.994   | 1.000 / 0.991                |----        |----        |----           |----        |    ---- |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><strong>MEJORES RESULTADOS SIN HIPERPARÁMETROS</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| **Algoritmo**                | **Dataset**             | **Exactitud (Accuracy)** | **F1 Score** | **Sensibilidad (Recall)** | **Precisión** | **AUC-ROC** | **Precision-Recall AUC** | **MAE**   | **MSE**   | **R2 Score** | **RMSE**  | **Explained Variance** |\n",
    "|--------------------------|---------------------|-------------------|----------------|---------------------|----------------|-----------|----------------------|-------|-------|----------|-------|--------------------|\n",
    "| **SVM**                   | dfesp_limpio        | ----      | ----    | ----          | ----      | ----    | ----                  | 0.584 / 0.980   | 0.851 / 1.827  | 0.911 / 0.800 | 0.922 / 1.351 | 0.912 / 0.802  |\n",
    "| **Árboles de Decisión**   | dfphishing_limpio   | **0.991 / 0.960**  | **0.992 / 0.964** | **0.991 / 0.964**  | **0.993 / 0.964**  | **1.000 / 0.972**  | **1.000 / 0.966**  | ---- |---- |---- |---- |---- |\n",
    "| **Bosques Aleatorios**    | dfvino_limpio       | **1.000 / 0.769**  | **1.000 / 0.789** | **1.000 / 0.780**  | **1.000 / 0.798**  | **1.000 / 0.886**  | **1.000 / 0.915**  | ---- |---- |---- |---- |---- |\n",
    "| **Bosques Aleatorios**    | dfcancer_limpio     | **1.000 / 0.956**  | **1.000 / 0.940** | **1.000 / 0.907**  | **1.000 / 0.975**  | **1.000 / 0.992**  | **1.000 / 0.988**  | ---- |---- |---- |---- |---- |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **dfesp_limpio → Support Vector Machine (SVM)**\n",
    "#### SVM es adecuado cuando los datos no son perfectamente separables y se necesita encontrar un límite óptimo entre clases. En este caso, que es de regresión nuestro problema a resolver, tenemos las métricas de regresión (MAE, MSE, R² Score) y sugieren que SVM ofrece un buen equilibrio entre error y capacidad de generalización.\n",
    "* **dfphishing_limpio → Árboles de Decisión**\n",
    "#### Este modelo es ideal para datos estructurados con reglas claras de clasificación, como la detección de phishing. Su alto rendimiento en exactitud (99.1%) y F1 Score (99.2%) muestra que puede diferenciar bien entre sitios legítimos y fraudulentos con decisiones basadas en reglas. También ayuda a minimizar los errores que el dataset esté bien normalizado y transformado antes de entrenarlo en el modelo.\n",
    "* **dfvino_limpio → Bosques Aleatorios**\n",
    "#### La clasificación de vinos puede depender de múltiples características con relaciones complejas. Los bosques aleatorios combinan varios árboles de decisión, reduciendo el sobreajuste y mejorando la capacidad predictiva. Su desempeño perfecto en el primer conjunto de datos (100%) confirma su efectividad.\n",
    "* **dfcancer_limpio → Bosques Aleatorios**\n",
    "#### En problemas médicos como la detección de cáncer, es crucial minimizar los errores. Bosques Aleatorios ofrecen alta precisión (100%) y estabilidad, lo que lo hace más confiable que un solo árbol de decisión. La combinación de múltiples árboles ayuda a manejar variaciones en los datos y mejorar la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><strong>MEJORES RESULTADOS CON HIPERPARÁMETROS</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| **Dataset**          | **Mejor Algoritmo** | **Exactitud (Accuracy)** | **F1 Score** | **Sensibilidad (Recall)** | **Precisión** | **AUC-ROC** | **Precision-Recall AUC** | **MAE** | **MSE** | **R2 Score** | **RMSE** | **Explained Variance** |\n",
    "|---------------------|-------------------|-------------------|------------|------------------|------------|----------|------------------|------|------|----------|------|--------------------|\n",
    "| **dfesp_limpio**   | Bosques Aleatorios (n_estimators = 150, max_depth = 10, min_samples_split = 5) | ---- | ---- | ---- | ---- | ---- | ---- | **0.276 / 0.613** | **0.159 / 0.962** | **0.983 / 0.895** | **0.399 / 0.981** | **0.983 / 0.898** |\n",
    "| **dfphishing_limpio** | K-Vecinos más Cercanos (n_neighbors = 10, weights = 'distance', metric = 'manhattan') | **0.991 / 0.965** | **0.992 / 0.969** | **0.991 / 0.975** | **0.993 / 0.962** | **1.000 / 0.989** | **1.000 / 0.986** | ---- | ---- | ---- | ---- | ---- |\n",
    "| **dfvino_limpio** | K-Vecinos más Cercanos (n_neighbors = 15, weights = 'distance', metric = 'euclidean') | **1.000 / 0.790** | **1.000 / 0.815** | **1.000 / 0.835** | **1.000 / 0.797** | **1.000 / 0.888** | **1.000 / 0.920** | ---- | ---- | ---- | ---- | ---- |\n",
    "| **dfcancer_limpio** | K-Vecinos más Cercanos (n_neighbors = 15, weights = 'distance', metric = 'euclidean') | **1.000 / 0.947** | **1.000 / 0.925** | **1.000 / 0.860** | **1.000 / 1.000** | **1.000 / 0.994** | **1.000 / 0.991** | ---- | ---- | ---- | ---- | ---- |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **dfesp_limpio** → Bosques Aleatorios(maneja bien datos con alta dimensionalidad y reduce el sobreajuste) con los Hiperparámetros:\n",
    "* **n_estimators = 150**: Un número equilibrado de árboles mejora la estabilidad sin aumentar demasiado el tiempo de cómputo.\n",
    "* **max_depth = 10**: Se estableció una profundidad intermedia para evitar sobreajuste.\n",
    "* **min_samples_split = 5**: Se aumentó el número de muestras requeridas para dividir un nodo, reduciendo la posibilidad de fragmentación excesiva.\n",
    "\n",
    "#### **dfphishing_limpio** → K-Vecinos más Cercanos (KNN) (es un método efectivo para clasificación basada en proximidad, útil en datos con estructuras claras.) con los Hiperparámetros:\n",
    "* **n_neighbors = 10:** Se encontró que este valor ofrece un balance entre suavidad y precisión.\n",
    "* **weights = 'distance':** Los vecinos más cercanos tienen mayor peso en la decisión, mejorando la clasificación.\n",
    "* **metric = 'manhattan':** Se usa esta métrica ya que se adapta bien a datos con características distintas en escalas variadas.\n",
    "\n",
    "#### **dfvino_limpio** → K-Vecinos más Cercanos (KNN) (mostró mejor desempeño en este conjunto de datos en comparación con otros modelos.) con los Hiperparámetros:\n",
    "* **n_neighbors = 15:** Un valor más alto reduce la variabilidad y mejora la estabilidad de la predicción.\n",
    "* **weights = 'distance':** Se ponderan los vecinos más cercanos, mejorando la precisión.\n",
    "* **metric = 'euclidean':** Se adapta bien a este tipo de datos con múltiples dimensiones homogéneas.\n",
    "\n",
    "#### **dfcancer_limpio** → K-Vecinos más Cercanos (KNN) (mostró alta precisión en la detección de cáncer, lo que es crucial para minimizar errores.) con los Hiperparámetros:\n",
    "* **n_neighbors = 15:** Un mayor número de vecinos mejora la robustez de la clasificación.\n",
    "* **weights = 'distance':** Se da más relevancia a los vecinos más cercanos.\n",
    "* **metric = 'euclidean':** Funciona bien en este conjunto de datos médicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dataset de ejemplo para probar le mejor algoritmo obtenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 10 REGISTROS PARA EL DATASET TEMPERATURA ESPAÑA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos los datos para hacer la prueba del mejor algoritmo y mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>rain_days</th>\n",
       "      <th>rain_accum</th>\n",
       "      <th>avg_wind</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diciembre</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noviembre</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Octubre</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Septiembre</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agosto</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Julio</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Junio</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mayo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abril</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marzo</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Febrero</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Enero</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Murcia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         month  max_temp  min_temp  rain_days  rain_accum  avg_wind   place\n",
       "0    Diciembre      15.0       6.0          4        23.0        10  Murcia\n",
       "1    Noviembre      19.0       9.0          5        27.0        10  Murcia\n",
       "2      Octubre      24.0      14.0          5        27.0         8  Murcia\n",
       "3   Septiembre      29.0      17.0          3        15.0         8  Murcia\n",
       "4       Agosto      32.0      19.0          1         3.0         9  Murcia\n",
       "5        Julio      35.0      20.0          0         0.0        10  Murcia\n",
       "6        Junio      30.0      18.0          2        10.0        10  Murcia\n",
       "7         Mayo      25.0      15.0          4        20.0         9  Murcia\n",
       "8        Abril      20.0      10.0          6        30.0         7  Murcia\n",
       "9        Marzo      18.0       8.0          7        35.0         8  Murcia\n",
       "10     Febrero      16.0       7.0          5        28.0         9  Murcia\n",
       "11       Enero      14.0       5.0          8        40.0         6  Murcia"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datos de los meses\n",
    "data = [\n",
    "    [\"Diciembre\", 15.0, 6.0, 4, 23.0, 10, \"Murcia\"],\n",
    "    [\"Noviembre\", 19.0, 9.0, 5, 27.0, 10, \"Murcia\"],\n",
    "    [\"Octubre\", 24.0, 14.0, 5, 27.0, 8, \"Murcia\"],\n",
    "    [\"Septiembre\", 29.0, 17.0, 3, 15.0, 8, \"Murcia\"],\n",
    "    [\"Agosto\", 32.0, 19.0, 1, 3.0, 9, \"Murcia\"],\n",
    "    [\"Julio\", 35.0, 20.0, 0, 0.0, 10, \"Murcia\"],\n",
    "    [\"Junio\", 30.0, 18.0, 2, 10.0, 10, \"Murcia\"],\n",
    "    [\"Mayo\", 25.0, 15.0, 4, 20.0, 9, \"Murcia\"],\n",
    "    [\"Abril\", 20.0, 10.0, 6, 30.0, 7, \"Murcia\"],\n",
    "    [\"Marzo\", 18.0, 8.0, 7, 35.0, 8, \"Murcia\"],\n",
    "    [\"Febrero\", 16.0, 7.0, 5, 28.0, 9, \"Murcia\"],\n",
    "    [\"Enero\", 14.0, 5.0, 8, 40.0, 6, \"Murcia\"]\n",
    "]\n",
    "\n",
    "# Definición de las columnas\n",
    "columns = [\"month\", \"max_temp\", \"min_temp\", \"rain_days\", \"rain_accum\", \"avg_wind\", \"place\"]\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_esp_10 = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "display(df_esp_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos igual que la de los datos originales: \n",
    "#### dejamos los datos como los tenemos en las pruebas de arriba, con las mismas técnicas para estos 12 registros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encoding: one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_Agosto</th>\n",
       "      <th>month_Diciembre</th>\n",
       "      <th>month_Enero</th>\n",
       "      <th>month_Febrero</th>\n",
       "      <th>month_Julio</th>\n",
       "      <th>month_Junio</th>\n",
       "      <th>month_Marzo</th>\n",
       "      <th>month_Mayo</th>\n",
       "      <th>month_Noviembre</th>\n",
       "      <th>month_Octubre</th>\n",
       "      <th>month_Septiembre</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>rain_days</th>\n",
       "      <th>rain_accum</th>\n",
       "      <th>avg_wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_Agosto  month_Diciembre  month_Enero  month_Febrero  month_Julio  \\\n",
       "0           0.0              1.0          0.0            0.0          0.0   \n",
       "1           0.0              0.0          0.0            0.0          0.0   \n",
       "2           0.0              0.0          0.0            0.0          0.0   \n",
       "3           0.0              0.0          0.0            0.0          0.0   \n",
       "4           1.0              0.0          0.0            0.0          0.0   \n",
       "\n",
       "   month_Junio  month_Marzo  month_Mayo  month_Noviembre  month_Octubre  \\\n",
       "0          0.0          0.0         0.0              0.0            0.0   \n",
       "1          0.0          0.0         0.0              1.0            0.0   \n",
       "2          0.0          0.0         0.0              0.0            1.0   \n",
       "3          0.0          0.0         0.0              0.0            0.0   \n",
       "4          0.0          0.0         0.0              0.0            0.0   \n",
       "\n",
       "   month_Septiembre  max_temp  min_temp  rain_days  rain_accum  avg_wind  \n",
       "0               0.0      15.0       6.0          4        23.0        10  \n",
       "1               0.0      19.0       9.0          5        27.0        10  \n",
       "2               0.0      24.0      14.0          5        27.0         8  \n",
       "3               1.0      29.0      17.0          3        15.0         8  \n",
       "4               0.0      32.0      19.0          1         3.0         9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas antes del One-Hot Encoding: 7\n",
      "Número de columnas después del One-Hot Encoding: 16\n"
     ]
    }
   ],
   "source": [
    "# Crear una copia del DataFrame original para no modificar el original\n",
    "dfesp_onehot_10 = df_esp_10.copy()\n",
    "\n",
    "# Filtrar las columnas categóricas\n",
    "columnas_categoricas_temp = [\"month\", \"place\"]\n",
    "\n",
    "# Instancia de OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Aplicar One-Hot Encoding a las columnas seleccionadas\n",
    "columnas_encoded_temp = one_hot_encoder.fit_transform(dfesp_onehot_10[columnas_categoricas_temp])\n",
    "\n",
    "# Convertir el resultado a un DataFrame\n",
    "columnas_encoded_df_temp = pd.DataFrame(columnas_encoded_temp, columns=one_hot_encoder.get_feature_names_out(columnas_categoricas_temp))\n",
    "\n",
    "# Ahora concatenamos las columnas numéricas (las que no son categóricas) al DataFrame resultante\n",
    "columnas_numéricas = dfesp_onehot_10.drop(columns=columnas_categoricas_temp)\n",
    "columnas_encoded_df_temp2 = pd.concat([columnas_encoded_df_temp, columnas_numéricas], axis=1)\n",
    "\n",
    "# Mostrar el resultado\n",
    "display(columnas_encoded_df_temp2.head())\n",
    "\n",
    "# Número de columnas antes y después del One-Hot Encoding\n",
    "print(\"Número de columnas antes del One-Hot Encoding:\", dfesp_onehot_10.shape[1])\n",
    "print(\"Número de columnas después del One-Hot Encoding:\", columnas_encoded_df_temp2.shape[1])\n",
    "#columnas_encoded_df_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_Agosto</th>\n",
       "      <th>month_Diciembre</th>\n",
       "      <th>month_Enero</th>\n",
       "      <th>month_Febrero</th>\n",
       "      <th>month_Julio</th>\n",
       "      <th>month_Junio</th>\n",
       "      <th>month_Marzo</th>\n",
       "      <th>month_Mayo</th>\n",
       "      <th>month_Noviembre</th>\n",
       "      <th>month_Octubre</th>\n",
       "      <th>month_Septiembre</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>rain_accum</th>\n",
       "      <th>avg_wind</th>\n",
       "      <th>rain_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.575</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.675</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month_Agosto  month_Diciembre  month_Enero  month_Febrero  month_Julio  \\\n",
       "0            0.0              1.0          0.0            0.0          0.0   \n",
       "1            0.0              0.0          0.0            0.0          0.0   \n",
       "2            0.0              0.0          0.0            0.0          0.0   \n",
       "3            0.0              0.0          0.0            0.0          0.0   \n",
       "4            1.0              0.0          0.0            0.0          0.0   \n",
       "5            0.0              0.0          0.0            0.0          1.0   \n",
       "6            0.0              0.0          0.0            0.0          0.0   \n",
       "7            0.0              0.0          0.0            0.0          0.0   \n",
       "8            0.0              0.0          0.0            0.0          0.0   \n",
       "9            0.0              0.0          0.0            0.0          0.0   \n",
       "10           0.0              0.0          0.0            1.0          0.0   \n",
       "11           0.0              0.0          1.0            0.0          0.0   \n",
       "\n",
       "    month_Junio  month_Marzo  month_Mayo  month_Noviembre  month_Octubre  \\\n",
       "0           0.0          0.0         0.0              0.0            0.0   \n",
       "1           0.0          0.0         0.0              1.0            0.0   \n",
       "2           0.0          0.0         0.0              0.0            1.0   \n",
       "3           0.0          0.0         0.0              0.0            0.0   \n",
       "4           0.0          0.0         0.0              0.0            0.0   \n",
       "5           0.0          0.0         0.0              0.0            0.0   \n",
       "6           1.0          0.0         0.0              0.0            0.0   \n",
       "7           0.0          0.0         1.0              0.0            0.0   \n",
       "8           0.0          0.0         0.0              0.0            0.0   \n",
       "9           0.0          1.0         0.0              0.0            0.0   \n",
       "10          0.0          0.0         0.0              0.0            0.0   \n",
       "11          0.0          0.0         0.0              0.0            0.0   \n",
       "\n",
       "    month_Septiembre  max_temp  min_temp  rain_accum  avg_wind  rain_days  \n",
       "0                0.0  0.047619  0.066667       0.575      1.00          4  \n",
       "1                0.0  0.238095  0.266667       0.675      1.00          5  \n",
       "2                0.0  0.476190  0.600000       0.675      0.50          5  \n",
       "3                1.0  0.714286  0.800000       0.375      0.50          3  \n",
       "4                0.0  0.857143  0.933333       0.075      0.75          1  \n",
       "5                0.0  1.000000  1.000000       0.000      1.00          0  \n",
       "6                0.0  0.761905  0.866667       0.250      1.00          2  \n",
       "7                0.0  0.523810  0.666667       0.500      0.75          4  \n",
       "8                0.0  0.285714  0.333333       0.750      0.25          6  \n",
       "9                0.0  0.190476  0.200000       0.875      0.50          7  \n",
       "10               0.0  0.095238  0.133333       0.700      0.75          5  \n",
       "11               0.0  0.000000  0.000000       1.000      0.00          8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copia del dataframe para aplicar la normalización\n",
    "df_esplimpio_10 = columnas_encoded_df_temp2.copy()\n",
    "\n",
    "# Lista de las columnas numéricas para las que haremos la normalización\n",
    "columnas_numericas = df_esplimpio_10 .select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Excluimos la columna objetivo (quality)\n",
    "columnas_numericas = columnas_numericas.drop('rain_days')\n",
    "\n",
    "# Aplicamos MinMaxScaler de sklearn para normalizar las columnas numéricas\n",
    "min_max = MinMaxScaler()\n",
    "\n",
    "# Aplicamos el ajuste y la transformación a las columnas numéricas\n",
    "dfesp_limpio_10 = pd.DataFrame(min_max.fit_transform(df_esplimpio_10[columnas_numericas]), columns=columnas_numericas)\n",
    "\n",
    "# Copiamos la columna \"quality\" (sin normalizar) a la tabla final\n",
    "dfesp_limpio_10['rain_days'] = df_esplimpio_10['rain_days']\n",
    "\n",
    "display(dfesp_limpio_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Probamos el mejor modelo: Bosques Aleatorios (n_estimators = 150, max_depth = 10, min_samples_split = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEJORES RESULTADOS PARA EL DATASET ENTERO\n",
      "n_estimators = 150, max_depth = 10, min_samples_split = 5\n",
      "Bosques Aleatorios : MAE en los datos de entrenamiento: 0.276\n",
      "Bosques Aleatorios : MAE en los datos de testeo: 0.613\n",
      "\n",
      "Bosques Aleatorios : MSE en los datos de entrenamiento: 0.159\n",
      "Bosques Aleatorios : MSE en los datos de testeo: 0.962\n",
      "\n",
      "Bosques Aleatorios : R2 Score en los datos de entrenamiento: 0.983\n",
      "Bosques Aleatorios : R2 Score en los datos de testeo: 0.895\n",
      "\n",
      "Bosques Aleatorios : RMSE en los datos de entrenamiento: 0.399\n",
      "Bosques Aleatorios : RMSE en los datos de testeo: 0.981\n",
      "\n",
      "Bosques Aleatorios : Explained Variance en los datos de entrenamiento: 0.983\n",
      "Bosques Aleatorios : Explained Variance en los datos de testeo: 0.898\n",
      "\n",
      "---------------------------------------------------------\n",
      "SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\n",
      "n_estimators = 150, max_depth = 10, min_samples_split = 5\n",
      "Bosques Aleatorios : MAE en los datos de entrenamiento: 0.730\n",
      "Bosques Aleatorios : MAE en los datos de testeo: 1.083\n",
      "\n",
      "Bosques Aleatorios : MSE en los datos de entrenamiento: 1.105\n",
      "Bosques Aleatorios : MSE en los datos de testeo: 1.416\n",
      "\n",
      "Bosques Aleatorios : R2 Score en los datos de entrenamiento: 0.807\n",
      "Bosques Aleatorios : R2 Score en los datos de testeo: 0.090\n",
      "\n",
      "Bosques Aleatorios : RMSE en los datos de entrenamiento: 1.051\n",
      "Bosques Aleatorios : RMSE en los datos de testeo: 1.190\n",
      "\n",
      "Bosques Aleatorios : Explained Variance en los datos de entrenamiento: 0.807\n",
      "Bosques Aleatorios : Explained Variance en los datos de testeo: 0.090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MEJORES RESULTADOS PARA EL DATASET ENTERO\")\n",
    "print(\"n_estimators = 150, max_depth = 10, min_samples_split = 5\")\n",
    "Bosques_hiper_espmejor = aplicar_random_forest_hiper(dfesp_limpio, 'rain_days', tipo_modelo='regresion', n_estimators=150, max_depth=10, min_samples_split=5)\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\")\n",
    "print(\"n_estimators = 150, max_depth = 10, min_samples_split = 5\")\n",
    "Bosques_hiper_esp10 = aplicar_random_forest_hiper(dfesp_limpio_10, 'rain_days', tipo_modelo='regresion', n_estimators=150, max_depth=10, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                       | **Dataset Entero (Entrenamiento / Testeo)** | **10 Nuevos Registros (Entrenamiento / Testeo)** |\n",
    "|------------------------------------|--------------------------------------------|-------------------------------------------------|\n",
    "| **MAE**                            | 0.276 / 0.613                              | 0.730 / 1.083                                   |\n",
    "| **MSE**                            | 0.159 / 0.962                              | 1.105 / 1.416                                   |\n",
    "| **R2 Score**                       | 0.983 / 0.895                              | 0.807 / 0.090                                   |\n",
    "| **RMSE**                           | 0.399 / 0.981                              | 1.051 / 1.190                                   |\n",
    "| **Explained Variance**             | 0.983 / 0.898                              | 0.807 / 0.090                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusuiones:\n",
    "* **MAE:** Vemos que se tienen mas errores en el dataframe con los 10 Nuevos Registros esto se debe a que los 10 registros son más difíciles de predecir que como lo haría para el conjunto de datos entero.\n",
    "* **MSE**  De la misma manera, para el dataset entero es mas bajo, por lo que este dataframe nuevo será menos preciso, no se ajustan bien al modelo entrenado con todos los datos.\n",
    "* **R2 Score** Para los 10 nuevos registros, el R2 en testeo es muy bajo lo que indica que el modelo tiene un muy mal desempeño al hacer prediucciones para estos registros específicos.\n",
    "* **RMSE** Igual que con el MSE, esta métrica penaliza más los errores grandes, lo que indica que este nuevo conjunto, está cometiendo errores más grandes al hacer predicciones.\n",
    "* **Explained Variance** Esta gráfica explicaba la capacidad del modelo en captar la variabilidad de los datos, también tendremos ese problema en el testeo, no está explicando bien la variabilidad en estos nuevos registros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 10 REGISTROS PARA EL DATASET PHISHING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos los datos para hacer la prueba del mejor algoritmo y mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>UsingIP</th>\n",
       "      <th>LongURL</th>\n",
       "      <th>ShortURL</th>\n",
       "      <th>Symbol@</th>\n",
       "      <th>Redirecting//</th>\n",
       "      <th>PrefixSuffix-</th>\n",
       "      <th>SubDomains</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DomainRegLen</th>\n",
       "      <th>...</th>\n",
       "      <th>UsingPopupWindow</th>\n",
       "      <th>IframeRedirection</th>\n",
       "      <th>AgeofDomain</th>\n",
       "      <th>DNSRecording</th>\n",
       "      <th>WebsiteTraffic</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>GoogleIndex</th>\n",
       "      <th>LinksPointingToPage</th>\n",
       "      <th>StatsReport</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  UsingIP  LongURL  ShortURL  Symbol@  Redirecting//  PrefixSuffix-  \\\n",
       "0      0        1        1         1        1              1             -1   \n",
       "1      1       -1        0         1        1              1             -1   \n",
       "2      2        1        0        -1        1              1             -1   \n",
       "3      3       -1        0        -1        1             -1             -1   \n",
       "4      4        1        0         1        1              1             -1   \n",
       "5      5       -1        0        -1        1              1             -1   \n",
       "6      6        1        1         1        1             -1              1   \n",
       "7      7       -1       -1         1        1              1             -1   \n",
       "8      8        1        1         1        1              1             -1   \n",
       "9      9       -1        0        -1        1              1             -1   \n",
       "\n",
       "   SubDomains  HTTPS  DomainRegLen  ...  UsingPopupWindow  IframeRedirection  \\\n",
       "0           0      1            -1  ...                 1                  1   \n",
       "1          -1     -1            -1  ...                 1                  1   \n",
       "2           1      1            -1  ...                -1                  1   \n",
       "3           1      1            -1  ...                 1                  1   \n",
       "4          -1     -1             1  ...                 1                  1   \n",
       "5           1      1            -1  ...                 1                  1   \n",
       "6           1     -1            -1  ...                 1                  1   \n",
       "7           1     -1             1  ...                 1                  1   \n",
       "8           0      1            -1  ...                 1                  1   \n",
       "9          -1     -1             1  ...                 1                  1   \n",
       "\n",
       "   AgeofDomain  DNSRecording  WebsiteTraffic  PageRank  GoogleIndex  \\\n",
       "0           -1            -1               0        -1            1   \n",
       "1            1            -1               1        -1            1   \n",
       "2           -1            -1               0        -1            1   \n",
       "3            1             1              -1         1           -1   \n",
       "4           -1            -1               0        -1            1   \n",
       "5            1            -1              -1        -1            1   \n",
       "6           -1             1               0        -1            1   \n",
       "7           -1            -1               1         1           -1   \n",
       "8            1            -1               0        -1            1   \n",
       "9           -1             1              -1         1            1   \n",
       "\n",
       "   LinksPointingToPage  StatsReport  class  \n",
       "0                    1            1      1  \n",
       "1                    0           -1     -1  \n",
       "2                    1            1     -1  \n",
       "3                    1           -1     -1  \n",
       "4                    0            1      1  \n",
       "5                    1           -1     -1  \n",
       "6                    0           -1      1  \n",
       "7                    1            1     -1  \n",
       "8                    0            1      1  \n",
       "9                   -1           -1     -1  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir las columnas basadas en el dataset original\n",
    "columns = [\n",
    "    \"Index\", \"UsingIP\", \"LongURL\", \"ShortURL\", \"Symbol@\", \"Redirecting//\", \"PrefixSuffix-\", \"SubDomains\",\n",
    "    \"HTTPS\", \"DomainRegLen\", \"Favicon\", \"NonStdPort\", \"HTTPSDomainURL\", \"RequestURL\", \"AnchorURL\",\n",
    "    \"LinksInScriptTags\", \"ServerFormHandler\", \"InfoEmail\", \"AbnormalURL\", \"WebsiteForwarding\", \"StatusBarCust\",\n",
    "    \"DisableRightClick\", \"UsingPopupWindow\", \"IframeRedirection\", \"AgeofDomain\", \"DNSRecording\",\n",
    "    \"WebsiteTraffic\", \"PageRank\", \"GoogleIndex\", \"LinksPointingToPage\", \"StatsReport\", \"class\"\n",
    "]\n",
    "\n",
    "# Datos predefinidos\n",
    "fixed_data = [\n",
    "    [0, 1, 1, 1, 1, 1, -1, 0, 1, -1, 1, 1, -1, 1, 0, -1, -1, 1, 1, 0, 1, 1, 1, 1, -1, -1, 0, -1, 1, 1, 1, 1],\n",
    "    [1, -1, 0, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 0, -1, -1, -1, -1, 0, 1, 1, 1, 1, 1, -1, 1, -1, 1, 0, -1, -1],\n",
    "    [2, 1, 0, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 0, 0, -1, 1, 1, 0, -1, 1, -1, 1, -1, -1, 0, -1, 1, 1, 1, -1],\n",
    "    [3, -1, 0, -1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 0, 0, -1, -1, -1, 0, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1],\n",
    "    [4, 1, 0, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 0, -1, -1, 1, 1, 0, 1, 1, 1, 1, -1, -1, 0, -1, 1, 0, 1, 1],\n",
    "    [5, -1, 0, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 0, -1, -1, -1, -1, 0, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1],\n",
    "    [6, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 0, -1, -1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 0, -1, 1, 0, -1, 1],\n",
    "    [7, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 0, -1, -1, -1, -1, 0, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1],\n",
    "    [8, 1, 1, 1, 1, 1, -1, 0, 1, -1, 1, 1, 1, -1, 0, 0, -1, -1, -1, 0, 1, 1, 1, 1, 1, -1, 0, -1, 1, 0, 1, 1],\n",
    "    [9, -1, 0, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 0, -1, -1, -1, 1, 0, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1]\n",
    "]\n",
    "\n",
    "# Crear DataFrame\n",
    "df_phishing_10 = pd.DataFrame(fixed_data, columns=columns)\n",
    "\n",
    "# Mostrar resultado\n",
    "display(df_phishing_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borramos la columna Index\n",
    "df_phishing_10 = df_phishing_10.drop(['Index'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Probamos el mejor modelo (n_neighbors = 10, weights = 'distance', metric = 'manhattan'): (COMENTADO PORQUE DA ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\n",
      "MEJORES RESULTADOS PARA EL DATASET ENTERO\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.991\n",
      "KNN : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.992\n",
      "KNN : F1 Score en los datos de testeo: 0.969\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.991\n",
      "KNN : Sensibilidad en los datos de testeo: 0.975\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.993\n",
      "KNN : Precisión en los datos de testeo: 0.962\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.989\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------\")\n",
    "print(\"SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\")\n",
    "#KVecinos_hiper_10 = aplicar_knn_hiper(df_phishing_10, 'class', tipo_modelo='clasificacion', n_neighbors=10, weights='distance', metric='manhattan')\n",
    "print(\"MEJORES RESULTADOS PARA EL DATASET ENTERO\")\n",
    "KVecinos_hiper_2_ = aplicar_knn_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_neighbors=10, weights='distance', metric='manhattan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO podemos aplicar (df_phishing_10, 'class', tipo_modelo='clasificacion', n_neighbors=10, weights='distance', metric='manhattan') a nuestros 10 registros, porque:\n",
    "* **n_neighbors=10** : y solo hay 10 registros en el dataset, puede que algunos puntos no tengan suficientes vecinos para calcular correctamente las distancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vamos a bajar este núemero de vecinos a la mitad para poder aplicar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\n",
      "KNN : Exactitud en los datos de entrenamiento: 1.000\n",
      "KNN : Exactitud en los datos de testeo: 1.000\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 1.000\n",
      "KNN : F1 Score en los datos de testeo: 1.000\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "KNN : Sensibilidad en los datos de testeo: 1.000\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 1.000\n",
      "KNN : Precisión en los datos de testeo: 1.000\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 1.000\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 1.000\n",
      "\n",
      "MEJORES RESULTADOS PARA EL DATASET ENTERO\n",
      "KNN : Exactitud en los datos de entrenamiento: 0.991\n",
      "KNN : Exactitud en los datos de testeo: 0.965\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 0.992\n",
      "KNN : F1 Score en los datos de testeo: 0.969\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 0.991\n",
      "KNN : Sensibilidad en los datos de testeo: 0.975\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 0.993\n",
      "KNN : Precisión en los datos de testeo: 0.962\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.989\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------\")\n",
    "print(\"SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\")\n",
    "KVecinos_hiper_10 = aplicar_knn_hiper(df_phishing_10, 'class', tipo_modelo='clasificacion', n_neighbors=5, weights='distance', metric='manhattan')\n",
    "print(\"MEJORES RESULTADOS PARA EL DATASET ENTERO\")\n",
    "KVecinos_hiper_2_ = aplicar_knn_hiper(dfphishing_limpio, 'class', tipo_modelo='clasificacion', n_neighbors=10, weights='distance', metric='manhattan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                        | **Dataset Entero (Entrenamiento / Testeo)** | **10 Nuevos Registros (Entrenamiento / Testeo)** |\n",
    "|------------------------------------|--------------------------------------------|-------------------------------------------------|\n",
    "| **Exactitud**                      | 0.991 / 0.965                              | 1.000 / 1.000                                   |\n",
    "| **F1 Score**                       | 0.992 / 0.969                              | 1.000 / 1.000                                   |\n",
    "| **Sensibilidad**                   | 0.991 / 0.975                              | 1.000 / 1.000                                   |\n",
    "| **Precisión**                      | 0.993 / 0.962                              | 1.000 / 1.000                                   |\n",
    "| **AUC-ROC**                        | 1.000 / 0.989                              | 1.000 / 1.000                                   |\n",
    "| **Precision-Recall AUC**           | 1.000 / 0.986                              | 1.000 / 1.000                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones:\n",
    "el modelo obtiene métricas perfectas (1.000) en los 10 registros puede deberse a que el conjunto de datos es pequeño y posiblemente sencillo de clasificar. Sin embargo, en el dataset completo, la ligera disminución en las métricas de testeo sugiere que el modelo se enfrenta a más variabilidad y complejidad en los datos reales. Esto indica que evaluar modelos solo con conjuntos pequeños puede dar una falsa sensación de perfección, mientras que el rendimiento real se mide mejor en datasets más amplios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 10 REGISTROS PARA EL DATASET VINO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos los datos para hacer la prueba del mejor algoritmo y mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25</td>\n",
       "      <td>67</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.084</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.092</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.065</td>\n",
       "      <td>23</td>\n",
       "      <td>89</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.79</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.074</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.65</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.078</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>20</td>\n",
       "      <td>85</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.82</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.061</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.80</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.5              0.50         0.36             2.0      0.084   \n",
       "3            6.9              0.76         0.02             1.8      0.075   \n",
       "4            8.0              0.65         0.00             2.4      0.092   \n",
       "5            7.1              0.42         0.24             1.9      0.065   \n",
       "6            6.8              0.38         0.29             2.3      0.074   \n",
       "7            7.0              0.40         0.32             2.1      0.078   \n",
       "8            7.2              0.36         0.45             2.0      0.062   \n",
       "9            6.5              0.34         0.40             2.2      0.061   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                   11                    34   0.9978  3.51       0.56   \n",
       "1                   25                    67   0.9968  3.20       0.68   \n",
       "2                    5                    25   0.9970  3.40       0.50   \n",
       "3                   14                    37   0.9966  3.52       0.54   \n",
       "4                   18                    45   0.9972  3.22       0.62   \n",
       "5                   23                    89   0.9959  3.35       0.79   \n",
       "6                   17                    40   0.9957  3.45       0.65   \n",
       "7                   30                    99   0.9958  3.50       0.75   \n",
       "8                   20                    85   0.9955  3.48       0.82   \n",
       "9                   21                    80   0.9953  3.51       0.80   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        0  \n",
       "1      9.8        0  \n",
       "2      9.2        0  \n",
       "3      9.5        0  \n",
       "4      9.7        0  \n",
       "5     10.5        1  \n",
       "6     11.3        1  \n",
       "7     12.1        1  \n",
       "8     12.5        1  \n",
       "9     13.0        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir las columnas\n",
    "columns = [\n",
    "    \"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\",\n",
    "    \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\",\n",
    "    \"alcohol\", \"quality\"\n",
    "]\n",
    "\n",
    "# Datos predefinidos con 5 vinos de calidad 0 y 5 de calidad 1\n",
    "vino_data = [\n",
    "    [7.4, 0.70, 0.00, 1.9, 0.076, 11, 34, 0.9978, 3.51, 0.56, 9.4, 0],  \n",
    "    [7.8, 0.88, 0.00, 2.6, 0.098, 25, 67, 0.9968, 3.20, 0.68, 9.8, 0],  \n",
    "    [7.5, 0.50, 0.36, 2.0, 0.084, 5, 25, 0.9970, 3.40, 0.50, 9.2, 0],  \n",
    "    [6.9, 0.76, 0.02, 1.8, 0.075, 14, 37, 0.9966, 3.52, 0.54, 9.5, 0],  \n",
    "    [8.0, 0.65, 0.00, 2.4, 0.092, 18, 45, 0.9972, 3.22, 0.62, 9.7, 0],  \n",
    "    [7.1, 0.42, 0.24, 1.9, 0.065, 23, 89, 0.9959, 3.35, 0.79, 10.5, 1],  \n",
    "    [6.8, 0.38, 0.29, 2.3, 0.074, 17, 40, 0.9957, 3.45, 0.65, 11.3, 1],  \n",
    "    [7.0, 0.40, 0.32, 2.1, 0.078, 30, 99, 0.9958, 3.50, 0.75, 12.1, 1],  \n",
    "    [7.2, 0.36, 0.45, 2.0, 0.062, 20, 85, 0.9955, 3.48, 0.82, 12.5, 1],  \n",
    "    [6.5, 0.34, 0.40, 2.2, 0.061, 21, 80, 0.9953, 3.51, 0.80, 13.0, 1]  \n",
    "]\n",
    "\n",
    "# Crear DataFrame\n",
    "df_vino_10 = pd.DataFrame(vino_data, columns=columns)\n",
    "\n",
    "# Mostrar resultado\n",
    "display(df_vino_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a escalar las variables categoricas usando StandardScaler porque las características, como la acidez o alcohol, tienen rangos diferentes. Estandarizarlas asegura que los algoritmos como SVM o kNN no se vean afectados por estas diferencias y aprendan de manera más efectiva. Además, es más robusto frente a valores atípicos que la normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.411220</td>\n",
       "      <td>0.879256</td>\n",
       "      <td>-1.193040</td>\n",
       "      <td>-0.916667</td>\n",
       "      <td>-0.042993</td>\n",
       "      <td>-1.085889</td>\n",
       "      <td>-1.024444</td>\n",
       "      <td>1.819435</td>\n",
       "      <td>0.840554</td>\n",
       "      <td>-1.008716</td>\n",
       "      <td>-0.966817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.325044</td>\n",
       "      <td>1.862276</td>\n",
       "      <td>-1.193040</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.848714</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>0.270830</td>\n",
       "      <td>0.555939</td>\n",
       "      <td>-1.873736</td>\n",
       "      <td>0.081788</td>\n",
       "      <td>-0.669335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.639676</td>\n",
       "      <td>-0.212988</td>\n",
       "      <td>0.871837</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.644900</td>\n",
       "      <td>-1.966340</td>\n",
       "      <td>-1.377700</td>\n",
       "      <td>0.808638</td>\n",
       "      <td>-0.122581</td>\n",
       "      <td>-1.553968</td>\n",
       "      <td>-1.115558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.731059</td>\n",
       "      <td>1.206930</td>\n",
       "      <td>-1.078325</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.645664</td>\n",
       "      <td>-0.906691</td>\n",
       "      <td>0.303239</td>\n",
       "      <td>0.928112</td>\n",
       "      <td>-1.190466</td>\n",
       "      <td>-0.892446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.781955</td>\n",
       "      <td>0.606195</td>\n",
       "      <td>-1.193040</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.332794</td>\n",
       "      <td>-0.058697</td>\n",
       "      <td>-0.592686</td>\n",
       "      <td>1.061337</td>\n",
       "      <td>-1.698620</td>\n",
       "      <td>-0.463464</td>\n",
       "      <td>-0.743705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       0.411220          0.879256    -1.193040       -0.916667  -0.042993   \n",
       "1       1.325044          1.862276    -1.193040        2.000000   1.848714   \n",
       "2       0.639676         -0.212988     0.871837       -0.500000   0.644900   \n",
       "3      -0.731059          1.206930    -1.078325       -1.333333  -0.128980   \n",
       "4       1.781955          0.606195    -1.193040        1.166667   1.332794   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0            -1.085889             -1.024444  1.819435  0.840554  -1.008716   \n",
       "1             0.968496              0.270830  0.555939 -1.873736   0.081788   \n",
       "2            -1.966340             -1.377700  0.808638 -0.122581  -1.553968   \n",
       "3            -0.645664             -0.906691  0.303239  0.928112  -1.190466   \n",
       "4            -0.058697             -0.592686  1.061337 -1.698620  -0.463464   \n",
       "\n",
       "    alcohol  quality  \n",
       "0 -0.966817        0  \n",
       "1 -0.669335        0  \n",
       "2 -1.115558        0  \n",
       "3 -0.892446        0  \n",
       "4 -0.743705        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el objeto escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copiamos el dataframe para no modificar el original\n",
    "df_vino_10_limpio = df_vino_10.copy()\n",
    "\n",
    "# Estandarizar las columnas numéricas (exceptuando 'quality')\n",
    "dfvino_limpio_10 = df_vino_10.drop(columns=['quality'])\n",
    "dfvino_limpio_10 = scaler.fit_transform(dfvino_limpio_10)\n",
    "\n",
    "# Convertir de nuevo a un DataFrame\n",
    "dfvino_limpio_10 = pd.DataFrame(dfvino_limpio_10, columns=df_vino_10.drop(columns=['quality']).columns)\n",
    "\n",
    "# Incluir 'quality' nuevamente al dataframe\n",
    "dfvino_limpio_10['quality'] = df_vino_10['quality']\n",
    "display(dfvino_limpio_10.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Probamos el mejor modelo (n_neighbors = 15, weights = 'distance', metric = 'euclidean')\n",
    "#### Como ya lo sabemos del apartado anterior, no podemos probar este modelo para nuestros 10 registros, por los n_neighbors = 15, por lo que lo probaremos con la mitad --> 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\n",
      "KNN : Exactitud en los datos de entrenamiento: 1.000\n",
      "KNN : Exactitud en los datos de testeo: 1.000\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 1.000\n",
      "KNN : F1 Score en los datos de testeo: 1.000\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "KNN : Sensibilidad en los datos de testeo: 1.000\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 1.000\n",
      "KNN : Precisión en los datos de testeo: 1.000\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 1.000\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 1.000\n",
      "\n",
      "MEJORES RESULTADOS PARA EL DATASET ENTERO\n",
      "KNN : Exactitud en los datos de entrenamiento: 1.000\n",
      "KNN : Exactitud en los datos de testeo: 0.764\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 1.000\n",
      "KNN : F1 Score en los datos de testeo: 0.792\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "KNN : Sensibilidad en los datos de testeo: 0.811\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 1.000\n",
      "KNN : Precisión en los datos de testeo: 0.774\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.872\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------\")\n",
    "print(\"SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\")\n",
    "KVecinos_hiper_10 = aplicar_knn_hiper(dfvino_limpio_10, 'quality', tipo_modelo='clasificacion', n_neighbors=7, weights='distance', metric='manhattan')\n",
    "print(\"MEJORES RESULTADOS PARA EL DATASET ENTERO\")\n",
    "KVecinos_hiper_2_ = aplicar_knn_hiper(dfvino_limpio, 'quality', tipo_modelo='clasificacion', n_neighbors=10, weights='distance', metric='manhattan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conclusiones:\n",
    "#### Tenemos el mismo problema, obtenemos 1.000 en todas las métricas, esto se debe a que este algoritmo no es real para conjunto de datos pequeños, porque el algoritmo k-NN tiende a sobreajustarse con conjuntos de datos pequeños, lo que significa que memoriza muy bien los puntos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 10 REGISTROS PARA EL DATASET CANCER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos el dataset con los 10 registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x.radius_mean</th>\n",
       "      <th>x.texture_mean</th>\n",
       "      <th>x.perimeter_mean</th>\n",
       "      <th>x.area_mean</th>\n",
       "      <th>x.smoothness_mean</th>\n",
       "      <th>x.compactness_mean</th>\n",
       "      <th>x.concavity_mean</th>\n",
       "      <th>x.concave_pts_mean</th>\n",
       "      <th>x.symmetry_mean</th>\n",
       "      <th>x.fractal_dim_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>x.texture_worst</th>\n",
       "      <th>x.perimeter_worst</th>\n",
       "      <th>x.area_worst</th>\n",
       "      <th>x.smoothness_worst</th>\n",
       "      <th>x.compactness_worst</th>\n",
       "      <th>x.concavity_worst</th>\n",
       "      <th>x.concave_pts_worst</th>\n",
       "      <th>x.symmetry_worst</th>\n",
       "      <th>x.fractal_dim_worst</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.130198</td>\n",
       "      <td>24.737195</td>\n",
       "      <td>88.810329</td>\n",
       "      <td>1247.634985</td>\n",
       "      <td>0.051448</td>\n",
       "      <td>0.162705</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.058143</td>\n",
       "      <td>0.212523</td>\n",
       "      <td>0.062168</td>\n",
       "      <td>...</td>\n",
       "      <td>24.585597</td>\n",
       "      <td>105.048960</td>\n",
       "      <td>2987.848210</td>\n",
       "      <td>0.201296</td>\n",
       "      <td>0.418472</td>\n",
       "      <td>0.843002</td>\n",
       "      <td>0.167773</td>\n",
       "      <td>0.529615</td>\n",
       "      <td>0.064025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.789122</td>\n",
       "      <td>17.665263</td>\n",
       "      <td>126.559937</td>\n",
       "      <td>823.603374</td>\n",
       "      <td>0.137727</td>\n",
       "      <td>0.248838</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.148641</td>\n",
       "      <td>0.088421</td>\n",
       "      <td>...</td>\n",
       "      <td>19.138682</td>\n",
       "      <td>70.077348</td>\n",
       "      <td>527.353744</td>\n",
       "      <td>0.081057</td>\n",
       "      <td>0.967259</td>\n",
       "      <td>0.768613</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>0.411533</td>\n",
       "      <td>0.114398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.291934</td>\n",
       "      <td>27.201953</td>\n",
       "      <td>181.558681</td>\n",
       "      <td>1855.503965</td>\n",
       "      <td>0.092321</td>\n",
       "      <td>0.130495</td>\n",
       "      <td>0.121235</td>\n",
       "      <td>0.161344</td>\n",
       "      <td>0.253601</td>\n",
       "      <td>0.050686</td>\n",
       "      <td>...</td>\n",
       "      <td>20.496797</td>\n",
       "      <td>244.051545</td>\n",
       "      <td>737.902638</td>\n",
       "      <td>0.113570</td>\n",
       "      <td>0.539616</td>\n",
       "      <td>0.519162</td>\n",
       "      <td>0.224678</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.103882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.057562</td>\n",
       "      <td>28.576870</td>\n",
       "      <td>118.085915</td>\n",
       "      <td>1950.063217</td>\n",
       "      <td>0.116175</td>\n",
       "      <td>0.088081</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.046779</td>\n",
       "      <td>0.271313</td>\n",
       "      <td>0.094279</td>\n",
       "      <td>...</td>\n",
       "      <td>42.416109</td>\n",
       "      <td>220.139219</td>\n",
       "      <td>4068.406721</td>\n",
       "      <td>0.137824</td>\n",
       "      <td>0.239713</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.053622</td>\n",
       "      <td>0.648685</td>\n",
       "      <td>0.184534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.918586</td>\n",
       "      <td>29.712978</td>\n",
       "      <td>179.793013</td>\n",
       "      <td>2137.624912</td>\n",
       "      <td>0.152703</td>\n",
       "      <td>0.208607</td>\n",
       "      <td>0.144123</td>\n",
       "      <td>0.102572</td>\n",
       "      <td>0.119708</td>\n",
       "      <td>0.072355</td>\n",
       "      <td>...</td>\n",
       "      <td>21.451040</td>\n",
       "      <td>63.424267</td>\n",
       "      <td>1093.128602</td>\n",
       "      <td>0.079290</td>\n",
       "      <td>0.210202</td>\n",
       "      <td>1.226388</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.422110</td>\n",
       "      <td>0.192488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.161025</td>\n",
       "      <td>14.472000</td>\n",
       "      <td>165.507047</td>\n",
       "      <td>767.169611</td>\n",
       "      <td>0.088117</td>\n",
       "      <td>0.064682</td>\n",
       "      <td>0.299970</td>\n",
       "      <td>0.111154</td>\n",
       "      <td>0.261824</td>\n",
       "      <td>0.087029</td>\n",
       "      <td>...</td>\n",
       "      <td>34.888900</td>\n",
       "      <td>214.781502</td>\n",
       "      <td>1736.560046</td>\n",
       "      <td>0.076944</td>\n",
       "      <td>0.751674</td>\n",
       "      <td>0.056103</td>\n",
       "      <td>0.272549</td>\n",
       "      <td>0.631171</td>\n",
       "      <td>0.128956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.358192</td>\n",
       "      <td>10.673417</td>\n",
       "      <td>54.533657</td>\n",
       "      <td>2243.729192</td>\n",
       "      <td>0.099610</td>\n",
       "      <td>0.306082</td>\n",
       "      <td>0.115744</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.201412</td>\n",
       "      <td>0.066918</td>\n",
       "      <td>...</td>\n",
       "      <td>45.088091</td>\n",
       "      <td>228.752291</td>\n",
       "      <td>626.643382</td>\n",
       "      <td>0.095609</td>\n",
       "      <td>1.015500</td>\n",
       "      <td>0.582116</td>\n",
       "      <td>0.108158</td>\n",
       "      <td>0.421198</td>\n",
       "      <td>0.195913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.761592</td>\n",
       "      <td>11.948286</td>\n",
       "      <td>102.011631</td>\n",
       "      <td>1440.100899</td>\n",
       "      <td>0.082082</td>\n",
       "      <td>0.126054</td>\n",
       "      <td>0.284197</td>\n",
       "      <td>0.194042</td>\n",
       "      <td>0.281004</td>\n",
       "      <td>0.071156</td>\n",
       "      <td>...</td>\n",
       "      <td>18.157305</td>\n",
       "      <td>247.514315</td>\n",
       "      <td>1082.508352</td>\n",
       "      <td>0.161203</td>\n",
       "      <td>0.524429</td>\n",
       "      <td>1.166074</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0.374829</td>\n",
       "      <td>0.109418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.809544</td>\n",
       "      <td>38.265323</td>\n",
       "      <td>53.404190</td>\n",
       "      <td>968.388971</td>\n",
       "      <td>0.130290</td>\n",
       "      <td>0.039052</td>\n",
       "      <td>0.423559</td>\n",
       "      <td>0.197425</td>\n",
       "      <td>0.165407</td>\n",
       "      <td>0.075848</td>\n",
       "      <td>...</td>\n",
       "      <td>35.536580</td>\n",
       "      <td>185.731004</td>\n",
       "      <td>4003.504235</td>\n",
       "      <td>0.136433</td>\n",
       "      <td>0.750488</td>\n",
       "      <td>1.004241</td>\n",
       "      <td>0.250674</td>\n",
       "      <td>0.282319</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.910086</td>\n",
       "      <td>37.422954</td>\n",
       "      <td>57.596190</td>\n",
       "      <td>1333.899971</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.294345</td>\n",
       "      <td>0.054597</td>\n",
       "      <td>0.182668</td>\n",
       "      <td>0.122754</td>\n",
       "      <td>0.099060</td>\n",
       "      <td>...</td>\n",
       "      <td>24.864998</td>\n",
       "      <td>98.543202</td>\n",
       "      <td>4090.749277</td>\n",
       "      <td>0.100997</td>\n",
       "      <td>0.825614</td>\n",
       "      <td>0.223107</td>\n",
       "      <td>0.113656</td>\n",
       "      <td>0.507188</td>\n",
       "      <td>0.075575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x.radius_mean  x.texture_mean  x.perimeter_mean  x.area_mean  \\\n",
       "0      10.130198       24.737195         88.810329  1247.634985   \n",
       "1      19.789122       17.665263        126.559937   823.603374   \n",
       "2      14.291934       27.201953        181.558681  1855.503965   \n",
       "3      12.057562       28.576870        118.085915  1950.063217   \n",
       "4      11.918586       29.712978        179.793013  2137.624912   \n",
       "5      12.161025       14.472000        165.507047   767.169611   \n",
       "6      13.358192       10.673417         54.533657  2243.729192   \n",
       "7      20.761592       11.948286        102.011631  1440.100899   \n",
       "8      16.809544       38.265323         53.404190   968.388971   \n",
       "9      15.910086       37.422954         57.596190  1333.899971   \n",
       "\n",
       "   x.smoothness_mean  x.compactness_mean  x.concavity_mean  \\\n",
       "0           0.051448            0.162705          0.001453   \n",
       "1           0.137727            0.248838          0.000173   \n",
       "2           0.092321            0.130495          0.121235   \n",
       "3           0.116175            0.088081          0.005006   \n",
       "4           0.152703            0.208607          0.144123   \n",
       "5           0.088117            0.064682          0.299970   \n",
       "6           0.099610            0.306082          0.115744   \n",
       "7           0.082082            0.126054          0.284197   \n",
       "8           0.130290            0.039052          0.423559   \n",
       "9           0.090092            0.294345          0.054597   \n",
       "\n",
       "   x.concave_pts_mean  x.symmetry_mean  x.fractal_dim_mean  ...  \\\n",
       "0            0.058143         0.212523            0.062168  ...   \n",
       "1            0.056343         0.148641            0.088421  ...   \n",
       "2            0.161344         0.253601            0.050686  ...   \n",
       "3            0.046779         0.271313            0.094279  ...   \n",
       "4            0.102572         0.119708            0.072355  ...   \n",
       "5            0.111154         0.261824            0.087029  ...   \n",
       "6            0.007163         0.201412            0.066918  ...   \n",
       "7            0.194042         0.281004            0.071156  ...   \n",
       "8            0.197425         0.165407            0.075848  ...   \n",
       "9            0.182668         0.122754            0.099060  ...   \n",
       "\n",
       "   x.texture_worst  x.perimeter_worst  x.area_worst  x.smoothness_worst  \\\n",
       "0        24.585597         105.048960   2987.848210            0.201296   \n",
       "1        19.138682          70.077348    527.353744            0.081057   \n",
       "2        20.496797         244.051545    737.902638            0.113570   \n",
       "3        42.416109         220.139219   4068.406721            0.137824   \n",
       "4        21.451040          63.424267   1093.128602            0.079290   \n",
       "5        34.888900         214.781502   1736.560046            0.076944   \n",
       "6        45.088091         228.752291    626.643382            0.095609   \n",
       "7        18.157305         247.514315   1082.508352            0.161203   \n",
       "8        35.536580         185.731004   4003.504235            0.136433   \n",
       "9        24.864998          98.543202   4090.749277            0.100997   \n",
       "\n",
       "   x.compactness_worst  x.concavity_worst  x.concave_pts_worst  \\\n",
       "0             0.418472           0.843002             0.167773   \n",
       "1             0.967259           0.768613             0.109550   \n",
       "2             0.539616           0.519162             0.224678   \n",
       "3             0.239713           0.002486             0.053622   \n",
       "4             0.210202           1.226388             0.003351   \n",
       "5             0.751674           0.056103             0.272549   \n",
       "6             1.015500           0.582116             0.108158   \n",
       "7             0.524429           1.166074             0.013372   \n",
       "8             0.750488           1.004241             0.250674   \n",
       "9             0.825614           0.223107             0.113656   \n",
       "\n",
       "   x.symmetry_worst  x.fractal_dim_worst  y  \n",
       "0          0.529615             0.064025  0  \n",
       "1          0.411533             0.114398  0  \n",
       "2          0.450000             0.103882  0  \n",
       "3          0.648685             0.184534  0  \n",
       "4          0.422110             0.192488  0  \n",
       "5          0.631171             0.128956  1  \n",
       "6          0.421198             0.195913  1  \n",
       "7          0.374829             0.109418  1  \n",
       "8          0.282319             0.060284  1  \n",
       "9          0.507188             0.075575  1  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir los rangos de las columnas\n",
    "column_ranges = {\n",
    "    'x.radius_mean': (6.98, 28.1),\n",
    "    'x.texture_mean': (9.71, 39.3),\n",
    "    'x.perimeter_mean': (43.8, 189),\n",
    "    'x.area_mean': (144, 2500),\n",
    "    'x.smoothness_mean': (0.05, 0.16),\n",
    "    'x.compactness_mean': (0.02, 0.35),\n",
    "    'x.concavity_mean': (0, 0.43),\n",
    "    'x.concave_pts_mean': (0, 0.2),\n",
    "    'x.symmetry_mean': (0.11, 0.3),\n",
    "    'x.fractal_dim_mean': (0.05, 0.1),\n",
    "    'x.radius_se': (0.11, 2.87),\n",
    "    'x.texture_se': (0.36, 4.88),\n",
    "    'x.perimeter_se': (0.76, 22),\n",
    "    'x.area_se': (6.8, 542),\n",
    "    'x.smoothness_se': (0, 0.03),\n",
    "    'x.compactness_se': (0, 0.14),\n",
    "    'x.concavity_se': (0, 0.4),\n",
    "    'x.concave_pts_se': (0, 0.05),\n",
    "    'x.symmetry_se': (0.01, 0.08),\n",
    "    'x.fractal_dim_se': (0, 0.03),\n",
    "    'x.radius_worst': (7.93, 36),\n",
    "    'x.texture_worst': (12, 49.5),\n",
    "    'x.perimeter_worst': (50.4, 251),\n",
    "    'x.area_worst': (185, 4250),\n",
    "    'x.smoothness_worst': (0.07, 0.22),\n",
    "    'x.compactness_worst': (0.03, 1.06),\n",
    "    'x.concavity_worst': (0, 1.25),\n",
    "    'x.concave_pts_worst': (0, 0.29),\n",
    "    'x.symmetry_worst': (0.16, 0.66),\n",
    "    'x.fractal_dim_worst': (0.06, 0.21)\n",
    "}\n",
    "\n",
    "# Número de registros a generar\n",
    "n_records = 10\n",
    "\n",
    "# Generar los valores para X de manera aleatoria dentro de los rangos\n",
    "data = {}\n",
    "for column, (min_val, max_val) in column_ranges.items():\n",
    "    data[column] = np.random.uniform(min_val, max_val, n_records)\n",
    "\n",
    "# Generar la variable objetivo y con 5 valores 0 y 5 valores 1\n",
    "y = np.array([0] * 5 + [1] * 5)\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_cancer_10 = pd.DataFrame(data)\n",
    "df_cancer_10['y'] = y\n",
    "\n",
    "# Mostrar los primeros registros del nuevo DataFrame\n",
    "display(df_cancer_10.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizamos como con los datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x.radius_mean</th>\n",
       "      <th>x.texture_mean</th>\n",
       "      <th>x.perimeter_mean</th>\n",
       "      <th>x.area_mean</th>\n",
       "      <th>x.smoothness_mean</th>\n",
       "      <th>x.compactness_mean</th>\n",
       "      <th>x.concavity_mean</th>\n",
       "      <th>x.concave_pts_mean</th>\n",
       "      <th>x.symmetry_mean</th>\n",
       "      <th>x.fractal_dim_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>x.texture_worst</th>\n",
       "      <th>x.perimeter_worst</th>\n",
       "      <th>x.area_worst</th>\n",
       "      <th>x.smoothness_worst</th>\n",
       "      <th>x.compactness_worst</th>\n",
       "      <th>x.concavity_worst</th>\n",
       "      <th>x.concave_pts_worst</th>\n",
       "      <th>x.symmetry_worst</th>\n",
       "      <th>x.fractal_dim_worst</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.367638</td>\n",
       "      <td>0.070510</td>\n",
       "      <td>-0.501311</td>\n",
       "      <td>-0.444673</td>\n",
       "      <td>-1.838027</td>\n",
       "      <td>-0.046810</td>\n",
       "      <td>-1.036649</td>\n",
       "      <td>-0.819711</td>\n",
       "      <td>0.147967</td>\n",
       "      <td>-1.012343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430747</td>\n",
       "      <td>-0.884607</td>\n",
       "      <td>0.616841</td>\n",
       "      <td>2.147346</td>\n",
       "      <td>-0.765880</td>\n",
       "      <td>0.487331</td>\n",
       "      <td>0.398229</td>\n",
       "      <td>0.574396</td>\n",
       "      <td>-1.196507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.511225</td>\n",
       "      <td>-0.674207</td>\n",
       "      <td>0.287999</td>\n",
       "      <td>-1.267567</td>\n",
       "      <td>1.176368</td>\n",
       "      <td>0.915679</td>\n",
       "      <td>-1.045895</td>\n",
       "      <td>-0.847240</td>\n",
       "      <td>-0.938000</td>\n",
       "      <td>0.804996</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.006256</td>\n",
       "      <td>-1.377555</td>\n",
       "      <td>-1.083915</td>\n",
       "      <td>-0.968179</td>\n",
       "      <td>1.276171</td>\n",
       "      <td>0.309514</td>\n",
       "      <td>-0.245203</td>\n",
       "      <td>-0.523994</td>\n",
       "      <td>-0.173604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.127224</td>\n",
       "      <td>0.330064</td>\n",
       "      <td>1.437974</td>\n",
       "      <td>0.734984</td>\n",
       "      <td>-0.410024</td>\n",
       "      <td>-0.406736</td>\n",
       "      <td>-0.171658</td>\n",
       "      <td>0.757958</td>\n",
       "      <td>0.846288</td>\n",
       "      <td>-1.807103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862761</td>\n",
       "      <td>1.074726</td>\n",
       "      <td>-0.938379</td>\n",
       "      <td>-0.125726</td>\n",
       "      <td>-0.315100</td>\n",
       "      <td>-0.286766</td>\n",
       "      <td>1.027089</td>\n",
       "      <td>-0.166180</td>\n",
       "      <td>-0.387148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.793183</td>\n",
       "      <td>0.474851</td>\n",
       "      <td>0.110815</td>\n",
       "      <td>0.918489</td>\n",
       "      <td>0.423398</td>\n",
       "      <td>-0.880698</td>\n",
       "      <td>-1.010991</td>\n",
       "      <td>-0.993438</td>\n",
       "      <td>1.147370</td>\n",
       "      <td>1.210475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.453185</td>\n",
       "      <td>0.737666</td>\n",
       "      <td>1.363751</td>\n",
       "      <td>0.502724</td>\n",
       "      <td>-1.431046</td>\n",
       "      <td>-1.521810</td>\n",
       "      <td>-0.863280</td>\n",
       "      <td>1.681989</td>\n",
       "      <td>1.250603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.834605</td>\n",
       "      <td>0.594490</td>\n",
       "      <td>1.401056</td>\n",
       "      <td>1.282479</td>\n",
       "      <td>1.699610</td>\n",
       "      <td>0.466114</td>\n",
       "      <td>-0.006376</td>\n",
       "      <td>-0.140506</td>\n",
       "      <td>-1.429843</td>\n",
       "      <td>-0.307115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761937</td>\n",
       "      <td>-1.471335</td>\n",
       "      <td>-0.692837</td>\n",
       "      <td>-1.013972</td>\n",
       "      <td>-1.540858</td>\n",
       "      <td>1.403765</td>\n",
       "      <td>-1.418834</td>\n",
       "      <td>-0.425615</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.762345</td>\n",
       "      <td>-1.010478</td>\n",
       "      <td>1.102349</td>\n",
       "      <td>-1.377084</td>\n",
       "      <td>-0.556902</td>\n",
       "      <td>-1.142158</td>\n",
       "      <td>1.119059</td>\n",
       "      <td>-0.009319</td>\n",
       "      <td>0.986069</td>\n",
       "      <td>0.708630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657877</td>\n",
       "      <td>0.662146</td>\n",
       "      <td>-0.248081</td>\n",
       "      <td>-1.074741</td>\n",
       "      <td>0.473974</td>\n",
       "      <td>-1.393647</td>\n",
       "      <td>1.556123</td>\n",
       "      <td>1.519074</td>\n",
       "      <td>0.122007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.405527</td>\n",
       "      <td>-1.410491</td>\n",
       "      <td>-1.218006</td>\n",
       "      <td>1.488390</td>\n",
       "      <td>-0.155338</td>\n",
       "      <td>1.555344</td>\n",
       "      <td>-0.211314</td>\n",
       "      <td>-1.599069</td>\n",
       "      <td>-0.040921</td>\n",
       "      <td>-0.683520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.735501</td>\n",
       "      <td>0.859073</td>\n",
       "      <td>-1.015284</td>\n",
       "      <td>-0.591107</td>\n",
       "      <td>1.455678</td>\n",
       "      <td>-0.136283</td>\n",
       "      <td>-0.260587</td>\n",
       "      <td>-0.434094</td>\n",
       "      <td>1.481679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.801071</td>\n",
       "      <td>-1.276240</td>\n",
       "      <td>-0.225284</td>\n",
       "      <td>-0.071165</td>\n",
       "      <td>-0.767725</td>\n",
       "      <td>-0.456362</td>\n",
       "      <td>1.005157</td>\n",
       "      <td>1.257824</td>\n",
       "      <td>1.312125</td>\n",
       "      <td>-0.390123</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.109946</td>\n",
       "      <td>1.123536</td>\n",
       "      <td>-0.700178</td>\n",
       "      <td>1.108488</td>\n",
       "      <td>-0.371608</td>\n",
       "      <td>1.259591</td>\n",
       "      <td>-1.308086</td>\n",
       "      <td>-0.865416</td>\n",
       "      <td>-0.274727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.623155</td>\n",
       "      <td>1.495104</td>\n",
       "      <td>-1.241622</td>\n",
       "      <td>-0.986590</td>\n",
       "      <td>0.916536</td>\n",
       "      <td>-1.428566</td>\n",
       "      <td>2.011545</td>\n",
       "      <td>1.309550</td>\n",
       "      <td>-0.652979</td>\n",
       "      <td>-0.065367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726310</td>\n",
       "      <td>0.252660</td>\n",
       "      <td>1.318889</td>\n",
       "      <td>0.466670</td>\n",
       "      <td>0.469561</td>\n",
       "      <td>0.872752</td>\n",
       "      <td>1.314378</td>\n",
       "      <td>-1.725944</td>\n",
       "      <td>-1.272465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.355070</td>\n",
       "      <td>1.406397</td>\n",
       "      <td>-1.153971</td>\n",
       "      <td>-0.277263</td>\n",
       "      <td>-0.487898</td>\n",
       "      <td>1.424193</td>\n",
       "      <td>-0.652878</td>\n",
       "      <td>1.083950</td>\n",
       "      <td>-1.378074</td>\n",
       "      <td>1.541470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401226</td>\n",
       "      <td>-0.976310</td>\n",
       "      <td>1.379195</td>\n",
       "      <td>-0.451502</td>\n",
       "      <td>0.749108</td>\n",
       "      <td>-0.994447</td>\n",
       "      <td>-0.199830</td>\n",
       "      <td>0.365785</td>\n",
       "      <td>-0.961956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x.radius_mean  x.texture_mean  x.perimeter_mean  x.area_mean  \\\n",
       "0      -1.367638        0.070510         -0.501311    -0.444673   \n",
       "1       1.511225       -0.674207          0.287999    -1.267567   \n",
       "2      -0.127224        0.330064          1.437974     0.734984   \n",
       "3      -0.793183        0.474851          0.110815     0.918489   \n",
       "4      -0.834605        0.594490          1.401056     1.282479   \n",
       "5      -0.762345       -1.010478          1.102349    -1.377084   \n",
       "6      -0.405527       -1.410491         -1.218006     1.488390   \n",
       "7       1.801071       -1.276240         -0.225284    -0.071165   \n",
       "8       0.623155        1.495104         -1.241622    -0.986590   \n",
       "9       0.355070        1.406397         -1.153971    -0.277263   \n",
       "\n",
       "   x.smoothness_mean  x.compactness_mean  x.concavity_mean  \\\n",
       "0          -1.838027           -0.046810         -1.036649   \n",
       "1           1.176368            0.915679         -1.045895   \n",
       "2          -0.410024           -0.406736         -0.171658   \n",
       "3           0.423398           -0.880698         -1.010991   \n",
       "4           1.699610            0.466114         -0.006376   \n",
       "5          -0.556902           -1.142158          1.119059   \n",
       "6          -0.155338            1.555344         -0.211314   \n",
       "7          -0.767725           -0.456362          1.005157   \n",
       "8           0.916536           -1.428566          2.011545   \n",
       "9          -0.487898            1.424193         -0.652878   \n",
       "\n",
       "   x.concave_pts_mean  x.symmetry_mean  x.fractal_dim_mean  ...  \\\n",
       "0           -0.819711         0.147967           -1.012343  ...   \n",
       "1           -0.847240        -0.938000            0.804996  ...   \n",
       "2            0.757958         0.846288           -1.807103  ...   \n",
       "3           -0.993438         1.147370            1.210475  ...   \n",
       "4           -0.140506        -1.429843           -0.307115  ...   \n",
       "5           -0.009319         0.986069            0.708630  ...   \n",
       "6           -1.599069        -0.040921           -0.683520  ...   \n",
       "7            1.257824         1.312125           -0.390123  ...   \n",
       "8            1.309550        -0.652979           -0.065367  ...   \n",
       "9            1.083950        -1.378074            1.541470  ...   \n",
       "\n",
       "   x.texture_worst  x.perimeter_worst  x.area_worst  x.smoothness_worst  \\\n",
       "0        -0.430747          -0.884607      0.616841            2.147346   \n",
       "1        -1.006256          -1.377555     -1.083915           -0.968179   \n",
       "2        -0.862761           1.074726     -0.938379           -0.125726   \n",
       "3         1.453185           0.737666      1.363751            0.502724   \n",
       "4        -0.761937          -1.471335     -0.692837           -1.013972   \n",
       "5         0.657877           0.662146     -0.248081           -1.074741   \n",
       "6         1.735501           0.859073     -1.015284           -0.591107   \n",
       "7        -1.109946           1.123536     -0.700178            1.108488   \n",
       "8         0.726310           0.252660      1.318889            0.466670   \n",
       "9        -0.401226          -0.976310      1.379195           -0.451502   \n",
       "\n",
       "   x.compactness_worst  x.concavity_worst  x.concave_pts_worst  \\\n",
       "0            -0.765880           0.487331             0.398229   \n",
       "1             1.276171           0.309514            -0.245203   \n",
       "2            -0.315100          -0.286766             1.027089   \n",
       "3            -1.431046          -1.521810            -0.863280   \n",
       "4            -1.540858           1.403765            -1.418834   \n",
       "5             0.473974          -1.393647             1.556123   \n",
       "6             1.455678          -0.136283            -0.260587   \n",
       "7            -0.371608           1.259591            -1.308086   \n",
       "8             0.469561           0.872752             1.314378   \n",
       "9             0.749108          -0.994447            -0.199830   \n",
       "\n",
       "   x.symmetry_worst  x.fractal_dim_worst  y  \n",
       "0          0.574396            -1.196507  0  \n",
       "1         -0.523994            -0.173604  0  \n",
       "2         -0.166180            -0.387148  0  \n",
       "3          1.681989             1.250603  0  \n",
       "4         -0.425615             1.412119  0  \n",
       "5          1.519074             0.122007  1  \n",
       "6         -0.434094             1.481679  1  \n",
       "7         -0.865416            -0.274727  1  \n",
       "8         -1.725944            -1.272465  1  \n",
       "9          0.365785            -0.961956  1  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Escalar todas las columnas numéricas, excepto la columna 'y'\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Seleccionar las características (eliminar 'y' antes de aplicar el escalado)\n",
    "X = df_cancer_10.drop('y', axis=1)\n",
    "\n",
    "# Aplicar el escalado\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reemplazar el DataFrame original con los valores escalados\n",
    "dfcancer_limpio_scaled_10 = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Volver a añadir la columna 'y' al DataFrame escalado\n",
    "dfcancer_limpio_scaled_10['y'] = df_cancer_10['y'].reset_index(drop=True)\n",
    "\n",
    "# Ahora dfcancer_limpio_scaled contiene los datos escalados\n",
    "df_cancer_10 = dfcancer_limpio_scaled_10\n",
    "display(df_cancer_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Probamos el modelo con el mejor algoritmo e hiperparámetros obtenidos (KNN (n_neighbors = 15, weights = 'distance', metric = 'euclidean') ):\n",
    "#### Como ya lo sabemos del apartado anterior, no podemos probar este modelo para nuestros 10 registros, por los n_neighbors = 15, por lo que lo probaremos con la mitad --> 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\n",
      "KNN : Exactitud en los datos de entrenamiento: 1.000\n",
      "KNN : Exactitud en los datos de testeo: 0.500\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 1.000\n",
      "KNN : F1 Score en los datos de testeo: 0.667\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "KNN : Sensibilidad en los datos de testeo: 1.000\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 1.000\n",
      "KNN : Precisión en los datos de testeo: 0.500\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 1.000\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 1.000\n",
      "\n",
      "MEJORES RESULTADOS PARA EL DATASET ENTERO\n",
      "KNN : Exactitud en los datos de entrenamiento: 1.000\n",
      "KNN : Exactitud en los datos de testeo: 0.939\n",
      "\n",
      "KNN : F1 Score en los datos de entrenamiento: 1.000\n",
      "KNN : F1 Score en los datos de testeo: 0.914\n",
      "\n",
      "KNN : Sensibilidad en los datos de entrenamiento: 1.000\n",
      "KNN : Sensibilidad en los datos de testeo: 0.860\n",
      "\n",
      "KNN : Precisión en los datos de entrenamiento: 1.000\n",
      "KNN : Precisión en los datos de testeo: 0.974\n",
      "\n",
      "KNN : AUC-ROC en los datos de entrenamiento: 1.000\n",
      "KNN : AUC-ROC en los datos de testeo: 0.996\n",
      "\n",
      "KNN : Precision-Recall AUC en los datos de entrenamiento: 1.000\n",
      "KNN : Precision-Recall AUC en los datos de testeo: 0.994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------\")\n",
    "print(\"SOLO CON LOS NUEVOS 10 REGISTROS DE PRUEBA\")\n",
    "KVecinos_hiper_10 = aplicar_knn_hiper(df_cancer_10, 'y', tipo_modelo='clasificacion', n_neighbors=7, weights='distance', metric='manhattan')\n",
    "print(\"MEJORES RESULTADOS PARA EL DATASET ENTERO\")\n",
    "KVecinos_hiper_2_ = aplicar_knn_hiper(dfcancer_limpio, 'y', tipo_modelo='clasificacion', n_neighbors=10, weights='distance', metric='manhattan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Métrica**                        | **Dataset Entero (Entrenamiento / Testeo)** | **10 Nuevos Registros (Entrenamiento / Testeo)** |\n",
    "|------------------------------------|--------------------------------------------|-------------------------------------------------|\n",
    "| **Exactitud**                      | 1.000 / 0.939                              | 1.000 / 0.500                                   |\n",
    "| **F1 Score**                       | 1.000 / 0.914                              | 1.000 / 0.667                                   |\n",
    "| **Sensibilidad**                   | 1.000 / 0.860                              | 1.000 / 1.000                                   |\n",
    "| **Precisión**                      | 1.000 / 0.974                              | 1.000 / 0.500                                   |\n",
    "| **AUC-ROC**                        | 1.000 / 0.996                              | 1.000 / 1.000                                   |\n",
    "| **Precision-Recall AUC**           | 1.000 / 0.994                              | 1.000 / 1.000                                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones:\n",
    "* **Exactitud (Accuracy)**: En el conjunto de datos completo, la exactitud es muy alta (cerca de 1.000 tanto en entrenamiento como en testeo). Sin embargo, en los 10 nuevos registros de prueba, la exactitud en el testeo disminuye significativamente a 0.500. Esto puede deberse a que el modelo se ajusta demasiado a los datos de entrenamiento (overfitting), especialmente si los 10 nuevos registros son muy diferentes o no siguen los patrones que el modelo aprendió con los 569 registros. Puede ser que sea porque tenemos 5 registros como positivos y 5 negativos y se ha aprendido ese patrón de resultado en y.\n",
    "* **F1 Score:** El F1 Score muestra una disminución en los nuevos registros de prueba (de 1.000 a 0.667). El F1 score es una métrica que combina la precisión y la sensibilidad, y su disminución también puede estar relacionada con la dificultad del modelo para generalizar a un conjunto de datos más pequeño.\n",
    "* **Sensibilidad:** La sensibilidad permanece igual en el entrenamiento (1.000), pero en los 10 registros de prueba es 1.000. Esto sugiere que el modelo detecta correctamente todas las instancias positivas en los nuevos registros, lo que puede ser el caso si estos registros no presentan mucha variabilidad en las clases, pero en nuestros 10 registros tenemos 5 registros positivos y 5 negativos, asi que no sé por qué tendría una Sensibilidad perfecta en este caso.\n",
    "* **Precisión:** La precisión (precisión) también disminuye en los nuevos registros de prueba, pasando de 1.000 en el entrenamiento a 0.500 en el testeo. Este cambio sugiere que el modelo tiene dificultades para identificar correctamente los casos negativos en el conjunto de prueba más pequeño.\n",
    "* **AUC-ROC y Precision-Recall AUC:** Ambas métricas permanecen en 1.000 en el entrenamiento y 1.000 en el testeo para los 10 nuevos registros. Esto indica que el modelo mantiene una buena capacidad discriminatoria incluso en los datos de prueba, a pesar de la baja exactitud y precisión. La AUC-ROC y Precision-Recall AUC miden la capacidad del modelo para clasificar correctamente las clases positivas y negativas sin verse tan afectadas por los desequilibrios en el conjunto de prueba.\n",
    "\n",
    "#### En conclusion con todas las pruebas que hemos hecho con solo 10 registros y comparándolas al mejor resultado cuando teníamos todos los dataset completos:\n",
    "* Siempre vamos a ver que las métricas como Exactitud y Precisión caen debido a la falta de variabilidad o representatividad del conjunto de prueba.\n",
    "* No podemos considerar esos resultados como \"reales\", los resultados no son tan sólidos como cuando se utiliza un conjunto de datos completo y más representativo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 532277,
     "sourceId": 975216,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1866301,
     "sourceId": 3047725,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3248517,
     "sourceId": 5651459,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5760185,
     "sourceId": 9471817,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
